[
    {
        "Index": 0,
        "Title": "Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models.",
        "Abstract": "Finetuning large language models (LLMs) has been empirically effective on a variety of downstream tasks. However, traditional tuning methods often require a significant amount of time and memory due to the large number of parameters in these models. In this paper, we propose Quantized Side Tuning, a fast and memory-efficient method for tuning quantized LLMs. By quantizing the weights during training, we reduce the memory footprint of the model while maintaining performance. Additionally, we introduce a side network that leverages the quantized weights to speed up the tuning process. Our experimental results demonstrate that Quantized Side Tuning achieves competitive performance compared to traditional fine-tuning methods but with significantly less time and memory requirements. Overall, our approach provides a more efficient way to fine-tune large language models for various downstream applications.",
        "Source": "GPT"
    },
    {
        "Index": 1,
        "Title": "Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances.",
        "Abstract": "Discovering the semantics of multimodal utterances is essential for understanding human language and enhancing human-machine interactions. In this study, we propose an unsupervised multimodal clustering approach for semantics discovery in multimodal utterances. By integrating information from multiple modalities such as text, audio, and visual signals, our model is able to capture the complex relationships between different modes of communication. The proposed method leverages the inherent structure in the data to cluster multimodal utterances based on their semantic content, without the need for labeled training data.\n\nWe demonstrate the effectiveness of our approach on a real-world multimodal dataset, showing that it outperforms traditional methods for semantics discovery in multimodal utterances. Our results indicate that our unsupervised multimodal clustering technique can accurately identify semantically similar multimodal utterances, providing valuable insights for understanding human language and improving human-machine interactions. Overall, our approach offers a promising avenue for enhancing multimodal communication systems by uncovering the underlying semantics of complex multimodal utterances.",
        "Source": "GPT"
    },
    {
        "Index": 2,
        "Title": "MAGE: Machine-generated Text Detection in the Wild.",
        "Abstract": "\n\nLarge language models (LLMs) have made significant strides in text generation, raising concerns about the potential misuse of technology for deepfake applications. In response to this growing threat, we introduce MAGE, a machine-generated text detection system designed to identify and combat deepfake text in real-world settings. Leveraging state-of-the-art deep learning techniques, MAGE can accurately distinguish between authentic and machine-generated text, providing a crucial defense against the dissemination of false information. Our experimental results demonstrate the effectiveness of MAGE in detecting various types of machine-generated text, including fake news, fraudulent emails, and misleading advertisements. By incorporating advanced natural language processing capabilities and robust model training, MAGE offers a practical solution for identifying and mitigating the risks associated with text-based deepfakes. Through its innovative approach and high detection accuracy, MAGE represents a significant advancement in the field of text detection technology, advancing the fight against deceptive and manipulative content in the digital age.",
        "Source": "GPT"
    },
    {
        "Index": 3,
        "Title": "PrivLM-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models.",
        "Abstract": "The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models, leading to concerns about privacy implications. To address this issue, we introduce PrivLM-Bench, a multi-level privacy evaluation benchmark designed to assess the privacy performance of language models. PrivLM-Bench evaluates language models based on various privacy metrics such as data exposure, data leakage, and user identification risk. By providing a standardized framework for privacy evaluation, PrivLM-Bench enables researchers and developers to compare the privacy performance of different language models and identify potential privacy vulnerabilities. Our benchmark offers a comprehensive evaluation process that considers various aspects of privacy, helping to improve the overall privacy protection of language models. Overall, PrivLM-Bench serves as a valuable tool for advancing the field of privacy-preserving language modeling and promoting the development of more privacy-aware language models.",
        "Source": "GPT"
    },
    {
        "Index": 4,
        "Title": "GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators.",
        "Abstract": "Recent advances in large language models (LLMs) have significantly advanced the field of multilingual speech and machine translation. These models, such as GPT-3 and BERT, have shown impressive capabilities in understanding and generating human language across multiple languages. By training on vast amounts of data from different language sources, LLMs are able to capture the nuances and complexities of various languages, allowing them to effectively translate and generate speech in multiple languages.\n\nGenTranslate is a groundbreaking project that leverages the power of LLMs to create a generative multilingual speech and machine translation system. By combining state-of-the-art LLMs with innovative techniques in machine translation, GenTranslate is able to provide accurate and natural translations across a wide range of languages. This system has the potential to revolutionize communication and break down language barriers in today's globalized world. With GenTranslate, users can expect high-quality, seamless translation and speech generation in multiple languages, making it easier than ever to connect and communicate with people from different linguistic backgrounds.",
        "Source": "GPT"
    },
    {
        "Index": 5,
        "Title": "Exploring Chain-of-Thought for Multi-modal Metaphor Detection.",
        "Abstract": "Metaphors are widely used in various forms of communication such as advertising and internet memes to convey complex ideas in a concise and engaging manner. Detecting metaphors in multi-modal content, which combines different modes of communication such as text, images, and videos, is a challenging task due to the diverse ways in which metaphors can be expressed. In this study, we propose an approach to multi-modal metaphor detection that leverages the concept of chain-of-thought, which refers to the cognitive process of generating and interpreting metaphors. By exploring the interconnected nature of metaphors within a given context, our method aims to enhance the accuracy and robustness of metaphor detection in multi-modal content. We evaluate our approach on a diverse dataset of internet memes and demonstrate its effectiveness in identifying metaphors across different modalities. Our findings suggest that incorporating chain-of-thought reasoning can improve the detection of metaphors in multi-modal content, offering valuable insights for understanding and analyzing metaphorical expressions in various forms of communication.",
        "Source": "GPT"
    },
    {
        "Index": 6,
        "Title": "BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation.",
        "Abstract": "The upscaling of Large Language Models (LLMs) has yielded impressive advances in natural language processing, enabling machines to generate coherent and contextually relevant text. However, the significant computational resources required for training and maintaining these models pose a challenge for widespread adoption. In this paper, we introduce BitDistiller, a novel approach to optimize and distill sub-4-bit LLMs, unlocking their potential for efficient and effective language processing tasks.\n\nBy leveraging self-distillation techniques, BitDistiller fine-tunes pre-trained sub-4-bit LLMs to improve their performance while reducing their memory footprint and computational cost. Our experimental results demonstrate that BitDistiller successfully enhances the efficiency and effectiveness of sub-4-bit LLMs, making them suitable for a wider range of applications. Through BitDistiller, we aim to democratize access to powerful language processing capabilities by providing a more cost-effective and resource-efficient solution that maintains high performance standards.",
        "Source": "GPT"
    },
    {
        "Index": 7,
        "Title": "A Unified Temporal Knowledge Graph Reasoning Model Towards Interpolation and Extrapolation.",
        "Abstract": "Temporal knowledge graph (TKG) reasoning has two settings: interpolation reasoning and extrapolation reasoning. Both of these settings aim to predict missing information within the knowledge graph based on existing temporal relationships. In this paper, we propose a unified TKG reasoning model that can handle both interpolation and extrapolation tasks seamlessly. Our model leverages the temporal dependencies between entities and events in the knowledge graph to make accurate predictions. We introduce a novel attention mechanism that dynamically captures the importance of different temporal relationships in the reasoning process. Additionally, we incorporate a graph neural network to capture higher-order dependencies within the knowledge graph. Experimental results on benchmark datasets demonstrate that our proposed model outperforms existing methods in both interpolation and extrapolation tasks. By providing a comprehensive solution for TKG reasoning, our model contributes to the advancement of temporal reasoning in knowledge graphs.",
        "Source": "GPT"
    },
    {
        "Index": 8,
        "Title": "Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation.",
        "Abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating additional information from retrieval. However, the effectiveness of RAG heavily relies on the quality of the retrieved information. In this study, we propose a novel approach for unsupervised information refinement training of LLMs for RAG. By iteratively updating the retrieval process based on the generation results, our method refines the retrieved information to better assist the language model in generating more accurate and coherent outputs. Through extensive experiments on various benchmarks, we demonstrate that our approach significantly improves the performance of RAG compared to traditional methods. Additionally, we show that our method can adapt to different retrieval systems and languages, making it a versatile and effective solution for enhancing LLMs through retrieval-augmented generation. Overall, our research provides a valuable contribution to the field of natural language processing, paving the way for more advanced and efficient language models.",
        "Source": "GPT"
    },
    {
        "Index": 9,
        "Title": "CSCD-NS: a Chinese Spelling Check Dataset for Native Speakers.",
        "Abstract": "In this paper, we present CSCD-NS, the first Chinese spelling check (CSC) dataset designed for native speakers. The dataset contains a large number of sentences with spelling errors commonly made by native Chinese speakers, as well as the corrected versions of these sentences. CSCD-NS aims to facilitate the development and evaluation of automatic spelling check systems specifically tailored to the needs of native Chinese speakers, enabling researchers to improve the accuracy and reliability of such systems.\n\nWe provide detailed statistics about the dataset, including the types of spelling errors present, the distribution of errors across different sentence structures, and the frequency of different corrections. Additionally, we propose a methodology for using CSCD-NS to train and evaluate CSC systems, and we demonstrate the utility of the dataset through experiments with state-of-the-art CSC models.\n\nOverall, CSCD-NS represents a valuable resource for advancing research in Chinese spelling check and improving the user experience for native Chinese speakers.",
        "Source": "GPT"
    },
    {
        "Index": 10,
        "Title": "Evaluating Dynamic Topic Models.",
        "Abstract": "Dynamic topic models (DTMs) have gained popularity in recent years for their ability to represent the evolution of topics over time. However, one significant challenge in the field is the lack of quantitative measures to evaluate the progression of topics through time. This has hindered the ability to effectively analyze the performance and interpretability of DTMs in real-world applications. \n\nIn this study, we propose a novel framework for evaluating DTMs by introducing quantitative measures to assess the coherence and distinctiveness of topics over time. We leverage tools from graph theory and statistical analysis to provide a comprehensive evaluation of the dynamic topic modeling process. \n\nOur approach allows for a systematic comparison of different DTMs and provides valuable insights into their performance and reliability in capturing temporal changes in textual data. By enhancing the evaluation process, our framework aims to advance the field of dynamic topic modeling and facilitate more accurate and robust analyses in various domains.",
        "Source": "GPT"
    },
    {
        "Index": 11,
        "Title": "How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition.",
        "Abstract": "Large language models (LLMs) with enormous pre-training tokens and parameters have been shown to possess a wide range of abilities, including mathematical reasoning. However, the extent to which these abilities are affected by the composition of supervised fine-tuning data remains unclear. In this study, we investigate how the composition of fine-tuning data impacts the abilities of LLMs in tasks requiring mathematical reasoning. We conduct experiments using LLMs fine-tuned on datasets with varying amounts of mathematical content and complexity. Our results suggest that the composition of fine-tuning data plays a significant role in shaping the mathematical abilities of LLMs. Models fine-tuned on datasets with a higher proportion of math-related content demonstrate improved performance on mathematical tasks compared to models fine-tuned on datasets with less math-related content. These findings have implications for the design of fine-tuning datasets for LLMs, highlighting the importance of incorporating diverse and relevant content to enhance their abilities in specific domains such as mathematics.",
        "Source": "GPT"
    },
    {
        "Index": 12,
        "Title": "Through the Lens of Split Vote: Exploring Disagreement, Difficulty and Calibration in Legal Case Outcome Classification.",
        "Abstract": "In legal decisions, split votes (SV) occur when judges cannot reach a unanimous decision, posing challenges in classifying case outcomes. This study examines the impact of SV on disagreement, difficulty, and calibration in legal case outcome classification. Through the lens of SV, we explore the factors influencing disagreement among judges, the difficulty of predicting case outcomes, and the calibration of classification models. Using a dataset of legal cases with SVs, we analyze the patterns and characteristics of disagreements among judges, the complexities in predicting outcomes when a unanimous decision is not reached, and the accuracy of classification models in reflecting judicial opinions. Our findings shed light on the intricate nature of legal decision-making in cases of disagreement, highlighting the importance of considering SVs in the classification of legal case outcomes. By understanding the nuances of SVs, we can improve the accuracy and reliability of legal case outcome predictions.",
        "Source": "GPT"
    },
    {
        "Index": 13,
        "Title": "Inference to the Best Explanation in Large Language Models.",
        "Abstract": "While Large Language Models (LLMs) have found success in real-world applications, their underlying explanatory process remains a topic of debate and concern. Inference to the Best Explanation (IBE) provides a framework for evaluating the credibility of competing explanations based on their explanatory power and coherence with background knowledge. This paper explores the application of IBE to LLMs, proposing a methodology for assessing the explanatory strength of generated text and predictions. By identifying the underlying reasoning processes used by LLMs, we can better understand their decision-making mechanisms and improve their transparency and accountability. We argue that incorporating IBE into the evaluation of LLMs can help address concerns related to bias, robustness, and ethical considerations, ultimately enhancing the trustworthiness of these powerful models in real-world applications. Through a combination of theoretical analysis and empirical validation, our approach offers a novel perspective on interpretability and explanation within the context of large language models.",
        "Source": "GPT"
    },
    {
        "Index": 14,
        "Title": "A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI: The First Romanian Natural Language Inference Corpus.",
        "Abstract": "Natural language inference (NLI), the task of recognizing the entailment relationship in sentence pairs, is a fundamental problem in natural language processing. In this study, we propose a novel cartography-based curriculum learning method applied on RoNLI, the first Romanian Natural Language Inference corpus. The proposed method leverages the power of curriculum learning to dynamically adjust the difficulty of training samples based on their novelty and complexity. Through this approach, we aim to improve the overall performance of NLI models by providing them with a more structured and guided learning process. Our experimental results show that the cartography-based curriculum learning method significantly outperforms traditional training approaches on the RoNLI dataset, achieving state-of-the-art results. By incorporating this novel curriculum learning technique into the training pipeline of NLI models, we can enhance their ability to accurately identify entailment relationships in sentence pairs, ultimately advancing the field of natural language understanding.",
        "Source": "GPT"
    },
    {
        "Index": 15,
        "Title": "MinPrompt: Graph-based Minimal Prompt Data Augmentation for Few-shot Question Answering.",
        "Abstract": "Recent advances in few-shot question answering (QA) mostly rely on the power of pre-trained language models such as GPT-3 and BERT. However, these models require large amounts of pre-training data and computational resources, making them less accessible for organizations with limited resources. In this paper, we propose a novel approach called MinPrompt which leverages graph-based minimal prompt data augmentation to improve few-shot QA performance. By generating minimal prompts based on the task-specific graph structure, we aim to provide a more efficient and effective way to adapt pre-trained language models for few-shot QA tasks. Our experimental results demonstrate that MinPrompt outperforms existing methods in terms of few-shot QA accuracy and computational efficiency. This suggests that leveraging graph-based minimal prompt data augmentation can be a promising direction for improving the performance of few-shot QA systems, especially for organizations with limited resources.",
        "Source": "GPT"
    },
    {
        "Index": 16,
        "Title": "SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs.",
        "Abstract": "Large language models (LLMs) have the ability to effectively integrate multiple types of data, including text documents and numerical data, to enhance information fusion capabilities. In this study, we focus on the application of LLMs in the context of sports metrics, where text and numerical data play a crucial role in understanding and analyzing athletic performance. By blending these two types of data, LLMs can provide a comprehensive and nuanced interpretation of sports-related information, enabling more accurate assessments and predictions.\n\nThrough the integration of text and numerical data, LLMs offer insights into the complexities of sports metrics, such as player statistics, game recaps, and performance analysis. This fusion of data allows for a more holistic understanding of sports-related information, leading to more informed decision-making and strategic planning in the athletic domain. Overall, the use of LLMs to blend text and numerical data has the potential to revolutionize the way we approach and analyze sports metrics, opening up new opportunities for advanced data integration and analysis techniques.",
        "Source": "GPT"
    },
    {
        "Index": 17,
        "Title": "SciMON: Scientific Inspiration Machines Optimized for Novelty.",
        "Abstract": "In this study, we investigate and improve the capacity of neural language models to produce innovative scientific pathways. We introduce SciMON - Scientific Inspiration Machines Optimized for Novelty, a novel framework designed to push the boundaries of conventional scientific idea generation. By leveraging the power of advanced neural networks, we aim to foster creativity and originality in research exploration. Through fine-tuning these models on vast amounts of scientific text data, we train them to generate fresh and inspiring directions for future studies. Our approach goes beyond traditional language model applications, focusing specifically on the generation of novel scientific insights. By optimizing for novelty, we seek to expedite the process of innovation in scientific research and propel discoveries forward. Overall, our work aims to unleash the full potential of neural language models in stimulating creativity and curiosity within the scientific community.",
        "Source": "GPT"
    },
    {
        "Index": 18,
        "Title": "Expedited Training of Visual Conditioned Language Generation via Redundancy Reduction.",
        "Abstract": "We introduce EVLGen, a streamlined framework designed for the pre-training of visually conditioned language generation. By leveraging redundancy reduction techniques, EVLGen quickly and effectively learns to generate high-quality language descriptions based on visual inputs. Traditional approaches to visual conditioned language generation often require large amounts of training data and computational resources, making them time-consuming and expensive to implement. In contrast, EVLGen efficiently learns to generate language descriptions by focusing on distilling key information from visual inputs and reducing unnecessary redundancy in the generated text. This results in faster training times and improved performance on various language generation tasks. Our experiments demonstrate that EVLGen outperforms existing methods in terms of both efficiency and quality of generated descriptions. Overall, EVLGen presents a novel approach to expedited training of visually conditioned language generation models, paving the way for more efficient and effective natural language processing systems.",
        "Source": "GPT"
    },
    {
        "Index": 19,
        "Title": "Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models.",
        "Abstract": "As the use of Large Language Models (LLMs) becomes more widespread, understanding their self-evaluation of confidence in generated outputs is crucial for ensuring their trustworthy applications. This study investigates the alignment between confidence and probability estimates in LLMs, focusing on their ability to accurately assess uncertainty levels. Through experiments and analysis, we explore how well LLMs calibrate their confidence against the actual probabilities associated with their prediction outcomes. We utilize various metrics and techniques to measure this alignment, shedding light on potential discrepancies or areas for improvement in LLMs' confidence estimation capabilities. The findings of this investigation provide valuable insights into the reliability of LLMs under different contexts and usage scenarios, with implications for the development of more robust and dependable language models. By enhancing our understanding of confidence under the hood in LLMs, we aim to foster a greater trust in their outputs and facilitate their responsible integration into various real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 20,
        "Title": "Retrieval-Augmented Multilingual Knowledge Editing.",
        "Abstract": "Knowledge represented in Large Language Models (LLMs) is often found to be inaccurate and may even deteriorate over time. In order to address this issue, Retrieval-Augmented Multilingual Knowledge Editing is proposed as a solution. This approach combines the strengths of large language models with retrieval-based techniques to enhance the accuracy and reliability of knowledge stored in LLMs. By incorporating an additional retrieval step, the model can verify and correct the information provided by the language model, resulting in more trustworthy and up-to-date knowledge. This method is particularly useful for multilingual knowledge editing, where language barriers and inconsistencies may lead to inaccuracies in the stored information. Overall, Retrieval-Augmented Multilingual Knowledge Editing offers a promising solution to improve the quality of knowledge stored in LLMs and enhance their effectiveness in various applications.",
        "Source": "GPT"
    },
    {
        "Index": 21,
        "Title": "Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge.",
        "Abstract": "Large Language Models (LLMs) have shown impressive performance on various natural language processing tasks, including the Winograd Schema Challenge. However, their success in resolving ambiguity in complex language understanding tasks can be further enhanced through the incorporation of visual information. In this paper, we introduce a novel approach to the Winograd Schema Challenge by combining language understanding with visual processing. Specifically, we propose a Visual Twist on the traditional Winograd Schema Challenge, where a visual component is introduced to provide additional context and aid in disambiguating difficult pronoun resolution tasks. We present results that demonstrate the effectiveness of our approach in improving the performance of LLMs on ambiguous language understanding tasks. Our findings suggest that incorporating visual cues into language models can significantly enhance their ability to resolve ambiguity and improve overall performance on challenging language understanding tasks.",
        "Source": "GPT"
    },
    {
        "Index": 22,
        "Title": "Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models.",
        "Abstract": "Research on Large Language Models (LLMs) has often neglected subtle biases that, although less apparent, can still have significant negative impacts. In this study, we propose the use of dual metrics for evaluating representative and affinity bias in LLMs. Representative bias refers to the unequal representation of different demographic groups in training data, leading to biased outcomes. Affinity bias, on the other hand, involves the model favoring certain groups over others based on similarities between the training data and the groups in question. These biases can perpetuate stereotypes and systemic discrimination, making it crucial to develop more nuanced measures of bias evaluation in LLMs. By incorporating dual metrics, we can better identify and address these subtle biases, ultimately leading to more fair and inclusive language models. Our findings highlight the importance of considering a wide range of biases in LLMs and developing strategies to mitigate their impact on society.",
        "Source": "GPT"
    },
    {
        "Index": 23,
        "Title": "Framing in the Presence of Supporting Data: A Case Study in U.S. Economic News.",
        "Abstract": "The mainstream media has much leeway in what it chooses to cover and how it presents information, particularly in the realm of economic news. This case study examines how framing techniques are used in the presentation of U.S. economic news, particularly in the presence of supporting data. By analyzing the language, tone, and imagery employed in news articles, this study aims to uncover the various ways in which media outlets shape public perceptions of economic issues. The findings reveal that framing plays a significant role in influencing public attitudes towards the economy, with media outlets often presenting data in a way that supports their own biases or agendas. Understanding the impact of framing in economic news is essential for media consumers to critically evaluate the information they are presented with and make informed decisions about economic policies and issues.",
        "Source": "GPT"
    },
    {
        "Index": 24,
        "Title": "Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences.",
        "Abstract": "Multimodal Large Language Models (MLLMs) have demonstrated proficiency in handling a variety of visual-language tasks. In this paper, we introduce Mementos, a comprehensive benchmark designed to evaluate MLLMs' reasoning capabilities over image sequences. By incorporating both textual and visual modalities, Mementos provides a challenging evaluation environment for assessing MLLMs' ability to understand and reason over complex visual information. Our benchmark covers a wide range of tasks, including image sequence captioning, question answering, and visual commonsense reasoning.\n\nWe evaluate several state-of-the-art MLLMs on the Mementos benchmark, providing insights into their strengths and weaknesses in multimodal reasoning. Our experiments reveal that while MLLMs excel at certain tasks, they struggle with more nuanced reasoning challenges, such as long-range temporal reasoning and context-aware image understanding. Overall, Mementos serves as a valuable resource for the research community to assess and improve the multimodal reasoning capabilities of large language models.",
        "Source": "GPT"
    },
    {
        "Index": 25,
        "Title": "TTM-RE: Memory-Augmented Document-Level Relation Extraction.",
        "Abstract": "Document-level relation extraction aims to categorize the association between any two entities within a document. In this paper, we propose a novel approach called TTM-RE (Memory-Augmented Document-Level Relation Extraction) that utilizes a memory-augmented neural network to improve the performance of document-level relation extraction tasks. Our method focuses on incorporating external knowledge in the form of memory cells, which store relevant information about entity pairs and their relationships. The memory cells are updated and accessed dynamically during the extraction process to enhance the model's ability to capture complex relations between entities.\n\nExperimental results on benchmark datasets demonstrate that our TTM-RE outperforms existing state-of-the-art methods in terms of precision, recall, and F1-score. Additionally, our method shows robustness to noisy and ambiguous data, making it a promising solution for real-world applications in information extraction tasks. Overall, TTM-RE presents a significant advancement in the field of document-level relation extraction by effectively leveraging external knowledge through memory augmentation.",
        "Source": "GPT"
    },
    {
        "Index": 26,
        "Title": "Answer is All You Need: Instruction-following Text Embedding via Answering the Question.",
        "Abstract": "This work aims to build a state-of-the-art text embedder that can effectively capture the characteristics of texts through the use of instruction-following and question-answering techniques. By incorporating both instruction-following and question-answering mechanisms, we propose a novel approach for generating text embeddings that can represent the semantic and syntactic features of the input texts in a more comprehensive and accurate manner. \n\nOur text embedder utilizes a series of pre-trained language models and neural network architectures to process the input texts and extract relevant information based on the specified instructions and questions. Through extensive experimentation and evaluation, we demonstrate that our proposed method outperforms existing text embedding techniques in various benchmark datasets and natural language processing tasks. \n\nOverall, our work showcases the importance of leveraging both instruction-following and question-answering strategies to enhance the performance of text embedders and provides a valuable contribution to the field of text representation learning.",
        "Source": "GPT"
    },
    {
        "Index": 27,
        "Title": "Explore Spurious Correlations at the Concept Level in Language Models for Text Classification.",
        "Abstract": "Language models (LMs) have achieved notable success in numerous NLP tasks, employing both fine-tuning and transfer learning strategies. However, recent studies have shown that LMs are susceptible to capturing spurious correlations in the data, which can lead to biased and unreliable predictions. In this study, we investigate spurious correlations at the concept level in language models for text classification tasks.\n\nWe first propose a method to identify and analyze concept-level spurious correlations in LMs by examining the relationships between different concepts within the model. We then conduct experiments on text classification tasks to demonstrate the impact of these spurious correlations on model performance and generalization capabilities.\n\nOur results show that concept-level spurious correlations can significantly affect the performance of LMs on text classification tasks, leading to erroneous predictions and poor generalization. By understanding and addressing these issues, we can improve the reliability and robustness of language models in NLP applications.",
        "Source": "GPT"
    },
    {
        "Index": 28,
        "Title": "Every Answer Matters: Evaluating Commonsense with Probabilistic Measures.",
        "Abstract": "Large language models have significantly advanced the field of natural language processing by achieving impressive performance on commonsense tasks. Despite their success, these models still struggle with understanding various aspects of common knowledge and everyday reasoning. This paper focuses on evaluating commonsense knowledge in large language models using probabilistic measures. We propose a novel approach to assess the reliability of commonsense predictions made by these models by calculating the probability of a given answer being correct. By assigning probabilities to each answer, we aim to provide a more nuanced understanding of the model's performance and identify areas in which improvements can be made. Our experimental results demonstrate the effectiveness of this approach in uncovering weaknesses in commonsense reasoning, ultimately emphasizing the importance of scrutinizing every answer provided by large language models. This work contributes to the ongoing effort to enhance the commonsense abilities of language models and highlights the significance of thorough evaluation in natural language understanding tasks.",
        "Source": "GPT"
    },
    {
        "Index": 29,
        "Title": "GradSafe: Detecting Jailbreak Prompts for LLMs via Safety-Critical Gradient Analysis.",
        "Abstract": "Large Language Models (LLMs) face threats from jailbreak prompts, which can compromise their security and integrity. Existing methods for detecting jailbreak prompts often struggle to accurately identify these malicious commands, putting LLMs at risk of exposure to potential security breaches. In response to this critical issue, we propose GradSafe, a novel approach for detecting jailbreak prompts in LLMs through safety-critical gradient analysis. By analyzing the gradients of LLMs during inference, GradSafe is able to identify subtle changes in the model's behavior that may indicate the presence of jailbreak prompts. Our experimental results demonstrate that GradSafe outperforms existing methods in terms of accuracy and efficiency, providing robust protection against malicious attacks on LLMs. Overall, our study highlights the importance of addressing security threats in LLMs and introduces a promising solution for detecting jailbreak prompts to safeguard the integrity and reliability of these powerful language models.",
        "Source": "GPT"
    },
    {
        "Index": 30,
        "Title": "Pouring Your Heart Out: Investigating the Role of Figurative Language in Online Expressions of Empathy.",
        "Abstract": "Empathy is a social mechanism used to support and strengthen emotional connection with others, including the ability to understand and share their feelings. In today's digital age, online expressions of empathy play a crucial role in maintaining and deepening these connections. This study explores the role of figurative language in online expressions of empathy, focusing on how metaphors, similes, and other forms of linguistic imagery are used to convey emotional support and understanding. Through a qualitative analysis of online communication examples, this research aims to uncover the nuances of figurative language in expressing empathy, shedding light on how these linguistic devices can enhance and enrich emotional connections in digital interactions. By examining the intricate interplay between language and emotion in online empathy expressions, this study contributes to a deeper understanding of the complexities of interpersonal communication in the digital era.",
        "Source": "GPT"
    },
    {
        "Index": 31,
        "Title": "An Information-Theoretic Approach to Analyze NLP Classification Tasks.",
        "Abstract": "Understanding the contribution of the inputs on the output is useful across many tasks in natural language processing (NLP) classification. In this study, we propose an information-theoretic approach to analyze NLP classification tasks. By quantifying the amount of information that each input variable provides about the output, we are able to gain insights into the importance of different features in the classification process. This approach allows us to not only identify the most informative features but also to understand how they interact with one another to influence the final classification decision. We apply this methodology to various NLP classification tasks, such as sentiment analysis and topic categorization, and demonstrate its effectiveness in providing a deeper understanding of the underlying mechanisms at play. Our results show that by leveraging information theory principles, we can improve the interpretability and performance of NLP classification models, leading to more accurate and reliable predictions.",
        "Source": "GPT"
    },
    {
        "Index": 32,
        "Title": "Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders.",
        "Abstract": "Conversational systems often rely on embedding models for intent classification and clustering tasks. However, challenges arise when these models struggle to differentiate between negations and implicatures in user queries. Negations, such as \"not interested,\" express a direct opposite of an intention, while implicatures, such as \"maybe later,\" suggest a potential intention without committing to it. This distinction is crucial for accurately understanding user intent and providing appropriate responses. In this study, we investigate the difficulties that intent encoders face in distinguishing between negations and implicatures. We propose a methodology for enhancing intent encoders' ability to discern these linguistic nuances, focusing on fine-tuning existing models and incorporating additional contextual features. By addressing these challenges, conversational systems can improve their accuracy in interpreting user intent and delivering more effective responses. Our findings shed light on the importance of linguistic subtleties in natural language processing tasks and offer insights for enhancing the performance of intent encoders in conversational systems.",
        "Source": "GPT"
    },
    {
        "Index": 33,
        "Title": "Wav2Gloss: Generating Interlinear Glossed Text from Speech.",
        "Abstract": "Wav2Gloss is a novel approach that aims to preserve endangered languages by automatically generating interlinear glossed text (IGT) from spoken language. With thousands of languages facing extinction, the loss of these languages represents a significant threat to cultural diversity and identity worldwide. Wav2Gloss addresses this challenge by leveraging recent advances in speech recognition technology to transcribe spoken language into text, and then generate interlinear glossed text that provides a linguistically meaningful and structured representation of the language. This system offers a practical and scalable solution for documenting and preserving endangered languages, enabling linguists and language researchers to analyze and study these languages before they disappear. By facilitating the creation of interlinear glossed text from speech, Wav2Gloss contributes to the ongoing efforts to safeguard linguistic diversity and heritage for future generations.",
        "Source": "GPT"
    },
    {
        "Index": 34,
        "Title": "Leveraging Codebook Knowledge with NLI and ChatGPT for Zero-Shot Political Relation Classification.",
        "Abstract": "Is it possible to accurately classify political relations within evolving event ontologies without extensive annotations? This remains a challenge in the field of natural language processing and information extraction. In this study, we propose a novel approach that leverages codebook knowledge with Natural Language Inference (NLI) and ChatGPT for zero-shot political relation classification. By integrating pre-defined codebook knowledge with state-of-the-art NLI models and generative ChatGPT language models, we aim to improve the performance of classifying political relations without the need for extensive labeled data.\n\nOur experimental results demonstrate the effectiveness of our proposed approach in accurately classifying political relations within evolving event ontologies. By exploiting the rich semantic representations learned by the NLI and ChatGPT models, we are able to achieve competitive performance compared to traditional supervised learning methods. This approach shows promise for enhancing the efficiency and effectiveness of political relation classification in real-time applications with limited annotated data.",
        "Source": "GPT"
    },
    {
        "Index": 35,
        "Title": "SPOR: A Comprehensive and Practical Evaluation Method for Compositional Generalization in Data-to-Text Generation.",
        "Abstract": "Compositional generalization is an important ability of language models and has many different manifestations. For instance, it involves the capability to combine known elements in new ways to understand and generate novel textual outputs. In the context of data-to-text generation, compositional generalization plays a critical role in ensuring the model's ability to effectively process and communicate complex information in a coherent manner. However, evaluating and quantifying this ability in language models remains a challenging task.\n\nIn this paper, we propose a novel evaluation method called SPOR (Systematic Performance Optimization through Rigorous Evaluation) for assessing compositional generalization in data-to-text generation models. SPOR offers a comprehensive and practical framework that incorporates a range of diverse linguistic tasks and datasets to provide a holistic evaluation of a model's compositional generalization abilities. Our method aims to address the limitations of existing evaluation metrics and provide a more robust and reliable assessment of a model's performance in handling compositional tasks. Through empirical experiments and analyses, we demonstrate the effectiveness and utility of SPOR in evaluating and improving compositional generalization in data-to-text generation models.",
        "Source": "GPT"
    },
    {
        "Index": 36,
        "Title": "OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following.",
        "Abstract": "Embodied Instruction Following (EIF) is a vital component of embodied learning, where agents must effectively interact with their environment to complete tasks. In this study, we focus on the analysis of LLM-Centric Agents in EIF, specifically examining the Operational-Executive (OPEx) processes involved in this task. By conducting a component-wise analysis, we aim to gain a comprehensive understanding of the cognitive mechanisms and decision-making processes that underlie successful instruction following in embodied environments.\n\nThrough our research, we identify the key factors that contribute to the effectiveness of LLM-Centric Agents in EIF, shedding light on how these agents can improve their performance in a variety of instructional contexts. By delving into the complexities of OPEx strategies, we are able to provide insights into the cognitive mechanisms that enable agents to navigate and interact within their environment, ultimately enhancing their ability to follow instructions effectively. Our findings have implications for the design and implementation of intelligent agents in embodied learning settings, paving the way for more efficient and adaptive instructional systems.",
        "Source": "GPT"
    },
    {
        "Index": 37,
        "Title": "Multimodal Instruction Tuning with Conditional Mixture of LoRA.",
        "Abstract": "Multimodal Large Language Models (MLLMs) have shown remarkable proficiency in a variety of tasks across different domains by effectively integrating information from multiple modalities. However, the performance of MLLMs can vary based on the specific task and domain. In this study, we propose a novel approach called Conditional Mixture of LoRA to tune the performance of MLLMs in a multimodal setting. By dynamically adjusting the weights of different modalities based on task-specific conditions, our method aims to enhance the overall performance and robustness of MLLMs. We conduct experiments on various multimodal tasks, including image captioning and video classification, to evaluate the effectiveness of our approach. The results demonstrate that our Conditional Mixture of LoRA method leads to significant improvements in performance compared to traditional multimodal approaches, highlighting the importance of adaptive tuning in multimodal instruction. Our findings suggest that fine-tuning multimodal models with conditional mixture strategies can further enhance their capabilities in diverse tasks and domains.",
        "Source": "GPT"
    },
    {
        "Index": 38,
        "Title": "DocLens: Multi-aspect Fine-grained Medical Text Evaluation.",
        "Abstract": "Medical text generation aims to assist with administrative work and highlight salient information to support healthcare providers in making informed decisions. However, evaluating the quality of generated medical text can be challenging due to the presence of multiple aspects and the need for fine-grained analysis. In this paper, we propose DocLens, a novel framework for multi-aspect fine-grained medical text evaluation. DocLens leverages a combination of natural language processing techniques and machine learning algorithms to assess the quality of generated medical text based on various dimensions such as relevance, accuracy, fluency, coherence, and specificity. Additionally, DocLens provides detailed feedback on areas of improvement, enabling healthcare providers to enhance the quality of generated medical text. Experimental results demonstrate the effectiveness of DocLens in identifying and addressing issues in medical text generation, thereby enhancing the overall quality of generated medical text. DocLens offers a valuable tool for healthcare providers to improve the efficiency and accuracy of medical text generation processes.",
        "Source": "GPT"
    },
    {
        "Index": 39,
        "Title": "FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability.",
        "Abstract": "This paper presents FoFo, a pioneering benchmark for evaluating large language models' (LLMs) ability to follow specific formats accurately. We propose a comprehensive set of format-following tasks, spanning various domains and styles, to assess the LLMs' capability in understanding and adhering to different formatting requirements. FoFo is designed to address the limitations of existing benchmarks, which often focus on generic language tasks without emphasizing the importance of maintaining specific formatting nuances. Through extensive experimentation on popular LLMs such as GPT-3 and BERT, we demonstrate the utility and effectiveness of FoFo in gauging the format-following capability of these models. Our results highlight the varying degrees of performance across tasks and models, shedding light on the strengths and weaknesses of LLMs in accurately replicating diverse formatting characteristics. By introducing FoFo, we aim to provide a robust framework for evaluating the format-following prowess of LLMs and inspire further advancements in this area.",
        "Source": "GPT"
    },
    {
        "Index": 40,
        "Title": "Hyper-CL: Conditioning Sentence Representations with Hypernetworks.",
        "Abstract": "While the introduction of contrastive learning frameworks in sentence representation learning has significantly contributed to the improvement of downstream natural language processing tasks, there still remains a challenge in capturing fine-grained semantic relationships between sentences. In this paper, we propose a new approach called Hyper-CL, which utilizes hypernetworks to condition sentence representations in a contrastive learning framework. By incorporating hypernetworks, we enable the generation of task-specific embeddings that can capture intricate semantic information from input sentences. Experimental results on various benchmark datasets demonstrate that our proposed Hyper-CL method outperforms existing contrastive learning approaches in tasks such as paraphrase detection and text classification. Additionally, we provide insights into the interpretability of the learned representations and showcase the effectiveness of using hypernetworks in conditioning sentence embeddings. Overall, our work highlights the importance of leveraging hypernetworks in enhancing the learning capabilities of contrastive learning frameworks for sentence representation.",
        "Source": "GPT"
    },
    {
        "Index": 41,
        "Title": "Analysis of Multi-Source Language Training in Cross-Lingual Transfer.",
        "Abstract": "The successful adaptation of multilingual language models (LMs) to a specific language-task pair critically depends on the effectiveness of cross-lingual transfer approaches. This study analyzes the benefits and challenges of utilizing multiple sources of language training data in cross-lingual transfer scenarios. By investigating the impact of varying amounts and sources of training data on model performance, our analysis highlights the importance of carefully selecting and combining diverse datasets to optimize cross-lingual transfer learning. We examine how leveraging a mixture of monolingual, bilingual, and parallel data can enhance the robustness and adaptability of multilingual LMs across different languages and tasks. Furthermore, we explore the potential for improving transfer learning outcomes through strategies such as data augmentation, domain adaptation, and fine-tuning techniques. Our findings underscore the significance of multi-source language training in facilitating effective cross-lingual transfer and offer insights for improving the performance of multilingual LMs in practical applications.",
        "Source": "GPT"
    },
    {
        "Index": 42,
        "Title": "ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions.",
        "Abstract": "We present ABEX, a novel and effective generative data augmentation methodology for low-resource Natural Language Understanding (NLU). ABEX leverages expanding abstract descriptions to augment training data, which enables models to better generalize to diverse and previously unseen examples. By generating synthetic examples with varying levels of abstraction, ABEX enriches the training set and improves the performance of NLU models on low-resource tasks.\n\nOur approach is based on the idea that abstract descriptions can capture the common patterns and underlying semantics of a given task, allowing for the generation of high-quality training examples. We demonstrate the effectiveness of ABEX on a range of low-resource NLU tasks, including sentiment analysis and named entity recognition. Experimental results show that our method significantly improves the performance of baseline models, outperforming existing data augmentation techniques.\n\nOverall, ABEX demonstrates the potential of leveraging abstract descriptions for data augmentation in low-resource NLU, offering a promising avenue for enhancing model performance in resource-constrained settings.",
        "Source": "GPT"
    },
    {
        "Index": 43,
        "Title": "The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants.",
        "Abstract": "We introduce the Belebele Benchmark, a comprehensive multi-lingual dataset designed for evaluating machine reading comprehension in 122 different language variants. The dataset consists of passages from various genres and difficulty levels, accompanied by multiple-choice questions that assess the ability of natural language processing models to comprehend and extract information from diverse linguistic contexts. Each language variant presents its own unique challenges, such as varying syntax, grammar, and vocabulary, making Belebele an ideal benchmark for cross-lingual MRC research.\n\nTo create Belebele, we leveraged existing datasets and translated passages into the target language variants, ensuring a consistent and standardized approach across all languages. Our evaluation results demonstrate the effectiveness of the dataset in measuring the performance of MRC models across different linguistic backgrounds. By providing a diverse and inclusive set of language variants, Belebele aims to facilitate the development of robust and cross-lingual MRC systems that can effectively operate in multilingual settings. We believe that Belebele will serve as a valuable resource for advancing research in the field of machine reading comprehension and promoting language diversity in NLP applications.",
        "Source": "GPT"
    },
    {
        "Index": 44,
        "Title": "Learn from Failure: Fine-tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving.",
        "Abstract": "Recent advances in Automated Theorem Proving have demonstrated the power of utilizing large language models (LLMs) for improving the efficiency and accuracy of theorem proving. In this paper, we focus on fine-tuning LLMs with trial-and-error data specifically for intuitionistic propositional logic proving. By leveraging trial-and-error data, we aim to enhance the ability of LLMs to effectively reason and prove theorems in this complex logic system. We propose a novel methodology that involves learning from failure, where the model learns from incorrect attempts at proving theorems and adjusts its reasoning process accordingly. Through this iterative process of fine-tuning with trial-and-error data, we aim to enhance the intuitionistic propositional logic proving capabilities of LLMs. Our experimental results show promising improvements in theorem proving performance, highlighting the potential of leveraging trial-and-error data for optimizing LLMs in the context of intuitionistic propositional logic proving.",
        "Source": "GPT"
    },
    {
        "Index": 45,
        "Title": "Interactive Text-to-Image Retrieval with Large Language Models: A Plug-and-Play Approach.",
        "Abstract": "In this paper, we introduce an interactive text-to-image retrieval system utilizing large language models. Our plug-and-play approach focuses on addressing dialogue-form context queries, allowing users to engage in a natural conversation with the system while requesting relevant images. By leveraging the power of pre-trained language models, we aim to enhance the user experience and improve the accuracy of image retrieval results. Our system supports a wide range of conversational queries, enabling users to specify detailed criteria and explore a diverse set of images. Through our experimentation, we demonstrate the effectiveness of our approach in generating relevant and high-quality image results in response to dialogue-based queries. Overall, our system provides a user-friendly and efficient solution for interactive text-to-image retrieval, offering a seamless and engaging experience for individuals seeking visual information through natural language interactions.",
        "Source": "GPT"
    },
    {
        "Index": 46,
        "Title": "IMBUE: Improving Interpersonal Effectiveness through Simulation and Just-in-time Feedback with Human-Language Model Interaction.",
        "Abstract": "Navigating certain communication situations can be challenging due to individuals' lack of skills and the dynamic nature of interpersonal interactions. In this study, we introduce IMBUE, a novel approach aimed at improving interpersonal effectiveness through simulation and just-in-time feedback with human-language model interaction. IMBUE leverages advanced technologies such as natural language processing and machine learning to create simulated scenarios that replicate real-world communication challenges. Participants are immersed in these scenarios, where they receive instant feedback and guidance on how to navigate various communication situations effectively. By providing personalized feedback in real time, IMBUE aims to help individuals develop and enhance their communication skills in a safe and controlled environment. This approach has the potential to revolutionize interpersonal communication training by offering interactive and engaging experiences that can be tailored to individual learning needs. The results of this study demonstrate the effectiveness of IMBUE in improving interpersonal effectiveness and overall communication skills.",
        "Source": "GPT"
    },
    {
        "Index": 47,
        "Title": "Token-wise Influential Training Data Retrieval for Large Language Models.",
        "Abstract": "Given a Large Language Model (LLM) generation, it is crucial to identify the training data that has had the most significant influence on its development. In this paper, we propose a novel approach called Token-wise Influential Training Data Retrieval for Large Language Models. Our method focuses on identifying the specific tokens within the training data that have had the most impact on the generated LLM output. By analyzing the token-wise contributions, we can gain insights into the underlying patterns and trends in the training data that have shaped the LLM's behavior.\n\nTo achieve this, we leverage state-of-the-art techniques in natural language processing and machine learning, including attention mechanisms and token importance scoring. Through extensive experiments on various large language models, we demonstrate the effectiveness of our approach in accurately retrieving token-wise influential training data. Our method provides a valuable tool for understanding and improving the training process of large language models, ultimately leading to better performance and more robust natural language generation.",
        "Source": "GPT"
    },
    {
        "Index": 48,
        "Title": "Tree-of-Counterfactual Prompting for Zero-Shot Stance Detection.",
        "Abstract": "Stance detection enables the inference of attitudes from human communication, allowing for a deeper understanding of opinions and beliefs expressed in text. Automatic stance identification has made significant advancements in recent years, with the development of various machine learning models and techniques. However, traditional approaches to stance detection often rely on labeled datasets, limiting their ability to generalize to new, unseen topics. To address this limitation, we introduce a novel approach called Tree-of-Counterfactual Prompting for Zero-Shot Stance Detection. By leveraging counterfactual prompts and a hierarchical tree structure, our model is able to effectively identify stances on new topics without the need for explicit training data. Experimental results on benchmark datasets demonstrate the effectiveness of our approach in achieving high accuracy and generalization performance in zero-shot stance detection tasks. Our proposed method represents a significant advancement in the field of stance detection, offering a more flexible and scalable solution for analyzing attitudes expressed in text across diverse topics.",
        "Source": "GPT"
    },
    {
        "Index": 49,
        "Title": "VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks.",
        "Abstract": "Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for improving user experience and efficiency in navigating online tasks. In this study, we introduce VisualWebArena, a platform designed to evaluate and compare multimodal agents on realistic visual web tasks. Our framework consists of challenging web-based scenarios that require agents to interact with websites through visual inputs, such as images and video, in addition to traditional textual data. We examine the capabilities of various agents in tasks including information retrieval, form filling, and online shopping, measuring performance based on accuracy, speed, and user satisfaction. Through comprehensive evaluations, we aim to highlight the strengths and weaknesses of different multimodal agent architectures and inform the development of more sophisticated web browsing tools. The results of our study provide valuable insights into the potential of autonomous agents in enhancing the user experience on the web and open new avenues for research in this rapidly evolving field.",
        "Source": "GPT"
    },
    {
        "Index": 50,
        "Title": "FineSurE: Fine-grained Summarization Evaluation using LLMs.",
        "Abstract": "Automated evaluation is crucial for streamlining text summarization benchmarking and model development, given the costly and time-consuming nature of manual evaluation. In this paper, we propose FineSurE, a fine-grained summarization evaluation framework utilizing Language Model-based Metrics (LLMs) for better assessing the quality of generated summaries. FineSurE addresses the limitations of existing evaluation methods by incorporating multiple levels of analysis, including surface-level features, semantic similarity, and fluency. By leveraging the power of pre-trained language models, FineSurE offers a more comprehensive and accurate evaluation of summary quality. We demonstrate the effectiveness of FineSurE through experiments on various datasets and compare its performance against existing evaluation metrics. The results show that FineSurE outperforms traditional evaluation methods in capturing the nuances and complexities of summarization tasks, providing valuable insights for both researchers and practitioners in the field of natural language processing.",
        "Source": "GPT"
    },
    {
        "Index": 51,
        "Title": "Tuning Large Multimodal Models for Videos using Reinforcement Learning from AI Feedback.",
        "Abstract": "Recent advancements in large language models have paved the way for the development of large multimodal models for processing videos. These models combine both visual and textual information to better understand and interpret the content of videos. However, tuning these large multimodal models for optimal performance can be a challenging task, as the interplay between the modalities can be complex and requires careful optimization.\n\nIn this study, we propose a novel approach for tuning large multimodal models for videos using reinforcement learning with AI feedback. By leveraging the strengths of reinforcement learning, our method can iteratively adjust the model parameters based on feedback from an AI agent, allowing for more efficient and effective tuning. We demonstrate the effectiveness of our approach through experiments on a diverse set of video datasets, showing improvements in accuracy and performance compared to traditional tuning methods.\n\nOverall, our study showcases the potential of reinforcement learning and AI feedback in optimizing large multimodal models for video processing, opening up new possibilities for enhancing video understanding and analysis in various applications.",
        "Source": "GPT"
    },
    {
        "Index": 52,
        "Title": "Prompt Refinement with Image Pivot for Text-to-Image Generation.",
        "Abstract": "For text-to-image generation, automatically refining user-provided natural language prompts into the keyword-enriched prompts favored by current models is crucial for achieving high-quality results. In this paper, we propose a novel approach called Prompt Refinement with Image Pivot (PRIP) that leverages the semantic relationships between text prompts and images to enhance the generation process. PRIP addresses the issue of vague or ambiguous prompts by extracting key keywords and refining the text using a pivot image as reference to ensure coherence and relevance. By automatically enriching the input prompts with relevant visual context, PRIP improves the overall quality and specificity of the generated images. Experimental results on benchmark datasets demonstrate that our method outperforms existing approaches in producing visually coherent and faithful images that closely align with the user's intentions. Overall, our study highlights the importance of incorporating image information into the text-to-image generation process and showcases the effectiveness of PRIP in refining prompts for enhanced image synthesis.",
        "Source": "GPT"
    },
    {
        "Index": 53,
        "Title": "Striking Gold in Advertising: Standardization and Exploration of Ad Text Generation.",
        "Abstract": "In response to the limitations of manual ad creation, significant research has been conducted in automated ad text generation. This paper explores the benefits of utilizing both standardization and exploration techniques in advertising to strike gold in generating effective ad copy. Standardization involves creating templates or guidelines to ensure consistency and brand cohesion across ad campaigns. On the other hand, exploration involves leveraging machine learning algorithms to generate unique and creative ad texts that resonate with target audiences. By combining these approaches, advertisers can optimize their ad copy generation process to improve ad performance and drive better results. This paper reviews the current state of automated ad text generation, discusses the advantages and drawbacks of standardization and exploration techniques, and provides recommendations for advertisers looking to enhance their advertising efforts through more effective ad text generation strategies.",
        "Source": "GPT"
    },
    {
        "Index": 54,
        "Title": "AbsInstruct: Eliciting Abstraction Ability from LLMs through Explanation Tuning with Plausibility Estimation.",
        "Abstract": "Abstraction ability is crucial in human intelligence as it enables individuals to extract essential features, generalize patterns, and make informed decisions based on limited information. In the field of Natural Language Processing (NLP), enhancing abstraction ability in Language Model (LM) systems has shown great potential for improving performance on various tasks such as summarization, question-answering, and natural language understanding.\n\nIn this paper, we introduce AbsInstruct, a novel framework designed to elicit abstraction ability from Language and Title Model (LLMs) through explanation tuning with plausibility estimation. By fine-tuning the explanations provided by LLMs and estimating the plausibility of generated abstractions, our method aims to enhance the model's abstract reasoning capabilities and generalize learning from specific instances to broader contexts. Experimental results demonstrate that AbsInstruct significantly improves the abstraction ability of LLMs, leading to superior performance on tasks requiring higher-level understanding and generalization. Our approach offers a promising avenue for advancing the capabilities of LLMs in NLP applications demanding abstraction and reasoning skills.",
        "Source": "GPT"
    },
    {
        "Index": 55,
        "Title": "Reflect-RL: Two-Player Online RL Fine-Tuning for LMs.",
        "Abstract": "As language models (LMs) demonstrate their capabilities in various fields, their application to tasks requiring fine-tuning has become increasingly important. In this study, we introduce Reflect-RL, a novel two-player online reinforcement learning (RL) approach for fine-tuning LMs in a collaborative setting. Reflect-RL leverages the strengths of both players to optimize the LM's performance on specific tasks, such as text generation or language understanding. \n\nThrough experimentation, we demonstrate the effectiveness of Reflect-RL in improving LM performance compared to traditional fine-tuning methods. Additionally, we explore the impact of different hyperparameters and training settings on Reflect-RL's performance, providing insights into how to best utilize this approach in practice. Our results show that Reflect-RL can significantly accelerate the fine-tuning process while maintaining high quality performance on a range of tasks. Overall, Reflect-RL offers a promising new direction for optimizing LMs in collaborative settings, opening up new opportunities for advancements in natural language processing and other related fields.",
        "Source": "GPT"
    },
    {
        "Index": 56,
        "Title": "Can ChatGPT's Performance be Improved on Verb Metaphor Detection Tasks? Bootstrapping and Combining Tacit Knowledge.",
        "Abstract": "Metaphor detection, as an important task in the field of Natural Language Processing (NLP), has been receiving sustained attention due to its relevance in understanding the nuanced meanings and expressions used in language. One particular aspect of metaphor detection involves identifying verb metaphors, which play a crucial role in conveying abstract concepts and emotions. This study explores the potential for improving the performance of ChatGPT, a state-of-the-art language model, on verb metaphor detection tasks through bootstrapping and combining tacit knowledge. By leveraging additional sources of data and incorporating implicit knowledge into the model training process, we aim to enhance ChatGPT's ability to accurately identify and interpret verb metaphors in text. Our experimental results demonstrate promising advancements in ChatGPT's performance on verb metaphor detection tasks, highlighting the effectiveness of combining multiple strategies to optimize the model's understanding of complex linguistic constructs. These findings contribute to the ongoing research efforts in enhancing NLP models for more nuanced language comprehension and interpretation.",
        "Source": "GPT"
    },
    {
        "Index": 57,
        "Title": "Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning.",
        "Abstract": "The surge in Large Language Models (LLMs) has revolutionized natural language processing by providing powerful pre-trained models that can be fine-tuned for specific tasks. However, fine-tuning these LLMs often requires large amounts of task-specific labeled data, which can be a bottleneck in practical applications where such data is limited or costly to acquire. \n\nIn this study, we propose a novel approach called Self-Distillation, which bridges the distribution gap in language model fine-tuning by leveraging the fine-tuned model itself as a teacher to distill knowledge into a smaller student model. This process allows for more efficient fine-tuning of LLMs on limited data, enabling better generalization and performance on downstream tasks.\n\nOur experimental results demonstrate that Self-Distillation significantly improves fine-tuning performance compared to traditional fine-tuning methods, especially when limited training data is available. This approach offers a promising solution for addressing the distribution gap in language model fine-tuning, making LLMs more accessible and adaptable for a wider range of applications.",
        "Source": "GPT"
    },
    {
        "Index": 58,
        "Title": "An Information Bottleneck Perspective for Effective Noise Filtering on Retrieval-Augmented Generation.",
        "Abstract": "Retrieval-augmented generation integrates the capabilities of large language models with relevant information retrieved from an external source to enhance the quality and relevance of generated text. However, noise from the retrieval process can impact the overall performance of the model. In this paper, we propose an information bottleneck perspective for effective noise filtering in retrieval-augmented generation tasks. By introducing a bottleneck mechanism that forces the model to distill only the most essential information from the retrieved knowledge, we are able to improve the quality and coherence of generated text. Our experimental results demonstrate that incorporating this mechanism leads to significant improvements in noise reduction and text generation quality compared to existing approaches. Overall, our work highlights the importance of efficiently filtering noisy information in retrieval-augmented generation settings, and provides a novel perspective for enhancing the effectiveness of these models.",
        "Source": "GPT"
    },
    {
        "Index": 59,
        "Title": "RORA: Robust Free-Text Rationale Evaluation.",
        "Abstract": "Free-text rationales play a pivotal role in explainable NLP by providing transparent justifications for model predictions. These rationales serve as a bridge between the knowledge encoded in the model and human reasoning, enabling users to understand and trust the underlying decision-making process. However, evaluating the quality and effectiveness of free-text rationales remains a significant challenge. In this paper, we propose a novel framework, RORA (Robust Free-Text Rationale Evaluation), for evaluating the robustness of free-text rationales generated by NLP models. RORA leverages a combination of similarity metrics, coherence analysis, and human judgment to assess the quality of rationales across a range of contexts and tasks. Through extensive experiments and case studies, we demonstrate the effectiveness and reliability of RORA in evaluating free-text rationales, highlighting its ability to provide valuable insights into the strengths and weaknesses of NLP models. Overall, RORA facilitates the development of more interpretable and trustworthy NLP systems by offering a reliable method for evaluating and improving free-text rationales.",
        "Source": "GPT"
    },
    {
        "Index": 60,
        "Title": "Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents.",
        "Abstract": "Current language model-driven agents often lack mechanisms for effective user participation, which is crucial given the increasing demand for personalized and interactive user experiences. In this paper, we propose a new approach towards implicit user intention understanding for language model-driven agents. By incorporating user input in the form of \"tell me more\" prompts, our model aims to bridge the gap between user expectations and agent capabilities, ultimately enhancing the user-agent interaction. We present a framework that leverages natural language processing techniques to analyze user prompts and infer underlying intentions, enabling the agent to provide more relevant and informative responses. Through a series of experiments, we demonstrate the effectiveness of our approach in improving user engagement and satisfaction with language model-driven agents. Our findings suggest that by allowing users to express their intentions explicitly, language model-driven agents can better understand and cater to individual preferences, leading to more meaningful and productive interactions.",
        "Source": "GPT"
    },
    {
        "Index": 61,
        "Title": "InstructProtein: Aligning Human and Protein Language via Knowledge Instruction.",
        "Abstract": "Large Language Models (LLMs) have revolutionized the field of natural language processing, but they fall short when it comes to understanding specialized domains such as protein sequences and structures. In this paper, we propose InstructProtein, a novel approach that aligns human language with protein language through knowledge instruction. By integrating domain-specific knowledge into LLMs, InstructProtein bridges the gap between the language of proteins and the language of humans, enabling more accurate and interpretable predictions in the realm of bioinformatics.\n\nWe demonstrate the effectiveness of InstructProtein on a variety of tasks, including protein sequence alignment, structure prediction, and function annotation. Our experimental results show that InstructProtein outperforms state-of-the-art methods in terms of both accuracy and interpretability, highlighting the potential of knowledge instruction in enhancing the capabilities of LLMs for domain-specific tasks. Overall, InstructProtein offers a promising solution for aligning human and protein language, opening up new possibilities for research and applications in the field of bioinformatics.",
        "Source": "GPT"
    },
    {
        "Index": 62,
        "Title": "ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation for Generative Large Language Models.",
        "Abstract": "In this position paper, we argue that human evaluation of generative large language models (LLMs) requires a rethinking of traditional methods. Current evaluation frameworks often struggle to capture the nuances and complexities of LLMs, leading to limited insights into model performance and capabilities. We propose the ConSiDERS framework, a comprehensive and multifaceted approach that considers key aspects such as Complexity, Similarity, Diversity, and Robustness in evaluating LLM outputs. By incorporating these dimensions, ConSiDERS aims to provide a more holistic and informative assessment of LLMs, helping researchers and practitioners better understand and improve model quality. Through case studies and discussions, we demonstrate the effectiveness of ConSiDERS in addressing the challenges of evaluating LLMs and highlight the need for a more nuanced and adaptable evaluation framework in the field. Our framework represents a significant step towards enhancing the reliability and relevance of human evaluation for generative LLMs.",
        "Source": "GPT"
    },
    {
        "Index": 63,
        "Title": "Linguistically Conditioned Semantic Textual Similarity.",
        "Abstract": "Semantic textual similarity (STS) is a fundamental NLP task that measures the semantic similarity between two texts. In recent years, a growing body of research has focused on the impact of linguistic factors on the performance of STS systems. Linguistic factors such as syntactic structure, semantic compositionality, and lexical semantics play a crucial role in determining the semantic similarity between texts. However, the relationship between linguistic factors and semantic textual similarity is complex and multifaceted.\n\nThis paper explores the role of linguistic factors in determining semantic textual similarity, focusing on how linguistic conditioning affects the performance of STS systems. We investigate the impact of syntactic and semantic features on STS tasks and propose a linguistic conditioning framework for improving the accuracy and robustness of STS systems. Our findings suggest that incorporating linguistic factors into STS models can significantly enhance their performance and provide valuable insights into the underlying mechanisms of semantic similarity.",
        "Source": "GPT"
    },
    {
        "Index": 64,
        "Title": "Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future.",
        "Abstract": "Reasoning, a fundamental cognitive process integral to human intelligence, has garnered substantial interest within artificial intelligence research. This survey explores the concept of chain of thought reasoning, a complex form of reasoning that involves navigating through enigmatic problem spaces. We analyze advances in the field, including the development of computational models and algorithms that mimic the way humans reason through interconnected concepts. Furthermore, we examine the frontiers of chain of thought reasoning, such as its application in natural language processing, cognitive psychology, and decision-making systems. Lastly, we discuss future avenues for research and development, including the integration of machine learning techniques and neural networks to enhance the efficiency and effectiveness of chain of thought reasoning in artificial intelligence systems. By shedding light on the current state of the art in chain of thought reasoning, this survey aims to inspire interdisciplinary collaboration and innovation in the field of artificial intelligence.",
        "Source": "GPT"
    },
    {
        "Index": 65,
        "Title": "TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models.",
        "Abstract": "Grasping the concept of time is a fundamental facet of human cognition, indispensable for truly understanding the world around us. In this study, we present TimeBench, a novel evaluation benchmark designed to comprehensively assess the temporal reasoning abilities of large language models. Through a series of tasks and challenges, TimeBench evaluates a model's capability to accurately process and reason about time-related information in natural language. By analyzing the performance of various state-of-the-art models on TimeBench, we provide valuable insights into the temporal reasoning capabilities of these systems. Our results highlight the varying degrees of proficiency exhibited by different models in tasks such as temporal ordering, event duration estimation, and temporal reasoning in context. Overall, TimeBench serves as a valuable tool for assessing and improving the temporal reasoning abilities of language models, ultimately advancing our understanding of how these models comprehend and reason about time in natural language contexts.",
        "Source": "GPT"
    },
    {
        "Index": 66,
        "Title": "BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering.",
        "Abstract": "Large language models (LLMs) have shown impressive reasoning capabilities in recent years, but they are still prone to factual errors due to their reliance on individual sources of knowledge. In order to address this issue, we propose BeamAggR, a novel framework that performs beam aggregation reasoning over multi-source knowledge for multi-hop question answering tasks. By aggregating information from multiple sources, BeamAggR is able to improve the accuracy of LLMs by reducing the impact of individual errors and biases. Through extensive experiments on benchmark datasets, we demonstrate that BeamAggR outperforms state-of-the-art models in multi-hop question answering tasks, achieving more accurate and reliable results. Our approach not only enhances the reasoning capabilities of LLMs, but also provides a more robust and comprehensive understanding of complex queries by leveraging diverse knowledge sources. Overall, BeamAggR represents a significant step towards improving the performance and reliability of large language models in multi-hop question answering scenarios.",
        "Source": "GPT"
    },
    {
        "Index": 67,
        "Title": "ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base.",
        "Abstract": "Analogical reasoning is a fundamental cognitive ability of humans, allowing for the understanding of relationships between concepts and the ability to apply this knowledge to new situations. Despite significant advances in natural language processing, current language models (LMs) still struggle to effectively capture and utilize analogical reasoning in their responses. In this paper, we propose ANALOGYKB, a novel approach that aims to unlock analogical reasoning in LMs by integrating a million-scale knowledge base. By incorporating a vast repository of analogical relations, our approach enhances the ability of LMs to understand and generate analogical relationships in language tasks. We conduct experimental evaluations on various benchmark datasets, demonstrating the effectiveness of our proposed method in improving analogical reasoning capabilities of LMs. Our findings highlight the importance of integrating external knowledge bases in enhancing the analogical reasoning capabilities of LMs and pave the way for further advancements in natural language understanding and generation.",
        "Source": "GPT"
    },
    {
        "Index": 68,
        "Title": "TaSL: Continual Dialog State Tracking via Task Skill Localization and Consolidation.",
        "Abstract": "In order to effectively interact with users, dialogue systems must continuously learn and adapt to new tasks and skills. This paper presents TaSL, a novel approach for continual dialog state tracking through task skill localization and consolidation. TaSL leverages task embeddings to identify relevant skills for each task and dynamically updates the dialogue state based on the user's interactions. By localizing task-specific skills, TaSL improves both the accuracy and efficiency of dialog state tracking. Furthermore, TaSL employs a consolidation mechanism to enhance the system's adaptability to new tasks, enabling seamless integration of new skills without extensive retraining. Experimental results on benchmark datasets demonstrate the effectiveness and robustness of TaSL in continual learning scenarios. Overall, this work advances the field of dialogue system development by providing a practical and efficient solution for continual skill acquisition and adaptability, which are essential for creating more engaging and responsive conversational agents.",
        "Source": "GPT"
    },
    {
        "Index": 69,
        "Title": "DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models.",
        "Abstract": "In the era of large language models, Mixture-of-Experts (MoE) is a promising architecture for managing the complex interplay of diverse knowledge sources and expertise. However, achieving ultimate expert specialization in MoE language models remains a challenging pursuit. In this paper, we propose DeepSeekMoE, a novel approach towards maximizing expert specialization within MoE models. By incorporating a hierarchical gating mechanism and an adaptive routing strategy, DeepSeekMoE aims to dynamically assign input tokens to the most relevant experts, thereby enhancing model performance and efficiency. Through extensive experiments on benchmark datasets, we demonstrate the effectiveness of DeepSeekMoE in achieving superior expert specialization and outperforming traditional MoE architectures. Furthermore, we provide insights into the mechanisms underlying DeepSeekMoE's enhanced performance, shedding light on the potential for further advancements in MoE-based language models. Our work contributes to the ongoing evolution of large language models, pushing towards the ultimate goal of expert specialization in the MoE framework.",
        "Source": "GPT"
    },
    {
        "Index": 70,
        "Title": "Grounding Language Model with Chunking-Free In-Context Retrieval.",
        "Abstract": "This paper presents a novel Chunking-Free In-Context (CFIC) retrieval approach designed for enhancing Retrieval-Augmented Generation tasks. Traditional language models often rely on chunking, which divides texts into smaller and more manageable segments for processing. However, this can lead to information loss and hinder the model's ability to maintain context and coherence during generation tasks. Our CFIC approach eliminates the need for chunking by directly retrieving and incorporating relevant information from the context, resulting in a more grounded and coherent language model.\n\nWe evaluate our CFIC retrieval approach on a series of benchmark datasets for Retrieval-Augmented Generation tasks and demonstrate significant improvements in terms of generation quality, context awareness, and response relevance compared to traditional chunking-based retrieval methods. Our results suggest that CFIC retrieval can effectively enhance language models' performance by enabling better context retention and more accurate information integration. Overall, our approach showcases the potential of chunking-free in-context retrieval in advancing the field of natural language processing.",
        "Source": "GPT"
    },
    {
        "Index": 71,
        "Title": "Advancing Abductive Reasoning in Knowledge Graphs through Complex Logical Hypothesis Generation.",
        "Abstract": "Abductive reasoning is the process of making educated guesses to provide explanations for observations. Although commonly used in everyday life, its application in knowledge graphs has been limited due to challenges in generating complex logical hypotheses. This paper proposes a method for advancing abductive reasoning in knowledge graphs through the generation of complex logical hypotheses. We introduce a framework that integrates existing knowledge in the graph with reasoning capabilities to infer possible explanations for observed data. By leveraging sophisticated algorithms and logical inference techniques, our approach allows for the generation of plausible hypotheses that can explain complex relationships within the graph. We demonstrate the effectiveness of our method through a series of experiments on real-world knowledge graphs, showing significant improvements in hypothesis generation and accuracy of abductive reasoning. Our work opens up new avenues for enhancing reasoning in knowledge graphs and contributes towards the development of more sophisticated artificial intelligence systems.",
        "Source": "GPT"
    },
    {
        "Index": 72,
        "Title": "Active Prompting with Chain-of-Thought for Large Language Models.",
        "Abstract": "The increasing scale of large language models (LLMs) brings emergent abilities to various complex tasks, revolutionizing natural language processing and artificial intelligence. This paper introduces a novel approach, called Active Prompting with Chain-of-Thought, that enhances the capabilities of LLMs by prompting the model with informative cues and guiding its thought process through a structured chain of reasoning. By actively engaging with the model during the generation process, we aim to improve the quality, coherence, and relevance of the outputs produced by LLMs, ultimately enabling more effective utilization of these powerful tools in real-world applications. Through experimental evaluation on a range of tasks, including text generation, question answering, and dialogue systems, we demonstrate the effectiveness of our proposed method in enhancing the performance of state-of-the-art LLMs. Our findings suggest that integrating active prompting and chain-of-thought reasoning can significantly enhance the capabilities of large language models and pave the way for more sophisticated and context-aware natural language processing systems.",
        "Source": "GPT"
    },
    {
        "Index": 73,
        "Title": "EasyGen: Easing Multimodal Generation with BiDiffuser and LLMs.",
        "Abstract": "We present EasyGen, an efficient model designed to enhance multimodal understanding and generation by harnessing the power of BiDiffuser and Large Language Models (LLMs). Combining the strengths of these two components, EasyGen is able to generate high-quality outputs that seamlessly integrate text and image modalities. Our model addresses the challenges of generating coherent and contextually relevant multimodal content by leveraging the discriminative capabilities of BiDiffuser for image-text alignment and the language modeling capabilities of LLMs for generating fluent and diverse text. Through extensive experiments, we demonstrate that EasyGen outperforms existing multimodal generation models in terms of both quantitative metrics and human evaluations. By bridging the gap between different modalities, EasyGen opens up new opportunities for applications in areas such as image captioning, visual storytelling, and content creation. Overall, our work showcases the potential of EasyGen in easing multimodal generation tasks and signifies a significant step forward in the field of multimodal AI research.",
        "Source": "GPT"
    },
    {
        "Index": 74,
        "Title": "Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search.",
        "Abstract": "Recent advancements in large language models have shown great potential in improving code search tasks. In this study, we propose a novel approach called the Generation-Augmented Retrieval (GAR) framework for enhancing code search using large language models. By generating exemplar code snippets during the retrieval process, GAR aims to provide more relevant and diverse search results to users. This method leverages the capabilities of large language models to understand and generate code snippets that are semantically similar to the query, thus improving the overall search experience. We demonstrate the effectiveness of the GAR framework through experiments on a large-scale code search dataset, showing significant improvements in both retrieval accuracy and diversity of search results. Our results suggest that incorporating generation-augmented retrieval methods can greatly enhance code search tasks, providing users with more accurate and varied code snippets to choose from. Overall, our proposed framework offers a simple yet effective method for utilizing large language models in code search applications.",
        "Source": "GPT"
    },
    {
        "Index": 75,
        "Title": "A Multidimensional Framework for Evaluating Lexical Semantic Change with Social Science Applications.",
        "Abstract": "Historical linguists have identified multiple forms of lexical semantic change, ranging from broad shifts in meaning to subtle nuances over time. In this paper, we present a three-dimensional framework for evaluating lexical semantic change, which combines the dimensions of directionality, magnitude, and speed. Directionality refers to the overall trajectory of semantic change, whether it be a shift towards a more general or specific meaning. Magnitude captures the extent to which a word's meaning has changed, from minor tweaks to radical transformations. Speed quantifies the pace at which semantic change occurs, whether it unfolds gradually over centuries or rapidly in response to cultural shifts. By incorporating these dimensions into our framework, we provide a comprehensive and nuanced approach to analyzing how words evolve in meaning over time. This multidimensional framework not only enhances our understanding of lexical semantic change but also offers valuable insights for social science applications, such as tracking cultural trends and examining historical discourse.",
        "Source": "GPT"
    },
    {
        "Index": 76,
        "Title": "Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal.",
        "Abstract": "Large language models (LLMs) suffer from catastrophic forgetting during continual learning, where the model tends to forget previously learned information as it learns new tasks. Conventional rehearsal-based methods, which involve storing and replaying past experiences, have been effective in mitigating this issue but are not scalable for LLMs due to their massive size and computational requirements. In this study, we propose a novel approach called Self-Synthesized Rehearsal, which addresses catastrophic forgetting in LLMs by generating synthetic examples for past tasks during training on new tasks. By utilizing the model itself to generate these examples, our method reduces the need for storing and replaying large amounts of data, making it more efficient and scalable for LLMs. Experimental results demonstrate that our approach effectively mitigates catastrophic forgetting and outperforms conventional rehearsal-based methods in terms of memory efficiency and task performance retention during continual learning tasks. Overall, our study contributes to the development of more robust and efficient continual learning techniques for large language models.",
        "Source": "GPT"
    },
    {
        "Index": 77,
        "Title": "Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency.",
        "Abstract": "Large language models (LLMs) have exhibited remarkable ability in code generation. However, generating the correct code alone is not enough; it is crucial that the generated code is also consistent and adheres to desired programming paradigms. In this paper, we propose a novel approach to enhance LLMs in coding through multi-perspective self-consistency.\n\nOur method leverages multiple sources of information, such as syntax rules, coding conventions, and contextual understanding, to ensure that the generated code is not only accurate but also semantically coherent. By incorporating these different perspectives into the training process, our model can better capture the complex nuances of coding and produce more reliable outputs.\n\nOur experimental results demonstrate that our approach significantly improves the consistency and quality of code generated by LLMs, outperforming existing methods on a variety of code generation tasks. This work contributes to advancing the capabilities of LLMs in coding and highlights the importance of incorporating multi-perspective self-consistency for enhancing their performance.",
        "Source": "GPT"
    },
    {
        "Index": 78,
        "Title": "Citation-Enhanced Generation for LLM-based Chatbots.",
        "Abstract": "Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbot systems. In this study, we propose a novel approach called Citation-Enhanced Generation for LLM-based chatbots, which leverages the power of citations to enhance the quality, coherence, and credibility of chatbot responses. By automatically generating citations from relevant sources and incorporating them into the chatbot's responses, our approach aims to improve the overall user experience and increase the trustworthiness of the information provided. We evaluate the effectiveness of our approach through a series of experiments, comparing the performance of our Citation-Enhanced Generation model with standard LLM-based chatbots. Our results show that the incorporation of citations leads to more informative and contextually relevant responses, with users rating the chatbot as more trustworthy and reliable. Overall, our study demonstrates the potential of integrating citation-enhanced generation techniques into LLM-based chatbots to enhance their performance and credibility in various conversational settings.",
        "Source": "GPT"
    },
    {
        "Index": 79,
        "Title": "Transitive Consistency Constrained Learning for Entity-to-Entity Stance Detection.",
        "Abstract": "Entity-to-entity stance detection identifies the stance between a pair of entities with a directed link. In this study, we propose a novel approach called Transitive Consistency Constrained Learning for Entity-to-Entity Stance Detection. Our method leverages the transitive relationship between entities to improve the accuracy and consistency of stance detection. By incorporating transitivity constraints into the learning process, our model is able to capture nuanced relationships and subtle nuances in the stance between entities.\n\nThrough extensive experiments on various datasets, we demonstrate that our approach outperforms existing methods in terms of accuracy and robustness. Our results show that the incorporation of transitivity constraints significantly enhances the performance of entity-to-entity stance detection, especially in scenarios where multiple entities are involved. Additionally, our approach is able to adapt to different domains and datasets, making it a versatile and effective solution for stance detection in a wide range of applications. Overall, our Transitive Consistency Constrained Learning approach represents a promising direction for improving entity-to-entity stance detection.",
        "Source": "GPT"
    },
    {
        "Index": 80,
        "Title": "Feature-Adaptive and Data-Scalable In-Context Learning.",
        "Abstract": "In-context learning (ICL), which promotes inference with several demonstrations, has become a widespread paradigm to facilitate machine learning in real-world applications. However, existing ICL methods often struggle with feature adaptability and data scalability, limiting their effectiveness in diverse and complex environments. To address these challenges, we propose a novel approach called Feature-Adaptive and Data-Scalable In-Context Learning (FADICL). FADICL leverages a combination of feature adaptation mechanisms and data-scaling techniques to enhance the robustness and flexibility of ICL algorithms. By dynamically adjusting features and scaling data based on contextual information, FADICL can effectively adapt to changing environments and accommodate varying levels of complexity. Experimental results demonstrate that FADICL outperforms traditional ICL methods in accuracy and efficiency across a wide range of tasks and datasets. Overall, FADICL provides a promising solution for improving the performance of in-context learning systems in practical settings.",
        "Source": "GPT"
    },
    {
        "Index": 81,
        "Title": "Probing the Multi-turn Planning Capabilities of LLMs via 20 Question Games.",
        "Abstract": "Large language models (LLMs) are effective at answering questions that are clearly asked. However, when it comes to multi-turn question-answering tasks such as 20 Question Games, their capabilities are still a work in progress. In this study, we investigate the multi-turn planning abilities of LLMs by evaluating their performance in 20 Question Games. We conduct experiments using various LLM architectures and training strategies to understand how well these models can handle the complexity of extended conversations and sequential decision-making.\n\nOur results show that while LLMs may struggle with maintaining coherence and consistency over multiple turns, they exhibit promising capabilities in generating relevant follow-up questions and strategizing towards a goal in the game. We also observe that fine-tuning LLMs on multi-turn dialog datasets can significantly improve their performance in 20 Question Games. Overall, our findings shed light on the strengths and limitations of LLMs in handling dynamic, interactive tasks and highlight the importance of further research in enhancing their multi-turn planning abilities.",
        "Source": "GPT"
    },
    {
        "Index": 82,
        "Title": "WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models.",
        "Abstract": "To mitigate the potential misuse of large language models (LLMs), recent research has developed watermarking techniques to detect and attribute the source of information leakage. In this paper, we introduce WaterBench, a comprehensive framework for evaluating the effectiveness and robustness of watermarks in LLMs. Our approach focuses on assessing both the defensive capabilities of watermarks against attacks and the impact on the model's performance and efficiency. We propose a systematic evaluation methodology that incorporates various metrics and scenarios to provide a holistic understanding of watermarking techniques. Through extensive experiments on different LLM architectures and datasets, we demonstrate the utility and reliability of WaterBench in accurately assessing the performance of watermarks. Our results highlight the importance of considering a wide range of factors in the evaluation of watermarking techniques to ensure their effectiveness in protecting the integrity and ownership of data in large language models.",
        "Source": "GPT"
    },
    {
        "Index": 83,
        "Title": "Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models.",
        "Abstract": "Dependency Transformer Grammars (DTGs) are a novel approach that integrates dependency structures into Transformer language models, aiming to enhance their generalization capabilities. By incorporating syntactic information such as syntax trees, DTGs provide a more structured and hierarchical representation of language, capturing dependencies between words and phrases. This allows for better contextual understanding and generation of text, leading to improved performance on various natural language processing tasks.\n\nUnlike traditional language models that rely solely on sequential token representations, DTGs consider the underlying syntactic relationships within a sentence, enabling more effective processing of complex linguistic patterns. This integration of dependency structures results in more robust and accurate predictions, especially in scenarios where syntax plays a crucial role in determining the meaning of a sentence.\n\nOverall, DTGs offer a promising avenue for advancing the capabilities of Transformer language models by incorporating syntactic dependencies and enhancing their ability to capture the nuances of natural language.",
        "Source": "GPT"
    },
    {
        "Index": 84,
        "Title": "A Non-autoregressive Generation Framework for End-to-End Simultaneous Speech-to-Any Translation.",
        "Abstract": "Simultaneous translation models play a crucial role in facilitating communication. However, existing research primarily focuses on autoregressive generation frameworks, which can result in latency issues and limit real-time applications. In this study, we propose a novel non-autoregressive generation framework for end-to-end simultaneous speech-to-any translation. Our framework achieves simultaneous translation by generating all target tokens in parallel, significantly reducing latency compared to autoregressive models. We introduce a new encoder-decoder architecture with transformer-based self-attention mechanisms that allows for efficient parallelization of target token generation. Our experimental results on multiple language pairs demonstrate that our non-autoregressive framework outperforms state-of-the-art autoregressive models in terms of translation quality and latency. Additionally, our framework can be easily integrated with different target languages, making it a versatile solution for real-time multilingual translation tasks.Overall, our study extends the capabilities of simultaneous translation models and establishes a promising direction for future research in this area.",
        "Source": "GPT"
    },
    {
        "Index": 85,
        "Title": "Probing Language Models for Pre-training Data Detection.",
        "Abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in natural language processing tasks, showcasing their potential for various applications. However, concerns have been raised regarding the potential misuse of these models to generate deceptive content or spread misinformation. In this study, we explore the use of LLMs for pre-training data detection, focusing on identifying potentially harmful or unethical content before it is disseminated. By probing the language models with diverse datasets, we aim to investigate their ability to recognize patterns associated with problematic content and develop strategies for early detection and mitigation. Our findings reveal that LLMs can effectively detect certain types of pre-training data, showing promise for enhancing content moderation efforts and safeguarding the integrity of online information. This study contributes to the growing body of research on leveraging language models for identifying and preventing the dissemination of harmful content in digital environments.",
        "Source": "GPT"
    },
    {
        "Index": 86,
        "Title": "Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding.",
        "Abstract": "The digital landscape is rapidly evolving with an ever-increasing volume of online news, emphasizing the need for advanced natural language processing models to analyze complex events over time. In this research, we propose a benchmark for analyzing temporal complex events using large language models. Our goal is to enhance the understanding of temporal relationships and context in long-form text, enabling more accurate and comprehensive event analysis. By leveraging state-of-the-art language models, we aim to capture nuanced temporal cues and dependencies, facilitating deeper insights into the evolving nature of complex events in a dynamic digital environment. Through this benchmark, we seek to evaluate the performance of existing models and spur further advancements in temporal, long-context understanding. Ultimately, our work contributes to the enhancement of information extraction and event tracking capabilities in the digital era, opening up new possibilities for analyzing and interpreting complex events with greater precision and efficiency.",
        "Source": "GPT"
    },
    {
        "Index": 87,
        "Title": "IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation.",
        "Abstract": "Large language models have demonstrated their capabilities in storyline creation and human-like character role-playing. However, existing approaches for generating controllable and interactive drama scripts often lack collaboration between directors, actors, and agents. In this study, we present IBSEN, a novel framework for Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation. IBSEN leverages the expertise of directors, actors, and agents to create more engaging and personalized drama scripts. By incorporating feedback and insights from all involved parties, IBSEN ensures that the generated scripts are not only coherent and compelling but also tailored to the specific needs and preferences of the team. Our experimental results show that IBSEN outperforms existing methods in terms of script quality, user satisfaction, and overall engagement. By bridging the gap between large language models and human collaborators, IBSEN offers a promising approach for enhancing the creativity and interactivity of drama script generation.",
        "Source": "GPT"
    },
    {
        "Index": 88,
        "Title": "Language Model Adaption for Reinforcement Learning with Natural Language Action Space.",
        "Abstract": "Reinforcement learning with natural language action space often suffers from the curse of dimensionality due to the exponentially large size of the action space. In order to mitigate this challenge and improve the efficiency of learning in such settings, language model adaptation techniques can be employed. This paper proposes a method for adapting language models within reinforcement learning frameworks, specifically focusing on environments with natural language action spaces. By incorporating language model adaptation, the agent can effectively navigate and interpret the complex action space, leading to improved performance and faster convergence. Experimental results demonstrate the effectiveness of the proposed approach in various tasks, showcasing significant improvements in learning efficiency and overall performance. Overall, this work highlights the importance of incorporating language model adaptation techniques in reinforcement learning with natural language action spaces to address the curse of dimensionality and enhance the agent's ability to effectively interact with its environment.",
        "Source": "GPT"
    },
    {
        "Index": 89,
        "Title": "Evaluating Intention Detection Capability of Large Language Models in Persuasive Dialogues.",
        "Abstract": "We investigate intention detection in persuasive multi-turn dialogs utilizing the latest Large Language Models (LLMs). Our study focuses on evaluating the capability of these LLMs in understanding and predicting the underlying intentions of speakers in persuasive conversations. By employing state-of-the-art NLP techniques and methodologies, we analyze the performance of these models in accurately detecting the intentions of speakers across various scenarios. Through a series of experiments, we compare the effectiveness of different LLMs in discerning the persuasive intents expressed by participants in dialogues. Our findings shed light on the strengths and limitations of these models in capturing nuanced intentions and provide insights into the challenges of intention detection in persuasive contexts. The results of our study have implications for the development of more robust and accurate models for understanding intentions in complex conversational settings.",
        "Source": "GPT"
    },
    {
        "Index": 90,
        "Title": "LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression.",
        "Abstract": "In long context scenarios, large language models (LLMs) face three main challenges: higher computational cost, increased memory requirements, and potential loss of performance due to information overload. To address these challenges, we propose LongLLMLingua, a novel approach that accelerates and enhances LLMs in long context scenarios through prompt compression. By identifying and extracting key information from the input prompt, LongLLMLingua significantly reduces the computational cost and memory overhead associated with processing lengthy contextual information. Additionally, our approach allows for better model performance by focusing on the most relevant and informative parts of the input, thus mitigating the impact of information overload. Experimental results demonstrate that LongLLMLingua outperforms existing methods in terms of efficiency and effectiveness, showing promising potential for improving the performance of LLMs in long context scenarios. Ultimately, our research contributes to the advancement of LLM technology, paving the way for more efficient and powerful language models in various application domains.",
        "Source": "GPT"
    },
    {
        "Index": 91,
        "Title": "Persuading across Diverse Domains: a Dataset and Persuasion Large Language Model.",
        "Abstract": "Effective persuasive dialogue requires individuals to possess the ability to engage in multi-turn conversations and strategically plan their arguments in order to successfully influence others. In this paper, we introduce a new dataset and Persuasion Large Language Model (P-LLM) that is designed to facilitate research on persuasive communication across diverse domains. The dataset consists of conversations between persuader and persuadee roles in various domains, including healthcare, education, and marketing. The P-LLM is a pre-trained language model that has been fine-tuned on the dataset to generate persuasive responses in different scenarios. By leveraging the dataset and P-LLM, researchers and practitioners can explore different strategies and approaches for improving persuasive dialogue in different contexts. This work contributes to the advancement of natural language processing research by providing a valuable resource for studying persuasion techniques and developing more effective communication strategies across diverse domains.",
        "Source": "GPT"
    },
    {
        "Index": 92,
        "Title": "HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy.",
        "Abstract": "Large Language Models (LLMs) can play a vital role in psychotherapy by adeptly handling the complex and dynamic nature of human language and emotions. In this paper, we propose the integration of cognitive reframing techniques into LLMs as a way to enhance their effectiveness in delivering psychotherapy. By leveraging cognitive reframing, LLMs can help clients reframe their negative thoughts and beliefs, leading to increased self-awareness, improved emotional regulation, and enhanced overall well-being.\n\nWe present a framework for incorporating cognitive reframing into LLMs, highlighting the potential impact on various therapeutic modalities such as Cognitive Behavioral Therapy (CBT) and Acceptance and Commitment Therapy (ACT). Through a series of case studies and experiments, we demonstrate the efficacy of this approach in facilitating therapeutic conversations and promoting positive outcomes for clients.\n\nOverall, our work showcases the potential of harnessing cognitive reframing in LLMs for psychotherapy, opening up new possibilities for personalized and accessible mental health interventions.",
        "Source": "GPT"
    },
    {
        "Index": 93,
        "Title": "Multimodal Prompt Learning with Missing Modalities for Sentiment Analysis and Emotion Recognition.",
        "Abstract": "The development of multimodal models has significantly advanced multimodal sentiment analysis and emotion recognition. However, one key challenge in this domain is the presence of missing modalities in the input data. In this paper, we propose a novel approach for multimodal prompt learning with missing modalities for sentiment analysis and emotion recognition tasks. Our method leverages the information present in the available modalities to predict the missing modalities and generate a complete representation of the input data. We introduce a multimodal prompt learning framework that incorporates both prompt-based learning and multimodal fusion techniques to effectively capture the sentiment and emotion conveyed in the input data. Experimental results on benchmark datasets demonstrate the effectiveness of our approach in handling missing modalities and improving sentiment analysis and emotion recognition performance. Our method offers a promising direction for multimodal sentiment analysis and emotion recognition tasks in real-world applications where the presence of missing modalities is common.",
        "Source": "GPT"
    },
    {
        "Index": 94,
        "Title": "An Effective Pronunciation Assessment Approach Leveraging Hierarchical Transformers and Pre-training Strategies.",
        "Abstract": "Automatic pronunciation assessment (APA) manages to quantify a second language (L2) learner’s pronunciation proficiency in a systematic and efficient manner. In this study, we propose an effective pronunciation assessment approach that leverages hierarchical transformers and pre-training strategies to accurately evaluate L2 pronunciation. The hierarchical transformers model captures phonetic and prosodic features at different levels of granularity, enabling deep and comprehensive analysis of pronunciation quality. Additionally, pre-training strategies, such as fine-tuning on a large dataset of L2 speech samples, facilitate the learning of pronunciation patterns specific to different languages and accents. We demonstrate the effectiveness of our approach through experiments on a diverse set of L2 learners and pronunciation tasks. The results indicate that our approach outperforms existing pronunciation assessment methods in terms of accuracy and consistency. Overall, our approach offers a promising solution for automatically assessing L2 pronunciation proficiency, facilitating personalized language learning and teaching.",
        "Source": "GPT"
    },
    {
        "Index": 95,
        "Title": "Detection-Correction Structure via General Language Model for Grammatical Error Correction.",
        "Abstract": "Grammatical error correction (GEC) is a crucial task that aims to improve the accuracy and fluency of written texts by making minimal edits. In this study, we propose a Detection-Correction structure utilizing a General Language Model to enhance GEC performance. The framework first detects potential grammatical errors in the input text and then corrects them using the language model's knowledge and contextual information. By leveraging the power of a general language model, our approach is able to address a wide range of grammatical errors effectively. We conducted experiments on a benchmark dataset and compared our model with existing GEC systems, demonstrating significant improvements in correction accuracy and fluency. Our findings show that our Detection-Correction structure, powered by a General Language Model, can efficiently and accurately correct grammatical errors in written texts with minimal intervention, making it a promising solution for automated GEC tasks.",
        "Source": "GPT"
    },
    {
        "Index": 96,
        "Title": "Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer.",
        "Abstract": "While recent advancements in speech language models have achieved significant progress, they face remarkable challenges in terms of efficiency and performance. In this study, we propose a Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer (GHET) to address these challenges. \n\nThe GHET model leverages a hierarchical transformer architecture that allows for better capturing of long-range dependencies in speech data and more efficient training processes. By pre-training the model on a vast amount of unlabeled speech data, GHET can effectively learn high-level representations and generate more contextually relevant speech. \n\nOur experiments demonstrate that GHET outperforms existing speech language models in terms of both accuracy and efficiency on various speech tasks. Moreover, GHET requires fewer parameters than other models, making it more memory-efficient and scalable. Overall, the proposed GHET model shows promise in advancing the field of speech language modeling by improving both performance and efficiency.",
        "Source": "GPT"
    },
    {
        "Index": 97,
        "Title": "Selene: Pioneering Automated Proof in Software Verification.",
        "Abstract": "Ensuring correctness is a pivotal aspect of software engineering. Among the various strategies available, software verification plays a crucial role in guaranteeing the reliability and safety of software systems. In recent years, the development of automated proof techniques has revolutionized the field of software verification, enabling the generation of rigorous mathematical proofs to demonstrate the correctness of software programs.\n\nOne groundbreaking tool in this realm is Selene, a pioneering automated proof system that leverages state-of-the-art techniques from formal methods and program analysis. Selene offers a user-friendly interface for specifying program properties and automatically generating proofs of their correctness. By automating the proof process, Selene significantly reduces the time and effort required for verifying software, making it an invaluable tool for software developers and engineers.\n\nIn this paper, we provide an overview of Selene and its key features, highlighting its capabilities in ensuring the reliability and safety of software systems through automated proof techniques.",
        "Source": "GPT"
    },
    {
        "Index": 98,
        "Title": "Dissecting Human and LLM Preferences.",
        "Abstract": "This study aims to dissect and compare the preferences of humans and Large Language Models (LLMs) in order to understand how their choices differ. By analyzing model responses and human preferences in various contexts, we can gain insights into the strengths and limitations of LLMs in replicating human decision-making processes. Through a series of controlled experiments and surveys, we explore the factors that influence individuals' choices and examine how LLMs interpret and prioritize information differently. Additionally, we investigate the impact of bias, personal experience, and societal norms on human and LLM preferences to identify potential areas for improvement in AI technology. Our findings shed light on the potential applications of LLMs in understanding human behavior and inform future developments in artificial intelligence research. Ultimately, this research contributes to the ongoing discourse surrounding the intersection of human cognition and AI technology, paving the way for more nuanced and sophisticated models that can better emulate human preferences.",
        "Source": "GPT"
    },
    {
        "Index": 99,
        "Title": "UniCoder: Scaling Code Large Language Model via Universal Code.",
        "Abstract": "Intermediate reasoning or acting steps have successfully improved large language models (LLMs) for handling various tasks such as text generation, translation, and conversational agents. However, the scalability of these models remains a challenge due to the computational resources required for training and inference. In this study, we propose UniCoder, a novel approach that aims to scale LLMs by utilizing a universal code that encapsulates a large corpus of text data in a compact and efficient manner. By encoding the text data into a universal code, UniCoder reduces the memory footprint and computational complexity of LLMs, enabling them to operate more efficiently on a wider range of tasks. We demonstrate the effectiveness of UniCoder on multiple benchmark datasets and show that it outperforms existing state-of-the-art LLMs in terms of both performance and efficiency. Our results suggest that UniCoder has the potential to revolutionize the field of natural language processing by enabling the development of more scalable and powerful language models.",
        "Source": "GPT"
    },
    {
        "Index": 100,
        "Title": "AoE: Angle-optimized Embeddings for Semantic Textual Similarity.",
        "Abstract": "Text embedding is pivotal in semantic textual similarity (STS) tasks, which are crucial components in various natural language processing applications. In this paper, we propose a novel angle-optimized embedding (AoE) approach for enhancing semantic textual similarity measurement. AoE leverages cosine similarity between embeddings to adjust the geometric angle between vectors, promoting better discrimination of semantic information. We evaluate the effectiveness of AoE on benchmark STS datasets, showing superior performance compared to traditional embedding methods such as Word2Vec and GloVe. Additionally, we conduct experiments across different languages and domains to demonstrate the robustness and generalizability of AoE. Our results indicate that AoE outperforms existing approaches in capturing semantic similarity across diverse text pairs. Overall, AoE offers a promising solution for improving STS tasks by optimizing the geometric relationship between text embeddings, leading to more accurate and reliable semantic similarity measurements. Our approach has the potential to benefit a wide range of natural language processing applications requiring semantic text understanding.",
        "Source": "GPT"
    },
    {
        "Index": 101,
        "Title": "InCharacter: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews.",
        "Abstract": "Role-playing agents (RPAs), powered by large language models, have emerged as a flourishing field of research with applications in various domains such as customer service, education, and entertainment. However, the effectiveness of RPAs in portraying realistic and consistent personalities remains a crucial challenge. This study proposes a novel approach to evaluating personality fidelity in RPAs through psychological interviews. By engaging RPAs in interactive conversations that simulate real-world scenarios, we aim to assess their ability to maintain a coherent and authentic personality throughout the dialogue. We present a framework for analyzing the interview transcripts, focusing on linguistic cues, emotional responses, and consistency in personality traits. Through a series of experiments involving human participants and RPAs with varying levels of personality fidelity, we demonstrate the potential of psychological interviews as a reliable method for evaluating the authenticity of RPAs. Our findings shed light on the strengths and limitations of current RPAs and pave the way for future advancements in creating more believable and engaging virtual characters.",
        "Source": "GPT"
    },
    {
        "Index": 102,
        "Title": "Does DetectGPT Fully Utilize Perturbation? Bridging Selective Perturbation to Fine-tuned Contrastive Learning Detector would be Better.",
        "Abstract": "The burgeoning generative capabilities of large language models (LLMs) have raised growing concerns about abuse, particularly in the context of generating deceptive or harmful content. DetectGPT is a state-of-the-art model designed to detect such malicious inputs through selective perturbation techniques. However, there is a need to fully utilize perturbation in order to enhance the model's performance and robustness. This paper proposes bridging selective perturbation to fine-tuned contrastive learning to create a more effective detector. By incorporating fine-tuned contrastive learning, the model can learn to better discern between malicious and benign inputs, ultimately improving its detection capabilities. The proposed approach aims to address the limitations of DetectGPT and provide a more advanced solution for detecting potentially harmful content generated by LLMs. By combining selective perturbation with fine-tuned contrastive learning, this new model has the potential to better safeguard against abuse of LLMs in various contexts.",
        "Source": "GPT"
    },
    {
        "Index": 103,
        "Title": "AFaCTA: Assisting the Annotation of Factual Claim Detection with Reliable LLM Annotators.",
        "Abstract": "With the rise of generative AI, automated fact-checking methods to combat misinformation are becoming more advanced. However, one of the major challenges in fact-checking algorithms is the reliable annotation of factual claims. In this paper, we propose AFaCTA (Assisting the Annotation of Factual Claim Detection with Reliable LLM Annotators), a framework that leverages Large Language Models (LLMs) to assist in the annotation process. Our approach incorporates LLMs as annotators to generate reliable annotations for factual claims, reducing the burden on human annotators and improving the efficiency and accuracy of the annotation process. We demonstrate the effectiveness of AFaCTA through experiments on a dataset of factual claims, showing that our framework achieves high levels of accuracy in claim detection. By combining the power of generative AI with human annotation, AFaCTA provides a scalable and reliable solution for enhancing fact-checking processes in combating misinformation.",
        "Source": "GPT"
    },
    {
        "Index": 104,
        "Title": "Towards Faithful and Robust LLM Specialists for Evidence-Based Question-Answering.",
        "Abstract": "Advances towards more faithful and traceable answers of Large Language Models (LLMs) are crucial for improving the reliability and credibility of evidence-based question-answering systems. In this paper, we discuss the importance of developing LLM specialists that prioritize faithfulness and robustness in generating responses to queries. By focusing on the accuracy and trustworthiness of outputs from LLMs, we aim to enhance the overall performance of question-answering systems, particularly in high-stakes situations where erroneous information can have serious consequences. We propose a framework for training LLM specialists that emphasizes the importance of ethical considerations, transparency, and accountability in the data-driven decision-making process. Through a combination of technical advancements and ethical guidelines, we believe that it is possible to create more reliable and trustworthy LLM specialists that can provide accurate and comprehensive answers to a wide range of queries. Ultimately, our goal is to promote the development of LLM specialists that prioritize fidelity and robustness in order to ensure the integrity and effectiveness of evidence-based question-answering systems.",
        "Source": "GPT"
    },
    {
        "Index": 105,
        "Title": "LoRAMoE: Alleviating World Knowledge Forgetting in Large Language Models via MoE-Style Plugin.",
        "Abstract": "Supervised fine-tuning (SFT) is a crucial step for large language models (LLMs), enabling them to adapt to specific tasks and improve performance. However, one of the main challenges faced by LLMs is forgetting previously learned knowledge when fine-tuning on new tasks. In this paper, we propose LoRAMoE, a novel approach to alleviate world knowledge forgetting in LLMs during fine-tuning by incorporating a Mixture of Experts (MoE) style plugin. LoRAMoE leverages the expertise of multiple sub-networks specialized in different areas of knowledge, allowing the LLM to retain and recall world knowledge more effectively. Through extensive experimentation, we demonstrate that our approach significantly outperforms existing methods in retaining world knowledge and achieving higher task performance. By mitigating forgetting and enhancing knowledge retention, LoRAMoE paves the way for LLMs to become more versatile and adaptable in handling a wide range of tasks without sacrificing performance.",
        "Source": "GPT"
    },
    {
        "Index": 106,
        "Title": "Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation.",
        "Abstract": "Despite showing impressive abilities, large language models (LLMs) often struggle with factual inaccuracies, i.e., \"hallucinations\". These inaccuracies pose a significant challenge for LLMs as they are utilized for various natural language processing tasks where factual correctness is crucial. In this paper, we propose a self-alignment mechanism for factuality in LLMs to mitigate hallucinations. Our approach involves self-evaluation by the LLM itself, where it assesses the accuracy of its generated outputs against external knowledge bases and fact-checking resources. By leveraging this self-alignment process, the LLM can identify and correct factual inaccuracies, thereby improving the overall reliability and trustworthiness of its outputs. We experimentally evaluate our proposed approach on several benchmark datasets and demonstrate its effectiveness in reducing hallucinations in LLMs. Our results show that self-evaluation for factuality can significantly enhance the performance of LLMs in maintaining factual accuracy, highlighting the importance of self-alignment mechanisms in mitigating hallucinations.",
        "Source": "GPT"
    },
    {
        "Index": 107,
        "Title": "M-RAG: Reinforcing Large Language Model Performance through Retrieval-Augmented Generation with Multiple Partitions.",
        "Abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant memories from an external knowledge source, significantly improving the quality and diversity of generated text. In this paper, we introduce M-RAG, a novel approach that further boosts LLM performance by incorporating multiple partitions within the retrieval process. By partitioning the external knowledge source into distinct subsets, M-RAG can more effectively retrieve contextually relevant information, resulting in more accurate and coherent text generation. We conduct extensive experiments on various benchmark datasets to demonstrate the effectiveness of M-RAG in enhancing LLM performance compared to existing methods. Our results show that M-RAG achieves state-of-the-art performance in terms of both language generation quality and relevance to the input prompt. Overall, our study highlights the significant potential of leveraging multiple partitions in the retrieval-augmented generation process to further advance the capabilities of Large Language Models.",
        "Source": "GPT"
    },
    {
        "Index": 108,
        "Title": "AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension.",
        "Abstract": "Recently, instruction-following audio-language models have received broad attention for human-audio interaction. However, the absence of standardized benchmarks hinders the fair comparison and evaluation of these models. In response to this need, we introduce AIR-Bench, a benchmarking framework specifically designed for evaluating large audio-language models based on generative comprehension tasks. AIR-Bench comprises a diverse set of audio-language tasks that require the model to understand and generate spoken instructions accurately. These tasks cover a range of complexity levels, from basic comprehension to more advanced reasoning and inference. By using AIR-Bench, researchers and developers can effectively assess the performance of their audio-language models in a standardized and systematic manner. We provide an open-source implementation of AIR-Bench, along with pre-trained models and evaluation metrics, to facilitate the research and development of instruction-following audio-language models. Through the use of AIR-Bench, we aim to foster progress in the field of human-audio interaction and drive innovation in audio-language model development.",
        "Source": "GPT"
    },
    {
        "Index": 109,
        "Title": "Navigating the Metrics Maze: Reconciling Score Magnitudes and Accuracies.",
        "Abstract": "Over the past decade, the field of machine translation research has evolved significantly, with BLEU emerging as a dominant metric for evaluating translation quality. However, as research in this field has progressed, the limitations of relying solely on BLEU have become increasingly apparent. This paper explores the complexities of navigating the metrics maze in machine translation research, focusing on the reconciliation of score magnitudes and accuracies. By examining the strengths and weaknesses of various evaluation metrics, including BLEU, ROUGE, and METEOR, we aim to shed light on the challenges faced by researchers in accurately measuring translation quality. Additionally, we propose practical strategies for effectively reconciling score magnitudes and accuracies, ensuring a more comprehensive and nuanced understanding of translation performance. Ultimately, this analysis highlights the need for a more nuanced approach to evaluating machine translation systems, one that takes into account the subtleties and complexities of language translation.",
        "Source": "GPT"
    },
    {
        "Index": 110,
        "Title": "ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models.",
        "Abstract": "Large Language Models (LLMs) are transforming diverse fields and gaining increasing influence as human proxies. However, evaluating the true capabilities and ethical implications of these models remains a challenge. In this study, we propose ValueBench, a framework aimed at comprehensively evaluating the value orientations and understanding of LLMs. ValueBench goes beyond traditional performance metrics by considering not only the accuracy of generated text but also the alignment of the values expressed. By doing so, we can better assess the potential societal impact of LLMs and identify areas for improvement. Through ValueBench, researchers and developers can gain a more nuanced understanding of the ethical implications of LLMs and make informed decisions about their deployment. Ultimately, our goal is to promote the responsible development and use of LLMs by providing a robust framework for evaluating their value orientations and understanding.",
        "Source": "GPT"
    },
    {
        "Index": 111,
        "Title": "DM-BLI: Dynamic Multiple Subspaces Alignment for Unsupervised Bilingual Lexicon Induction.",
        "Abstract": "The unsupervised bilingual lexicon induction (BLI) task aims to find word translations between languages without the need for parallel corpora. In this paper, we propose a novel approach, Dynamic Multiple Subspaces Alignment (DM-BLI), for unsupervised BLI. Our method leverages the power of multiple subspaces to capture various linguistic nuances and improve the alignment accuracy. By dynamically learning and updating the subspaces during the alignment process, our model adapts to the inherent complexity and variability of language data. We evaluate DM-BLI on several language pairs and demonstrate its effectiveness in accurately identifying word translations. Compared to existing BLI methods, our approach achieves superior performance by effectively leveraging multiple subspaces and capturing a wider range of semantic and syntactic relationships between words. Overall, our proposed DM-BLI method offers a promising solution for unsupervised bilingual lexicon induction, providing a more robust and accurate framework for cross-lingual word translation tasks.",
        "Source": "GPT"
    },
    {
        "Index": 112,
        "Title": "SparseFit: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations.",
        "Abstract": "Models that generate natural language explanations (NLEs) for their predictions have recently gained increasing interest due to their interpretability and transparency. However, training these models typically requires a large amount of labeled data, which can be costly and time-consuming to acquire. In this work, we propose SparseFit, a few-shot prompting approach with sparse fine-tuning, to jointly generate predictions and NLEs with limited training data. By leveraging sparse training examples and utilizing prompt-based learning, SparseFit is able to effectively learn from minimal training data while achieving competitive performance compared to fully supervised models. We conduct experiments on various datasets and tasks to demonstrate the effectiveness of SparseFit in generating accurate predictions and coherent NLEs with limited labeled data. Our results show that SparseFit outperforms baseline approaches in few-shot settings and significantly reduces the annotation burden required for training NLE models. Overall, SparseFit offers a promising solution for efficiently training NLE models in low-resource scenarios.",
        "Source": "GPT"
    },
    {
        "Index": 113,
        "Title": "Handling Ambiguity in Emotion: From Out-of-Domain Detection to Distribution Estimation.",
        "Abstract": "The subjective perception of emotion often leads to inconsistent labels from human annotators, making emotion detection a challenging task. In this study, we address the issue of handling ambiguity in emotion detection, specifically focusing on out-of-domain detection and distribution estimation. We propose a novel approach that combines machine learning algorithms with natural language processing techniques to improve the accuracy of emotion detection in ambiguous contexts. Our method involves identifying utterances lacking clear emotional cues and effectively estimating the distribution of emotions present in a given text. By leveraging this approach, we aim to provide a more nuanced understanding of emotion in natural language, allowing for more accurate and reliable emotion detection in a variety of contexts. Our experimental results demonstrate the effectiveness of our approach in handling ambiguity in emotion detection and highlight the importance of considering distribution estimation in improving emotion detection accuracy. Overall, our study contributes to the advancement of emotion detection technology and provides valuable insights for researchers and practitioners in the field.",
        "Source": "GPT"
    },
    {
        "Index": 114,
        "Title": "REANO: Optimising Retrieval-Augmented Reader Models through Knowledge Graph Generation.",
        "Abstract": "Open domain question answering (ODQA) is a challenging task that aims to answer questions based on knowledge derived from an external corpus. One approach to tackle this problem is through the use of Retrieval-Augmented Reader (ReA) models, which integrate retriever components to provide relevant information from a large document collection for question answering. However, existing ReA models often struggle to effectively retrieve relevant information due to limitations in the retrieval process. In this paper, we propose a novel approach, REANO, for optimising ReA models through the generation of a knowledge graph. By representing the information from the external corpus in a structured graph format, REANO enhances the retrieval process by providing a more organised and contextually rich representation of knowledge. We demonstrate the effectiveness of our approach through experiments on benchmark datasets, showing that REANO significantly improves the performance of ReA models in open domain question answering tasks. Our work contributes to advancing the state-of-the-art in ODQA systems by enhancing the retrieval process through knowledge graph generation.",
        "Source": "GPT"
    },
    {
        "Index": 115,
        "Title": "Learning Disentangled Semantic Spaces of Explanations via Invertible Neural Networks.",
        "Abstract": "Disentangled latent spaces usually have better semantic separability and geometrical properties, which leads to better interpretability and generalization in machine learning tasks. In this paper, we propose a method for learning disentangled semantic spaces of explanations using invertible neural networks. By leveraging the invertibility property of neural networks, our model can generate explanations that are both semantically meaningful and disentangled, capturing specific features independently. This allows for a more interpretable and accurate representation of explanations, enabling better decision-making in various applications such as natural language processing and image recognition. We demonstrate the effectiveness of our approach on several benchmark datasets, showing improved performance compared to existing methods in terms of semantic separability and explainability. Overall, our work contributes to the advancement of disentangled representation learning, providing a valuable tool for understanding and leveraging the underlying structure of complex data for improved machine learning outcomes.",
        "Source": "GPT"
    },
    {
        "Index": 116,
        "Title": "MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation.",
        "Abstract": "A story premise succinctly defines a story’s main idea, foundation, and trajectory. It serves as the essential blueprint upon which a narrative is built, guiding the development of characters, conflicts, and plot progression. In the realm of automatic story generation, crafting compelling story premises can be a challenging task, often requiring a delicate balance of creativity and structure.\n\nThis paper introduces MoPS, a novel approach to Modular Story Premise Synthesis for Open-Ended Automatic Story Generation. MoPS leverages a modular design framework to facilitate the seamless integration of various narrative elements, allowing for the dynamic generation of diverse and engaging story premises. By breaking down the story premise generation process into manageable modules, MoPS enables greater flexibility and customization, empowering users to tailor their generated stories to specific themes, genres, and styles.\n\nThrough experimental evaluations and case studies, we demonstrate the effectiveness and versatility of MoPS in generating high-quality story premises that inspire rich and immersive narratives. With its modular approach and open-ended capabilities, MoPS represents a promising advancement in automatic story generation technology.",
        "Source": "GPT"
    },
    {
        "Index": 117,
        "Title": "Open-Set Semi-Supervised Text Classification via Adversarial Disagreement Maximization.",
        "Abstract": "Open-Set Semi-Supervised Text Classification (OSTC) aims to train a classification model on a limited labeled dataset while utilizing an abundant unlabeled dataset. In this paper, we propose a novel approach for OSTC using Adversarial Disagreement Maximization (ADM) to enhance model performance. The ADM framework leverages the disagreement between multiple models to encourage the model to make more informed decisions on uncertain instances. By maximizing the uncertainty and ambiguity in the classification process, our approach improves the model's ability to distinguish between known classes and unknown classes in open-set scenarios. Experimental results on benchmark text classification datasets demonstrate that our ADM-based OSTC approach outperforms existing methods, particularly in scenarios with limited labeled data and a large pool of unlabeled data. Our proposed framework not only achieves higher accuracy but also provides insights into the mechanism of semi-supervised learning in text classification tasks. Overall, ADM shows promise as an effective strategy for enhancing open-set semi-supervised text classification performance.",
        "Source": "GPT"
    },
    {
        "Index": 118,
        "Title": "ToolSword: Unveiling Safety Issues of Large Language Models in Tool Learning Across Three Stages.",
        "Abstract": "Tool learning is widely acknowledged as a foundational approach for deploying large language models (LLMs) in various applications. However, the safety issues associated with utilizing LLMs for tool learning across different stages have not been thoroughly explored. This study aims to address this gap by examining the safety concerns of utilizing LLMs in tool learning across three stages: pre-training, fine-tuning, and deployment.\n\nWe conducted an analysis of the potential risks and challenges that may arise during each stage of tool learning with LLMs. Our findings highlight the importance of ensuring transparency, accountability, and fairness in the development and deployment of LLMs for tool learning. Furthermore, we identify key areas for improvement in current practices to mitigate safety issues associated with LLMs in tool learning.\n\nOverall, our research sheds light on the safety implications of utilizing LLMs in tool learning and provides insights for future research and development in this field.",
        "Source": "GPT"
    },
    {
        "Index": 119,
        "Title": "A synthetic data approach for domain generalization of NLI models.",
        "Abstract": "Natural Language Inference (NLI) remains an important benchmark task for Large Language Models (LLMs) as it tests their ability to understand and reason with natural language. However, the performance of NLI models often deteriorates when applied to new domains due to domain-specific biases in the training data. In this paper, we propose a novel approach using synthetic data to improve the domain generalization of NLI models. By generating diverse and representative synthetic data from multiple domains, we aim to enhance the model's ability to generalize across different domains. Our experimental results demonstrate that incorporating synthetic data during training significantly improves the domain generalization performance of NLI models compared to traditional training methods. This approach not only addresses the issue of domain shift but also increases the robustness and effectiveness of NLI models in handling real-world scenarios with varying domains. The incorporation of synthetic data provides a practical solution for improving the generalization capacity of NLI models and advancing the field of natural language understanding.",
        "Source": "GPT"
    },
    {
        "Index": 120,
        "Title": "Enhancing Contrastive Learning with Noise-Guided Attack: Towards Continual Relation Extraction in the Wild.",
        "Abstract": "Continual relation extraction (CRE) is a fundamental principle in natural language processing that requires adapting to emerging novel relations while preserving existing knowledge. In this study, we propose a novel approach to enhancing contrastive learning with noise-guided attack techniques to achieve more robust and efficient continual relation extraction in real-world scenarios. By introducing controlled noise into the training process, our method is able to simulate the challenging conditions of continual learning and improve the model's ability to adapt to new relations while maintaining a high level of accuracy on previously learned relations. Through extensive experiments on various benchmark datasets, we demonstrate that our noise-guided attack approach significantly outperforms traditional contrastive learning methods in terms of both accuracy and adaptability to changing data distributions. This research represents a significant advancement towards achieving continual relation extraction in complex and dynamic environments, such as social media or news articles, where relations are constantly evolving.",
        "Source": "GPT"
    },
    {
        "Index": 121,
        "Title": "LRQuant: Learnable and Robust Post-Training Quantization for Large Language Models.",
        "Abstract": "Post-training quantization (PTQ) for large language models (LLMs) significantly accelerates model inference and relieves memory constraints by reducing the precision of model weights and activations. However, conventional PTQ methods often struggle to balance between model efficiency and degradation in performance, particularly for complex tasks such as natural language processing. In this paper, we propose LRQuant, a Learnable and Robust PTQ method specifically designed for large language models. LRQuant incorporates a learnable quantization approach that adaptively adjusts quantization levels during the training process, enabling the model to optimize performance under reduced precision constraints. Furthermore, LRQuant includes robustness mechanisms to mitigate performance degradation caused by quantization errors, ensuring the model maintains high accuracy despite lower precision. Experimental results on benchmark language modeling datasets demonstrate that LRQuant outperforms existing PTQ methods in terms of both model efficiency and robustness, making it a promising solution for deploying large language models in resource-constrained environments.",
        "Source": "GPT"
    },
    {
        "Index": 122,
        "Title": "VariErr NLI: Separating Annotation Error from Human Label Variation.",
        "Abstract": "Human label variation arises when annotators assign different labels to the same item for valid reasons, such as subjective interpretation or ambiguity in the data. Current Natural Language Inference (NLI) datasets often exhibit label variation, which can affect the performance of NLI models. In this work, we propose VariErr NLI, a method to separate annotation error from human label variation in NLI datasets. By analyzing the consistency of labels assigned by multiple annotators, we are able to identify and correct annotation errors, while preserving valid instances of label variation. This method allows for a more accurate evaluation of NLI models, as it ensures that the labels in the dataset are reliable and consistent. We evaluate our approach on several popular NLI datasets and show that it effectively filters out annotation errors, leading to improved model performance. VariErr NLI provides a valuable tool for researchers working with NLI data, enabling them to distinguish between genuine label variation and annotation errors.",
        "Source": "GPT"
    },
    {
        "Index": 123,
        "Title": "Benchmarking Knowledge Boundary for Large Language Models: A Different Perspective on Model Evaluation.",
        "Abstract": "In recent years, substantial advancements have been made in the development of large language models, leading to their widespread adoption in various applications. However, evaluating the performance of these models remains a challenging task, with traditional benchmarks often falling short in capturing the full extent of their capabilities. This paper proposes a novel approach to model evaluation by introducing the concept of benchmarking knowledge boundaries for large language models. By expanding the scope of evaluation to include a diverse range of linguistic phenomena and knowledge domains, this new perspective offers a more comprehensive understanding of a model's capacity for contextual understanding and knowledge integration. Through a series of experiments and evaluations, we demonstrate the effectiveness of this approach in uncovering the strengths and limitations of large language models, providing valuable insights for future development and deployment. Ultimately, this alternative perspective on model evaluation aims to push the boundaries of current benchmarks and drive innovation in the field of natural language processing.",
        "Source": "GPT"
    },
    {
        "Index": 124,
        "Title": "ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval.",
        "Abstract": "We propose ListT5, a novel reranking approach based on Fusion-in-Decoder (FiD) that enhances the performance of zero-shot retrieval tasks by efficiently handling multiple candidate lists. Our approach leverages the powerful pre-trained T5 model to encode and rank candidate lists through a fusion mechanism in the decoder. By integrating information from multiple candidates at the decoder level, ListT5 effectively captures the semantic relationships among documents and generates more accurate rankings. We conduct extensive experiments on various benchmark datasets, demonstrating that ListT5 consistently outperforms existing reranking approaches in terms of retrieval accuracy. Furthermore, our approach significantly improves zero-shot retrieval performance, showcasing its capability to generalize across different domains without requiring training data in those domains. Overall, ListT5 offers a promising solution for enhancing retrieval tasks by seamlessly integrating FiD and leveraging the strengths of pre-trained models like T5.",
        "Source": "GPT"
    },
    {
        "Index": 125,
        "Title": "Exploring the Potential of Large Language Models in Computational Argumentation.",
        "Abstract": "Computational argumentation has become an essential tool in various domains, including law, public policy, and academia. In recent years, large language models (LLMs) have shown significant potential in advancing the field of computational argumentation. These models, such as GPT-3 and BERT, have the capability to generate coherent and contextually relevant arguments, leading to more effective communication and decision-making processes.\n\nOne of the key advantages of LLMs in computational argumentation is their ability to analyze complex and diverse sources of information to support a given claim or counter-argument. This can help in detecting biases, identifying fallacies, and improving the overall quality of argumentation. Additionally, LLMs can assist in automating various stages of argumentation, such as summarizing arguments, generating rebuttals, and evaluating the strength of arguments.\n\nOverall, the potential of LLMs in computational argumentation is vast and holds promise for enhancing the efficiency and effectiveness of argumentation processes across different domains. Further research and development in this area can lead to novel applications and advancements in the field of computational argumentation.",
        "Source": "GPT"
    },
    {
        "Index": 126,
        "Title": "TaxoLLaMA: WordNet-based Model for Solving Multiple Lexical Semantic Tasks.",
        "Abstract": "In this paper, we explore the capabilities of Lexical-Semantic Language Models (LLMs) in capturing and leveraging lexical-semantic knowledge from WordNet, a large lexical database of the English language. We propose TaxoLLaMA, a novel model that utilizes pre-trained LLMs to solve multiple lexical-semantic tasks, such as word sense disambiguation, semantic similarity, and taxonomy construction. By fine-tuning LLMs on WordNet data, TaxoLLaMA demonstrates impressive performance on these tasks, outperforming traditional methods in capturing subtle nuances and intricate relationships between words. Our approach not only showcases the effectiveness of LLMs in capturing rich lexical-semantic information but also highlights the importance of leveraging external knowledge resources like WordNet to enhance the capabilities of language models. Through experimental evaluations and analysis, we provide insights into the strengths and limitations of TaxoLLaMA, shedding light on the potential of leveraging WordNet for improving the performance of LLMs on various lexical-semantic tasks.",
        "Source": "GPT"
    },
    {
        "Index": 127,
        "Title": "CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning.",
        "Abstract": "The sequential process of conceptualization and instantiation is essential to generalizable commonsense reasoning as it allows for the development of diverse and robust representations of knowledge. In this paper, we propose a novel approach to this process, called CANDLE, which leverages large language models to iteratively refine and distill concepts and instances for commonsense reasoning tasks. Through a series of experiments, we demonstrate the effectiveness of CANDLE in enhancing the performance of various commonsense reasoning models across different datasets and tasks. By dynamically adapting to the complexity and ambiguity of real-world scenarios, CANDLE enables more accurate and coherent reasoning outcomes. Moreover, the iterative nature of our approach ensures that the resulting conceptualizations and instantiations are continuously updated and refined, leading to improved generalization capabilities. Overall, our work advances the state-of-the-art in commonsense reasoning by providing a principled framework for conceptualization and instantiation that is both efficient and effective in leveraging the power of large language models.",
        "Source": "GPT"
    },
    {
        "Index": 128,
        "Title": "MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter.",
        "Abstract": "Parameter-Efficient Fine-tuning (PEFT) has been successful in enabling the fine-tuning of Large Language Models (LLMs) with limited computational resources. However, this approach still requires a significant amount of memory to store the weights of the entire model during training. To address this issue, we propose Memory-Efficient Fine-Tuning through Sparse Adapter (MEFT), a novel technique that reduces the memory footprint of the fine-tuning process.\n\nMEFT introduces sparse adapters, which are lightweight modules that connect the pre-trained LLM to the task-specific layers. By utilizing sparse adapters, only a small fraction of the original model parameters need to be stored in memory, significantly reducing the memory requirements of fine-tuning. Experimental results on a range of tasks demonstrate that MEFT achieves comparable performance to PEFT while significantly reducing memory usage. Our approach opens up new possibilities for fine-tuning LLMs on devices with constrained memory resources, enabling a wider range of applications for these powerful models.",
        "Source": "GPT"
    },
    {
        "Index": 129,
        "Title": "Surgical Feature-Space Decomposition of LLMs: Why, When and How?",
        "Abstract": "Low-rank approximations of the weight and feature space have been shown to significantly improve the performance of deep learning models. In this study, we propose a novel approach for decomposing the feature space of Large Language Models (LLMs) to enhance their effectiveness in surgical applications. By decomposing the feature space into low-rank representations, we aim to reduce the computational complexity and memory requirements of LLMs, while maintaining or even improving their performance.\n\nIn this paper, we discuss the importance of feature-space decomposition for LLMs, outlining the motivations, benefits, and potential drawbacks of this technique. We also provide practical guidelines for when and how to implement feature-space decomposition in surgical applications, highlighting the key considerations and best practices for achieving optimal results.\n\nOverall, our research suggests that surgical feature-space decomposition of LLMs can lead to more efficient and effective deep learning models, offering a promising avenue for enhancing the performance of surgical tasks.",
        "Source": "GPT"
    },
    {
        "Index": 130,
        "Title": "Reasoning in Flux: Enhancing Large Language Models Reasoning through Uncertainty-aware Adaptive Guidance.",
        "Abstract": "Machine reasoning, involving step-by-step deduction and analysis, is crucial for solving complex problems. Large language models have shown promising capabilities in reasoning tasks, but they often struggle with uncertainty and ambiguity. This paper presents a novel approach to enhancing reasoning in large language models through uncertainty-aware adaptive guidance. By incorporating uncertainty estimation mechanisms, the model is able to dynamically adjust its reasoning process based on the level of confidence in its predictions. This adaptive guidance allows the model to make more informed decisions when faced with uncertain or contradictory information, leading to improved reasoning performance. Experimental results demonstrate that our proposed method outperforms baseline models in various reasoning tasks, showcasing the importance of considering uncertainty in the reasoning process. Overall, our approach provides a promising direction for enhancing the reasoning capabilities of large language models and addressing the challenges posed by uncertainty and ambiguity in complex problem-solving scenarios.",
        "Source": "GPT"
    },
    {
        "Index": 131,
        "Title": "Modality-Aware Integration with Large Language Models for Knowledge-Based Visual Question Answering.",
        "Abstract": "Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge sources. In this paper, we propose a novel approach for modality-aware integration with large language models to enhance the performance of KVQA. By leveraging large language models such as BERT, we are able to capture complex relationships between textual queries and visual content, leading to more accurate answers. Our method incorporates modality-specific information during the fusion of textual and visual features, allowing for more effective integration of knowledge sources. Through experiments on benchmark datasets, we demonstrate the effectiveness of our proposed approach in improving the accuracy of KVQA compared to existing methods. Additionally, we analyze the impact of different knowledge sources on the performance of our model, highlighting the importance of modality-aware integration in knowledge-based visual question answering tasks. Overall, our approach offers a promising direction for advancing the field of KVQA by leveraging the capabilities of large language models for enhanced reasoning and understanding.",
        "Source": "GPT"
    },
    {
        "Index": 132,
        "Title": "Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression.",
        "Abstract": "Key-value (KV) caching is crucial for accelerating the inference of large language models by storing frequently accessed key-value pairs in a cache memory for quick retrieval. However, the size of the cache memory directly impacts the performance and energy efficiency of the system. To address this challenge, data-free low-bit quantization with matrix decomposition is proposed as a solution for KV cache compression. This innovative technique allows for the efficient representation of key-value pairs in a reduced memory footprint without compromising inference accuracy. By leveraging matrix decomposition, the data-free low-bit quantization method can significantly reduce the storage requirements of the cache memory while maintaining high inference speeds. Experimental results demonstrate the effectiveness of this approach in compressing KV caches for large language models, achieving substantial memory savings without sacrificing performance. The proposed method unlocks new possibilities for optimizing KV cache compression in language model inference applications, paving the way for more efficient and scalable systems.",
        "Source": "GPT"
    },
    {
        "Index": 133,
        "Title": "VerifiNER: Verification-augmented NER via Knowledge-grounded Reasoning with Large Language Models.",
        "Abstract": "Recent approaches in domain-specific named entity recognition (NER), such as biomedical NER, have shown remarkable advancements in utilizing knowledge sources to improve entity recognition accuracy. However, existing methods often struggle to effectively integrate various knowledge sources and lack robust mechanisms for verifying the correctness of recognized entities. To address these limitations, we propose VerifiNER, a novel verification-augmented NER framework that leverages knowledge-grounded reasoning with large language models. VerifiNER combines the contextual knowledge encoded in language models with external knowledge sources to facilitate accurate entity recognition and verification. Through a series of experiments on biomedical NER tasks, we demonstrate that VerifiNER outperforms state-of-the-art NER models by effectively harnessing knowledge for improved entity recognition accuracy. Our results indicate that VerifiNER significantly enhances the robustness and reliability of entity recognition in domain-specific NER tasks by incorporating verification mechanisms within a knowledge-grounded reasoning framework.",
        "Source": "GPT"
    },
    {
        "Index": 134,
        "Title": "Making Long-Context Language Models Better Multi-Hop Reasoners.",
        "Abstract": "Recent advancements in long-context modeling have significantly improved the performance of language models (LMs) for complex tasks that require reasoning across multiple pieces of information. One key challenge in natural language understanding is the ability to perform multi-hop reasoning, where a model must integrate information from various parts of a text to answer a question or solve a problem. By incorporating techniques such as transformer architectures and attention mechanisms, researchers have been able to enhance the capabilities of LMs to effectively perform multi-hop reasoning tasks. These advancements have enabled LMs to achieve state-of-the-art results in tasks such as question answering, text generation, and language understanding. However, there is still room for improvement in making long-context language models even better multi-hop reasoners. In this paper, we discuss recent developments in long-context modeling and propose strategies to further enhance the performance of LMs in multi-hop reasoning tasks. Our findings contribute to the ongoing research efforts aimed at advancing the capabilities of language models for complex language understanding tasks.",
        "Source": "GPT"
    },
    {
        "Index": 135,
        "Title": "TransliCo: A Contrastive Learning Framework to Address the Script Barrier in Multilingual Pretrained Language Models.",
        "Abstract": "The world’s more than 7000 languages are written in at least 293 scripts. Due to this vast linguistic diversity, multilingual pretrained language models face a major challenge known as the script barrier, where the model struggles to generalize across languages with different scripts. In this study, we propose TransliCo, a contrastive learning framework designed to address this issue and improve the overall performance of multilingual pretrained language models. By learning representations of languages with different scripts in a common embedding space, TransliCo enables the model to better capture cross-script similarities and differences, ultimately enhancing its ability to understand and generate text in diverse languages. We evaluate TransliCo on several benchmark tasks and demonstrate significant improvements in multilingual model performance, particularly in low-resource settings where data scarcity exacerbates the script barrier problem. Our results highlight the effectiveness of TransliCo in overcoming the script barrier and improving the cross-lingual capabilities of multilingual pretrained language models.",
        "Source": "GPT"
    },
    {
        "Index": 136,
        "Title": "Extreme Miscalibration and the Illusion of Adversarial Robustness.",
        "Abstract": "Deep learning-based Natural Language Processing (NLP) models have shown remarkable performance in various applications, but they are vulnerable to adversarial attacks. These attacks, known as adversarial examples, involve making small perturbations to input data that are imperceptible to the human eye but can drastically affect the model's predictions. This vulnerability raises concerns about the reliability and robustness of NLP systems in real-world scenarios.\n\nIn this paper, we investigate the phenomenon of extreme miscalibration and the illusion of adversarial robustness in NLP models. We analyze the efficacy of current defenses against adversarial attacks and demonstrate that many models exhibit a false sense of robustness in the face of carefully crafted adversarial examples. We also explore the underlying reasons for this phenomenon and propose potential solutions to enhance the adversarial robustness of NLP models.\n\nOverall, our findings highlight the need for continued research and development to improve the security and reliability of NLP systems in the presence of adversarial attacks.",
        "Source": "GPT"
    },
    {
        "Index": 137,
        "Title": "HyCoRec: Hypergraph-Enhanced Multi-Preference Learning for Alleviating Matthew Effect in Conversational Recommendation.",
        "Abstract": "The Matthew effect is a notorious issue in Recommender Systems (RSs), i.e., the rich get richer phenomenon where popular items receive even more recommendations, while lesser-known items struggle to gain visibility. In conversational recommendation systems, this effect can be exacerbated as users are often limited in their interactions and preferences, leading to biased recommendations and potentially overlooking valuable but less popular items.\n\nTo alleviate the Matthew effect in conversational recommendation, we propose HyCoRec, a novel Hypergraph-Enhanced Multi-Preference Learning framework. By incorporating hypergraph structures and multiple preference types, HyCoRec can effectively capture diverse user preferences and item relationships, elevating the recommendation quality for both popular and niche items. Through extensive experiments on real-world datasets, we demonstrate that HyCoRec outperforms state-of-the-art methods in mitigating the Matthew effect, offering more balanced and personalized recommendations to users. Our findings highlight the importance of incorporating hypergraph structures and leveraging multiple preference signals to combat bias and improve the overall performance of conversational recommendation systems.",
        "Source": "GPT"
    },
    {
        "Index": 138,
        "Title": "Co-training for Low Resource Scientific Natural Language Inference.",
        "Abstract": "Scientific Natural Language Inference (NLI) is the task of predicting the semantic relation between a hypothesis and a premise in the context of scientific texts. The challenge of performing NLI in the scientific domain is exacerbated by limited labeled data and domain-specific vocabulary. In this paper, we propose a co-training approach for low-resource scientific NLI that leverages unlabeled data to improve model performance. Our method utilizes two separate models trained on different views of the data, where each model learns from its own predictions on unlabeled instances and exchanges confident predictions with the other model. This iterative process of co-training allows the models to learn from each other and improve overall performance. We evaluate our approach on a dataset of scientific NLI examples and demonstrate significant gains in accuracy compared to baseline models. Our results show that co-training is an effective strategy for enhancing NLI performance in low-resource scientific settings.",
        "Source": "GPT"
    },
    {
        "Index": 139,
        "Title": "RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with Human Feedback in Large Language Models.",
        "Abstract": "Reinforcement Learning with Human Feedback (RLHF) is a methodology designed to align Large Language Models (LLMs) with human preferences and goals through interactive feedback mechanisms. In this paper, we introduce RLHFPoison, a novel attack strategy targeting the RLHF framework specifically tailored for LLMs. RLHFPoison leverages the rewards provided by human annotators to manipulate the training process of the LLM, resulting in skewed model behaviors that deviate from the desired objectives. By injecting poisoned rewards into the RLHF system, adversaries can exploit vulnerabilities in the feedback loop to subvert the learning process and steer the model towards harmful or malicious behaviors. We present empirical evidence demonstrating the effectiveness of RLHFPoison in inducing reward poisoning attacks on LLMs, highlighting the potential risks associated with incorporating human feedback into reinforcement learning pipelines. Our findings underscore the importance of developing robust defenses against reward poisoning attacks in RLHF settings to safeguard the integrity and reliability of AI systems.",
        "Source": "GPT"
    },
    {
        "Index": 140,
        "Title": "Time is Encoded in the Weights of Finetuned Language Models.",
        "Abstract": "We present time vectors, a simple tool to customize language models to new time periods. By incorporating time information into the weights of finetuned language models, we are able to effectively capture the temporal characteristics of a given text. This allows for more accurate generation of content that is relevant to specific time frames, such as historical events or current trends. Our approach offers a flexible and efficient way to adapt language models to different time periods, enabling improved performance in a variety of applications, from text generation to sentiment analysis. Through experimental validation, we demonstrate the effectiveness of our method in enhancing the temporal sensitivity of language models, leading to better contextual understanding and more precise predictions. Overall, time vectors present a valuable tool for researchers and practitioners looking to leverage the temporal dimensions of text data in a simple yet powerful manner.",
        "Source": "GPT"
    },
    {
        "Index": 141,
        "Title": "Long-Context Language Modeling with Parallel Context Encoding.",
        "Abstract": "In this study, we propose a novel approach to extending large language models (LLMs) to process longer inputs, addressing a critical need for various applications. Our method, Parallel Context Encoding, enhances the capabilities of LLMs by efficiently incorporating extensive context information during training. By leveraging parallel processing techniques, we are able to overcome the limitations of traditional sequential encoding methods, significantly improving the model's ability to understand and generate longer sequences of text.\n\nThrough extensive experimentation on a range of datasets and tasks, including language modeling and text generation, we demonstrate the effectiveness of our approach in improving the performance of LLMs on longer inputs. Our results show substantial gains in both the quality and fluency of generated text, highlighting the importance of considering context beyond just the immediate surroundings of a word or phrase. Overall, our proposed method offers a promising solution for enhancing the capabilities of LLMs in processing and producing longer sequences of text, with potential applications in natural language understanding, dialogue systems, and machine translation.",
        "Source": "GPT"
    },
    {
        "Index": 142,
        "Title": "SirLLM: Streaming Infinite Retentive LLM.",
        "Abstract": "As Large Language Models (LLMs) become increasingly prevalent in various domains, their ability to process, analyze, and generate text at a remarkable scale is revolutionizing the way we interact with information. One notable LLM, known as SirLLM, is leading the charge in streaming infinite retentive LLM technology. This innovative model possesses the capability to remember and retain vast amounts of data, enabling it to produce coherent and contextually relevant responses in real-time.\n\nSirLLM's impressive performance has opened doors for applications in a wide range of fields, from natural language processing and data analysis to content generation and personalized recommendations. By harnessing the power of infinite retentive LLM technology, organizations can enhance efficiency, streamline processes, and uncover valuable insights from massive datasets. As we continue to push the boundaries of LLM capabilities, SirLLM stands at the forefront of this technological revolution, offering unprecedented opportunities for innovation and advancement.",
        "Source": "GPT"
    },
    {
        "Index": 143,
        "Title": "IMO: Greedy Layer-Wise Sparse Representation Learning for Out-of-Distribution Text Classification with Pre-trained Models.",
        "Abstract": "While machine learning models have achieved remarkable success in various tasks, such as image and speech recognition, they continue to face challenges when dealing with out-of-distribution text classification. Out-of-distribution samples often contain information that differs significantly from the data on which the models were trained, leading to poor performance and unreliable predictions. To address this issue, we propose a novel approach called Greedy Layer-Wise Sparse Representation Learning for Out-of-Distribution Text Classification with Pre-trained Models (IMO). This method leverages sparse representations at multiple layers of pre-trained models to improve the generalization ability of the model. By encouraging the learning of more informative and concise features, our approach enables the model to better capture the underlying similarities and differences between in-distribution and out-of-distribution samples, resulting in more robust and accurate classification performance. Experimental results demonstrate the effectiveness of our method in improving out-of-distribution text classification tasks, highlighting its potential for enhancing the overall performance of machine learning models in challenging scenarios.",
        "Source": "GPT"
    },
    {
        "Index": 144,
        "Title": "Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale.",
        "Abstract": "A syntactic language model (SLM) incrementally generates a sentence with its syntactic tree in a hierarchical manner, capturing the underlying grammatical structure of the language. In this paper, we introduce Generative Pretrained Structured Transformers (GPST), an unsupervised approach to training syntactic language models at scale. GPST leverages transformer-based architecture and pretrained models to learn syntactic representations in a self-supervised manner. By incorporating structured prediction during training, GPST is able to encode syntactic information more effectively than traditional language models. We demonstrate the effectiveness of GPST on a variety of syntactic tasks, showcasing its ability to generate coherent and grammatically correct sentences while maintaining syntactic structures. Our experiments show that GPST outperforms existing unsupervised syntactic language models, achieving state-of-the-art performance on multiple benchmarks. Overall, GPST represents a significant advancement in the field of unsupervised syntactic language modeling, offering a powerful tool for analyzing and generating text at scale.",
        "Source": "GPT"
    },
    {
        "Index": 145,
        "Title": "MELA: Multilingual Evaluation of Linguistic Acceptability.",
        "Abstract": "In this work, we present the largest benchmark to date on linguistic acceptability: Multilingual Evaluation of Linguistic Acceptability (MELA). MELA is a comprehensive dataset that encompasses a wide range of languages, making it a valuable resource for evaluating the linguistic acceptability of text across different linguistic backgrounds. Our dataset consists of sentences annotated by native speakers for grammaticality, fluency, and other linguistic properties, allowing for a nuanced evaluation of language usage. We introduce a new evaluation metric, the Linguistic Acceptability Score (LAS), which combines multiple linguistic properties to provide a more holistic assessment of text quality. Through experiments on MELA, we demonstrate the utility of our benchmark for evaluating and comparing language models across multiple languages. We believe that MELA will serve as a valuable tool for researchers and practitioners in natural language processing, enabling them to improve the linguistic quality of text generation systems and enhance cross-lingual communication.",
        "Source": "GPT"
    },
    {
        "Index": 146,
        "Title": "CopyNE: Better Contextual ASR by Copying Named Entities.",
        "Abstract": "End-to-end automatic speech recognition (ASR) systems have achieved remarkable advancements in various scenarios. However, they still face challenges in accurately transcribing named entities due to their unique properties and context dependencies. In this paper, we propose a novel approach called CopyNE, which improves contextual ASR performance by incorporating named entity copying mechanisms.\n\nCopyNE leverages named entity recognition (NER) models to identify and copy named entities in the speech input, thereby enhancing the system's ability to transcribe them accurately. By directly copying named entities, CopyNE reduces errors caused by ambiguity and context mismatch, resulting in more contextually-aware ASR outputs.\n\nWe evaluate CopyNE on a diverse set of speech datasets and demonstrate its superior performance in transcription accuracy, especially for named entities. Our results show that CopyNE significantly outperforms existing state-of-the-art ASR systems, highlighting the effectiveness of named entity copying in enhancing contextual understanding and transcription quality in ASR tasks.",
        "Source": "GPT"
    },
    {
        "Index": 147,
        "Title": "Is Table Retrieval a Solved Problem? Exploring Join-Aware Multi-Table Retrieval.",
        "Abstract": "Retrieving relevant tables containing the necessary information to accurately answer a given question over tables is a crucial task in many information retrieval systems. However, the effectiveness of table retrieval has been a topic of ongoing debate in the research community. In this study, we explore the concept of join-aware multi-table retrieval, where the system is able to not only retrieve individual tables, but also understand the relationships between tables and retrieve them in a coherent manner.\n\nWe conduct experiments on a benchmark dataset to evaluate the performance of current table retrieval methods and propose a novel approach that incorporates join-awareness for more accurate and efficient retrieval. Our results show that join-aware multi-table retrieval significantly improves the relevance of retrieved tables and enhances the overall performance of table retrieval systems.\n\nOverall, our study sheds light on the challenges and opportunities in table retrieval and suggests that there is still room for improvement in this area.",
        "Source": "GPT"
    },
    {
        "Index": 148,
        "Title": "Generalizing Conversational Dense Retrieval via LLM-Cognition Data Augmentation.",
        "Abstract": "Conversational search utilizes multi-turn natural language contexts to retrieve relevant passages from large document collections. Existing conversational dense retrieval methods have shown promising results in capturing complex conversational dynamics, but they often lack generalization capabilities across a wide range of conversational topics. In this study, we propose a novel approach to enhance conversational dense retrieval through LLM-Cognition data augmentation. By incorporating a large pre-trained language model (LLM) with cognitive data augmentation techniques, our method aims to improve the generalization of conversational search models. Through experimental evaluation on a conversational search dataset, we demonstrate that our approach outperforms state-of-the-art methods in terms of retrieval effectiveness and generalization across diverse conversational topics. Our findings suggest that utilizing LLM-Cognition data augmentation can significantly enhance the performance of conversational dense retrieval models, paving the way for more effective and robust conversational search systems.",
        "Source": "GPT"
    },
    {
        "Index": 149,
        "Title": "ItD: Large Language Models Can Teach Themselves Induction through Deduction.",
        "Abstract": "Although Large Language Models (LLMs) are showing impressive performance on a wide range of Natural Language Processing tasks, their ability to learn through induction remains a challenge. In this study, we propose a method where LLMs can teach themselves induction through deduction. By incorporating both inductive and deductive reasoning processes into the model, we aim to enhance its ability to generalize from limited data and make accurate predictions on unseen instances. We demonstrate the effectiveness of our approach on various benchmark datasets, showcasing the model's improved performance in tasks requiring generalization and reasoning abilities. Our results suggest that combining induction with deduction can significantly enhance the capabilities of LLMs and enable them to learn complex patterns and relationships in language data. This novel approach opens up new possibilities for LLMs to tackle real-world problems that require reasoning and critical thinking skills, providing a promising direction for future research in the field of Natural Language Processing.",
        "Source": "GPT"
    },
    {
        "Index": 150,
        "Title": "MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs.",
        "Abstract": "Large language models (LLMs) have shown promising results in mathematical reasoning tasks, but they still face challenges in generating diverse and high-quality synthetic data for enhanced learning. In this paper, we introduce MathGenie, a novel approach that leverages question back-translation to generate synthetic data for improving the mathematical reasoning abilities of LLMs. By translating math word problems into different languages and then back to the original language, MathGenie creates diverse variations of the original problems, effectively increasing the diversity and complexity of the training data.\n\nExperimental results demonstrate that MathGenie significantly improves the performance of LLMs on mathematical reasoning tasks, outperforming existing data augmentation techniques. Furthermore, our approach is robust to noise and variations in the input data, making it a valuable tool for enhancing the mathematical reasoning capabilities of LLMs in real-world applications. Overall, MathGenie presents a promising avenue for improving the generalization and reasoning abilities of LLMs in mathematical tasks.",
        "Source": "GPT"
    },
    {
        "Index": 151,
        "Title": "Rethinking Task-Oriented Dialogue Systems: From Complex Modularity to Zero-Shot Autonomous Agent.",
        "Abstract": "Task-oriented dialogue (TOD) systems have traditionally been structured as complex modular systems, with separate modules for tasks such as natural language understanding, dialogue management, and response generation. However, this modular approach can lead to issues such as information loss between modules, increased development time, and difficulties in adapting to new tasks.\n\nIn this paper, we propose a new approach to TOD systems that moves away from complex modularity towards a zero-shot autonomous agent. This autonomous agent is able to perform task-oriented dialogue without relying on pre-defined modules or explicit task-specific training data. Instead, it leverages techniques such as transfer learning and self-supervised learning to generalize across tasks and adapt to new tasks with minimal additional training.\n\nBy rethinking the conventional modular design of TOD systems, we aim to create more flexible, scalable, and efficient dialogue agents that can seamlessly handle a wide range of tasks without the need for extensive manual engineering or task-specific data. Our zero-shot autonomous agent represents a step towards more intelligent and adaptive dialogue systems.",
        "Source": "GPT"
    },
    {
        "Index": 152,
        "Title": "On Context Utilization in Summarization with Large Language Models.",
        "Abstract": "Large language models (LLMs) excel in abstractive summarization tasks, delivering fluent and pertinent summaries. Recently, the utilization of context in summarization with LLMs has garnered significant attention. Context plays a crucial role in producing coherent and informative summaries, as it helps LLMs understand the relationships between different parts of the input text. In this paper, we explore various strategies for incorporating context into the summarization process with LLMs. We investigate how different types of context, such as discourse coherence, inter-sentence relationships, and domain-specific knowledge, can be leveraged to improve the quality of summaries generated by LLMs. Furthermore, we propose novel techniques for modeling and utilizing context in the summarization pipeline, aiming to enhance the overall performance of LLMs in generating concise and informative summaries. Our experimental results demonstrate the effectiveness of these context utilization strategies in improving the summarization capabilities of LLMs.",
        "Source": "GPT"
    },
    {
        "Index": 153,
        "Title": "INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning.",
        "Abstract": "Large language models (LLMs) have demonstrated impressive capabilities in various natural language processing tasks. Despite their success, deploying these models in search applications poses several challenges, including the need for high-quality instructions to guide the model towards relevant information retrieval. In this paper, we propose a novel approach called Instruction Tuning for Efficient Retrieval with LLMs (INTERS) that leverages the power of large language models in search by fine-tuning the instructions provided to the models. By optimizing the instructions based on user queries and context, INTERS aims to improve the relevance and efficiency of information retrieval in search tasks. We conduct experiments on various datasets and demonstrate that our approach outperforms existing methods in terms of search accuracy and speed. Overall, our work highlights the potential of utilizing large language models in search applications and underscores the importance of fine-tuning instructions to unlock their full power.",
        "Source": "GPT"
    },
    {
        "Index": 154,
        "Title": "Enhancing In-Context Learning via Implicit Demonstration Augmentation.",
        "Abstract": "The emergence of in-context learning (ICL) has significantly expanded the capabilities of large pre-trained language models (PLMs) by allowing them to make predictions based on contextual information. However, while PLMs excel at extracting and understanding context from large amounts of text data, they may still struggle with certain nuances and intricacies of language use. This paper proposes a novel approach to enhance ICL through implicit demonstration augmentation, where human-provided demonstrations are subtly integrated into the PLM's learning process to improve its performance in context-aware tasks. By leveraging the power of both human intelligence and machine learning algorithms, this approach aims to bridge the gap between the capabilities of PLMs and the nuanced understanding required for complex language tasks. Through a series of experiments and evaluations, we demonstrate the effectiveness of implicit demonstration augmentation in improving the performance of PLMs in various context-dependent tasks, ultimately leading to a more robust and accurate in-context learning system.",
        "Source": "GPT"
    },
    {
        "Index": 155,
        "Title": "PRoLoRA: Partial Rotation Empowers More Parameter-Efficient LoRA.",
        "Abstract": "With the rapid scaling of large language models (LLMs), serving numerous low-rank adaptations (LoRAs) concurrently has become a crucial challenge. In this study, we propose a novel approach called PRoLoRA (Partial Rotation Empowers More Parameter-Efficient LoRA) to address this issue. PRoLoRA leverages partial rotation techniques to empower more parameter-efficient LoRAs, allowing for the efficient utilization of resources in serving multiple low-rank adaptations simultaneously. Our experimental results demonstrate that PRoLoRA achieves superior performance compared to existing methods in terms of both accuracy and efficiency. By efficiently utilizing parameters and resources, PRoLoRA enables the seamless integration of numerous LoRAs into large language models, facilitating the deployment of diverse adaptations tailored to specific tasks or languages. Overall, PRoLoRA presents a promising solution for enhancing the scalability and efficiency of large language models, providing a flexible and effective framework for serving multiple low-rank adaptations concurrently in a resource-efficient manner.",
        "Source": "GPT"
    },
    {
        "Index": 156,
        "Title": "Improving Event Definition Following For Zero-Shot Event Detection.",
        "Abstract": "Zero-shot event detection is a challenging task in natural language processing that aims to identify events in text without the need for labeled training data. Existing approaches typically rely on models trained on datasets annotated with known events to make predictions on unseen events. This can lead to limited generalization capabilities, as the model may struggle to identify events that were not present in the training data. In this paper, we propose a novel approach to improving event definition following for zero-shot event detection. Our method seeks to enhance the model's ability to recognize a wider range of events by refining the event definitions used during training. By carefully adjusting and expanding the event definitions, we aim to create a more comprehensive understanding of events in text, enabling the model to better handle unseen events. Experimental results demonstrate the effectiveness of our approach in enhancing zero-shot event detection performance, highlighting the importance of refining event definitions for improved model generalization.",
        "Source": "GPT"
    },
    {
        "Index": 157,
        "Title": "Through the MUD: A Multi-Defendant Charge Prediction Benchmark with Linked Crime Elements.",
        "Abstract": "The current charge prediction datasets mostly focus on single-defendant criminal cases. However, real-world criminal cases usually involve multiple defendants with interconnected criminal activities. In this paper, we introduce a new benchmark dataset, Through the MUD, to address the challenges of predicting charges in multi-defendant cases with linked crime elements. The dataset includes a diverse set of cases involving multiple defendants and a wide range of criminal charges. Each case is annotated with detailed information on the defendants' relationships, criminal histories, and the specific criminal activities they were involved in. We provide baseline results using state-of-the-art machine learning models to predict the charges for each defendant in the multi-defendant cases. Through the MUD not only advances the field of charge prediction in criminal cases but also sheds light on the complexities of multi-defendant cases in the criminal justice system.",
        "Source": "GPT"
    },
    {
        "Index": 158,
        "Title": "Interpreting Conversational Dense Retrieval by Rewriting-Enhanced Inversion of Session Embedding.",
        "Abstract": "Conversational dense retrieval has proven to be a powerful tool in the realm of conversational search, allowing for more accurate and relevant results to be delivered to users. However, a significant limitation of this approach lies in the challenge of effectively interpreting and understanding the underlying conversations to retrieve the most pertinent information. In this study, we propose a novel method for addressing this limitation through the use of rewriting-enhanced inversion of session embedding.\n\nBy utilizing rewriting techniques, we aim to enhance the interpretability of conversational dense retrieval results, allowing for a more thorough understanding of the context and intent behind the conversations. This, in turn, will enable more accurate retrieval of information and improve the overall effectiveness of conversational search systems.\n\nOur approach represents a novel contribution to the field of conversational search and retrieval, offering a promising solution to the challenge of interpreting conversational dense retrieval results. Through our rewriting-enhanced inversion of session embedding method, we strive to enhance the user experience and ultimately improve the relevance and accuracy of search results in conversational settings.",
        "Source": "GPT"
    },
    {
        "Index": 159,
        "Title": "Stumbling Blocks: Stress Testing the Robustness of Machine-Generated Text Detectors Under Attacks.",
        "Abstract": "The widespread use of large language models (LLMs) is increasing the demand for methods that can effectively detect and mitigate malicious attacks on machine-generated text. In this study, we aim to stress test the robustness of existing text detectors against various forms of adversarial attacks on LLMs. By implementing a series of carefully crafted attacks, we evaluate the performance of these detectors in detecting manipulated text generated by LLMs. Our findings highlight the vulnerabilities of current detection methods and the need for more robust defenses against sophisticated attacks. Through our experiments, we provide valuable insights into the strengths and weaknesses of different detection strategies, shedding light on potential areas for improvement in the field of text detection in the context of machine-generated text. Overall, our study emphasizes the importance of continuous evaluation and enhancement of text detection systems to maintain the integrity and security of machine-generated content.",
        "Source": "GPT"
    },
    {
        "Index": 160,
        "Title": "Training Language Models to Generate Text with Citations via Fine-grained Rewards.",
        "Abstract": "While recent Large Language Models (LLMs) have proven useful in answering user queries, they are often unable to provide accurate and reliable information with proper citations. In this paper, we propose a method for training language models to generate text with citations through the use of fine-grained rewards. By incorporating citations into the training process, our approach aims to improve the credibility and trustworthiness of the generated text. We demonstrate the effectiveness of our method through experiments on various datasets and show that our model outperforms existing approaches in generating text with accurate citations. Additionally, we explore the impact of different reward mechanisms on the performance of the model and discuss the implications of our findings for future research in natural language processing. Our work contributes to the development of more reliable and informative language models that can better assist users in accessing trustworthy information.",
        "Source": "GPT"
    },
    {
        "Index": 161,
        "Title": "Hypergraph based Understanding for Document Semantic Entity Recognition.",
        "Abstract": "Semantic entity recognition is an important task in the field of visually-rich document understanding. It involves identifying and categorizing entities such as people, organizations, locations, and more within a document. Traditional methods for semantic entity recognition rely on named entity recognition (NER) models, which can be limited in their ability to accurately identify entities in visually complex documents. In this paper, we propose a hypergraph-based approach for document semantic entity recognition, which leverages the relationships between entities in a document to improve recognition accuracy. By representing entities and their relationships as vertices and hyperedges in a hypergraph, we can capture the complex interactions between entities and extract richer semantic information. Experimental results show that our method outperforms traditional NER models in visually-rich document understanding tasks, demonstrating the effectiveness of hypergraph-based approaches for semantic entity recognition. Our proposed approach opens up new possibilities for improving the accuracy and efficiency of semantic entity recognition in visually complex documents.",
        "Source": "GPT"
    },
    {
        "Index": 162,
        "Title": "GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers.",
        "Abstract": "Large language models (LLMs) have achieved impressive performance across various mathematical reasoning benchmarks. However, their robustness and generalizability in solving mathematical problems remain underexplored. In this work, we introduce GSM-Plus, a comprehensive benchmark specifically designed to evaluate the robustness of LLMs as mathematical problem solvers. GSM-Plus consists of a diverse set of mathematical reasoning tasks, including algebraic equations, geometric proofs, number theory problems, and more. \n\nWe evaluate the performance of state-of-the-art LLMs, such as GPT-3 and BERT, on GSM-Plus and uncover their strengths and weaknesses in solving different types of mathematical problems. Our results demonstrate that while LLMs excel in certain mathematical tasks, they struggle with others, revealing the limitations of current models in generalizing across mathematical domains. \n\nOverall, our benchmark provides a standardized evaluation framework for assessing the robustness and generalizability of LLMs in mathematical problem-solving, shedding light on the capabilities and limitations of these models in mastering complex mathematical concepts.",
        "Source": "GPT"
    },
    {
        "Index": 163,
        "Title": "Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models.",
        "Abstract": "Cross-document event coreference resolution (CDECR) is a challenging task in natural language processing that involves linking and clustering event mentions across different documents. In this paper, we propose a novel approach to CDECR that leverages large language models and emphasizes collaboration between multiple sources of information. By incorporating syntactic and semantic features from various documents, our approach focuses on capturing the nuanced relationships between events mentioned across texts. We demonstrate the effectiveness of our method through experiments on a diverse set of datasets, showing significant improvements in event coreference resolution compared to existing approaches. Our results underscore the importance of collaboration and synergistic understanding in tackling the complexities of cross-document event coreference resolution. This collaborative approach not only enhances the accuracy and efficiency of event clustering but also sheds light on potential applications in document summarization, information retrieval, and knowledge base construction.",
        "Source": "GPT"
    },
    {
        "Index": 164,
        "Title": "AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning.",
        "Abstract": "Language agents have achieved impressive performance on challenging question-answering tasks through the use of external planning. However, existing methodologies often rely on hand-crafted features and predetermined strategies, limiting their flexibility and scalability. In this paper, we propose AutoAct, a novel approach that enables automatic agent learning from scratch for question-answering tasks via self-planning. AutoAct leverages reinforcement learning techniques to allow agents to autonomously learn effective strategies for planning and executing actions to answer questions. By eliminating the need for manual feature engineering and pre-defined strategies, AutoAct significantly improves the flexibility and adaptability of language agents. Experimental results demonstrate that our approach outperforms state-of-the-art methods on various question-answering benchmarks, showcasing the effectiveness and efficiency of automatic agent learning through self-planning. Overall, AutoAct represents a significant advancement in the field of language agents, achieving superior performance on complex question-answering tasks while leveraging the power of self-learning and autonomous planning.",
        "Source": "GPT"
    },
    {
        "Index": 165,
        "Title": "ChronosLex: Time-aware Incremental Training for Temporal Generalization of Legal Classification Tasks.",
        "Abstract": "Legal multi-label text classification is a complex task due to the dynamic nature of legal documents and their ever-changing content. This study delves into the challenges that arise from the temporal aspect of legal classification tasks, particularly in the context of multi-label classification. We propose ChronosLex, a time-aware incremental training approach that addresses the issue of temporal generalization in legal text classification. By incorporating temporal information into the training process, ChronosLex aims to improve the performance and accuracy of the classification model over time. Our approach leverages historical data and updates the model incrementally to adapt to changes in legal documents, ensuring that the classifier remains up-to-date and effective in classifying legal texts. We conduct experiments on various legal datasets to demonstrate the effectiveness of ChronosLex in handling temporal variations and achieving high classification accuracy. Overall, this study sheds light on the importance of considering the temporal dimension in legal text classification tasks and provides a practical solution for achieving temporal generalization in multi-label classification.",
        "Source": "GPT"
    },
    {
        "Index": 166,
        "Title": "Virtual Compiler Is All You Need For Assembly Code Search.",
        "Abstract": "Assembly code search is a crucial aspect of reverse engineering, enabling practitioners to efficiently analyze and understand the functionality of software programs. By utilizing a virtual compiler, reverse engineers can streamline the process of searching for specific assembly code snippets, thereby reducing the time and effort required for analysis. This innovative tool provides a user-friendly interface for searching and accessing relevant assembly code instructions, functions, and references.\n\nWith a virtual compiler, reverse engineers can quickly identify patterns and relationships within the codebase, facilitating a comprehensive understanding of the software's inner workings. Additionally, the virtual compiler offers a seamless integration with various debugging and disassembling tools, further enhancing the efficiency and accuracy of code analysis.\n\nIn conclusion, assembly code search is a crucial component of reverse engineering, and a virtual compiler serves as an invaluable resource for simplifying and enhancing the process. By leveraging this tool, reverse engineers can effectively navigate complex codebases, accelerating the identification and resolution of software vulnerabilities and weaknesses.",
        "Source": "GPT"
    },
    {
        "Index": 167,
        "Title": "MELoRA: Mini-Ensemble Low-Rank Adapters for Parameter-Efficient Fine-Tuning.",
        "Abstract": "Parameter-efficient fine-tuning (PEFT) has emerged as a popular technique for adapting pre-trained large language models (LLMs) to specific downstream tasks while minimizing computational resources and training time. In this paper, we propose MELoRA: Mini-Ensemble Low-Rank Adapters, a novel approach to further improve the efficiency of fine-tuning large language models. \n\nMELoRA leverages the concept of low-rank adapters, which are lightweight modules added to the pre-trained LLMs to adapt them for specific tasks. By utilizing a mini-ensemble of low-rank adapters, MELoRA not only enhances the adaptability of LLMs but also significantly reduces the number of parameters required for fine-tuning. This results in a more efficient and parameter-effective fine-tuning process, making it particularly suitable for resource-constrained environments or scenarios where rapid model adaptation is required.\n\nOur experimental results demonstrate that MELoRA achieves competitive performance compared to traditional fine-tuning methods, while utilizing fewer parameters and requiring less computational resources. Overall, MELoRA offers a promising approach for parameter-efficient fine-tuning of large language models.",
        "Source": "GPT"
    },
    {
        "Index": 168,
        "Title": "Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning.",
        "Abstract": "Large language models (LLMs) have showcased impressive reasoning capabilities, sparking interest in harnessing their potential for various tasks. Despite their successes, LLMs are not immune to errors. This study delves into the investigation of LLMs' errors to enhance their reasoning abilities. By analyzing and learning from previous mistakes made by LLMs, we aim to boost their overall performance and reliability. Through this research, we seek to uncover valuable insights that can aid in the development of more robust and accurate LLMs. By understanding the root causes of errors and implementing corrective measures, we can further leverage the power of LLMs for improved reasoning outcomes. Ultimately, this study sheds light on the importance of error analysis in advancing the capabilities of LLMs and highlights the potential for continuous improvement in their reasoning prowess.",
        "Source": "GPT"
    },
    {
        "Index": 169,
        "Title": "An Iterative Associative Memory Model for Empathetic Response Generation.",
        "Abstract": "Empathetic response generation aims to comprehend the cognitive and emotional states in dialogue utterances to provide appropriate and supportive responses. In this study, we propose an Iterative Associative Memory (IAM) model for empathetic response generation. The IAM model is designed to generate empathetic responses by iteratively refining the representation of input utterances through multiple associative memory layers. By capturing the intricate relationships between different cognitive and emotional components expressed in dialogues, the IAM model enables more nuanced and contextually appropriate responses. We evaluate the effectiveness of the IAM model on a dataset of dialogue utterances with ground truth empathetic responses, demonstrating its ability to generate empathetic responses that are both emotionally relevant and contextually coherent. The results highlight the potential of the IAM model for enhancing empathetic response generation in dialogue systems, paving the way for more natural and empathetic human-computer interactions.",
        "Source": "GPT"
    },
    {
        "Index": 170,
        "Title": "Detoxifying Large Language Models via Knowledge Editing.",
        "Abstract": "This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a framework for systematically identifying and removing harmful biases and misinformation from LLMs. By leveraging existing knowledge bases and fact-checking resources, we propose a novel approach that combines human oversight with automated algorithms to fine-tune LLMs towards more ethical and accurate outputs. Our experimental results demonstrate the efficacy of our approach in mitigating the spread of false information and harmful biases. Through a series of case studies, we showcase how knowledge editing can enhance the trustworthiness and fairness of LLM-generated content across various domains. Additionally, we discuss potential challenges and future directions for further advancing the field of knowledge editing for LLMs. Overall, our findings suggest that incorporating knowledge editing techniques is a promising strategy for promoting responsible and beneficial use of LLMs in a wide range of applications.",
        "Source": "GPT"
    },
    {
        "Index": 171,
        "Title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding.",
        "Abstract": "Although large language models (LLMs) demonstrate impressive performance for many language tasks, most of them are evaluated on short-context benchmarks that do not fully capture their capabilities in understanding and processing long-form text. To address this limitation, we introduce LongBench, a bilingual and multitask benchmark designed specifically to evaluate LLMs' ability to comprehend lengthy and complex text. LongBench consists of a diverse range of tasks, including text summarization, question answering, and language modeling, all performed on extensive text passages in multiple languages. By providing a challenging and comprehensive evaluation of LLMs' long-context understanding abilities, LongBench aims to push the boundaries of natural language processing research and model development. We believe that this benchmark will not only better showcase the true capabilities of LLMs but also drive advancements in the field toward a deeper understanding of how these models process and interpret lengthy textual input.",
        "Source": "GPT"
    },
    {
        "Index": 172,
        "Title": "Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models.",
        "Abstract": "Teachers are important in imparting knowledge and guiding learners, and the role of large language models in educational settings continues to evolve. In this study, we introduce Dr.Academy, a benchmark for evaluating questioning capability in education for large language models. Dr.Academy aims to assess the ability of these models to generate high-quality questions that stimulate critical thinking and facilitate learning. By evaluating the questioning capability of these models, we can better understand their potential impact on education and their ability to support teachers in classroom settings. Through this benchmark, we seek to provide a standardized framework for assessing the effectiveness of large language models in generating questions that promote deep understanding and engagement among learners. Ultimately, Dr.Academy aims to contribute to the ongoing conversation around the integration of artificial intelligence in education and the enhancement of teaching and learning practices.",
        "Source": "GPT"
    },
    {
        "Index": 173,
        "Title": "UniBridge: A Unified Approach to Cross-Lingual Transfer Learning for Low-Resource Languages.",
        "Abstract": "In this paper, we introduce UniBridge (Cross-Lingual Transfer Learning with Optimized Embeddings and Vocabulary), a unified approach to cross-lingual transfer learning designed specifically for low-resource languages. Our method leverages pre-trained embeddings and vocabulary mappings to facilitate knowledge transfer across languages, enabling effective model adaptation with limited linguistic resources. By utilizing these optimized components, UniBridge is able to bridge the gap between high-resource and low-resource languages, allowing for improved performance on tasks such as natural language processing and machine translation. We evaluate UniBridge on a range of benchmark datasets and demonstrate its effectiveness in enhancing the performance of models on low-resource languages compared to traditional transfer learning methods. Our results show significant improvements in both accuracy and efficiency, highlighting the potential of UniBridge to address the challenges of language diversity and resource scarcity in cross-lingual learning scenarios. Overall, this work contributes to the advancement of cross-lingual transfer learning techniques and provides a promising solution for bridging language barriers in diverse linguistic settings.",
        "Source": "GPT"
    },
    {
        "Index": 174,
        "Title": "VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval.",
        "Abstract": "Multi-modal retrieval, the process of retrieving information across different modalities such as text, images, and videos, is a rapidly growing field in information retrieval. Despite its popularity, existing retrievers are predominantly text-oriented, lacking the ability to effectively incorporate and retrieve information from other modalities. To address this limitation, we propose VISTA (Visualized Text Embedding for Universal Multi-Modal Retrieval), a novel approach that combines visual and textual information to enhance multi-modal retrieval capabilities. VISTA utilizes advanced text embedding techniques to encode textual information, while also incorporating visual data through the use of visual embeddings. By effectively integrating both modalities, VISTA improves retrieval performance by providing a more holistic representation of information. Our experimental results demonstrate the effectiveness of VISTA in achieving superior retrieval accuracy compared to existing text-centric retrievers. Overall, our approach showcases the potential of integrating visual and textual information for multi-modal retrieval tasks, making strides towards more comprehensive and universal retrieval systems.",
        "Source": "GPT"
    },
    {
        "Index": 175,
        "Title": "Black-Box Prompt Optimization: Aligning Large Language Models without Model Training.",
        "Abstract": "Large language models (LLMs) have shown impressive success in various applications. However, these models are often computationally expensive to train and fine-tune, limiting their scalability and widespread adoption. In this study, we propose a novel approach for optimizing LLM performance without the need for additional model training. Our method, called Black-Box Prompt Optimization, leverages the inherent capabilities of LLMs to align with specific tasks and objectives through prompt engineering. By iteratively fine-tuning prompt templates, our approach effectively directs the model's attention towards relevant information and improves its performance on diverse tasks. We demonstrate the effectiveness of our method on various benchmark datasets, achieving competitive results compared to traditional fine-tuning approaches. Moreover, our approach significantly reduces the computational overhead associated with model training, making it a practical and efficient solution for deploying LLMs in real-world applications. Overall, our study highlights the potential of prompt optimization as a viable alternative to traditional training paradigms for enhancing LLM performance.",
        "Source": "GPT"
    },
    {
        "Index": 176,
        "Title": "Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with Ko-H5 Benchmark.",
        "Abstract": "This paper introduces the Open Ko-LLM Leaderboard and the Ko-H5 Benchmark as vital tools for evaluating Large Language Models (LLMs) in Korean. Large Language Models have shown impressive performance across various natural language processing tasks, but their effectiveness and generalization capabilities in Korean language settings have not been extensively explored. The Open Ko-LLM Leaderboard provides a platform for researchers to benchmark and compare the performance of different LLMs specifically in the Korean language. \n\nThe Ko-H5 Benchmark, a curated dataset specifically designed for evaluating LLMs in Korean, serves as a standardized evaluation metric to ensure fair and consistent comparisons between models. Through the use of the Open Ko-LLM Leaderboard and the Ko-H5 Benchmark, researchers and practitioners can gain insights into the capabilities and limitations of LLMs in the Korean language domain. This paper highlights the importance of these tools in advancing research and development in Korean language processing and lays the groundwork for future advancements in this area.",
        "Source": "GPT"
    },
    {
        "Index": 177,
        "Title": "Unified Hallucination Detection for Multimodal Large Language Models.",
        "Abstract": "Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the challenge of unified hallucination detection. This paper proposes a novel approach to address this issue by introducing a unified hallucination detection mechanism for MLLMs. The proposed method leverages both textual and visual modalities to effectively capture and identify hallucinated content within MLLMs. By incorporating multimodal cues, our approach achieves state-of-the-art performance in hallucination detection across various datasets and languages. Additionally, we demonstrate the effectiveness of our method through extensive experiments and analyses, showcasing its robustness and generalizability. Our unified hallucination detection framework not only enhances the reliability of MLLMs but also contributes to the advancement of multimodal model interpretability and trustworthiness. This work paves the way for future research on improving the overall performance and trustworthiness of MLLMs in various applications and domains.",
        "Source": "GPT"
    },
    {
        "Index": 178,
        "Title": "Empowering Character-level Text Infilling by Eliminating Sub-Tokens.",
        "Abstract": "In infilling tasks, sub-tokens are often used to represent instances where a complete token is segmented into two parts. This can lead to challenges in effectively predicting and generating missing characters within a token. In this study, we propose a novel approach to empower character-level text infilling by eliminating sub-tokens. By integrating a sub-token elimination mechanism into the infilling process, we aim to improve the overall accuracy and efficiency of text completion tasks. Our method involves identifying and merging sub-tokens to reconstruct the original tokens, allowing for more contextually relevant predictions and a more seamless generation of missing characters. Experimental results demonstrate that our approach outperforms existing methods in various text infilling benchmarks, showcasing its effectiveness in enhancing the quality and reliability of character-level completion tasks. Overall, our research contributes to advancing the field of text infilling by introducing a more streamlined and accurate approach to handling sub-tokens in character-level predictions.",
        "Source": "GPT"
    },
    {
        "Index": 179,
        "Title": "Landmark Embedding: A Chunking-Free Embedding Method For Retrieval Augmented Long-Context Large Language Models.",
        "Abstract": "Retrieval augmentation is a promising approach to enhance long-context language modeling by integrating external knowledge sources into large language models. However, existing retrieval methods often rely on chunking the input text into smaller segments, which can lead to information loss and hinder the model's ability to capture intricate relationships within the data. In this paper, we propose a novel approach known as Landmark Embedding, which eliminates the need for chunking and instead directly embeds landmarks from the external knowledge source into the large language model. By embedding landmarks in this manner, we can effectively augment the model's long-context capabilities without sacrificing information fidelity. Our experimental results demonstrate that our chunking-free embedding method outperforms existing retrieval methods in capturing complex relationships and achieving higher retrieval accuracy. Overall, our approach offers a promising solution for enhancing long-context language modeling through retrieval augmentation, showcasing the potential of improving the performance of large language models across various natural language processing tasks.",
        "Source": "GPT"
    },
    {
        "Index": 180,
        "Title": "GrowOVER: How Can LLMs Adapt to Growing Real-World Knowledge?",
        "Abstract": "In the real world, knowledge is constantly evolving, which can render existing knowledge-based datasets outdated. This poses a challenge for Legal and Compliance professionals, who rely heavily on accurate and up-to-date information to make informed decisions. The concept of GrowOVER offers a solution to this issue by emphasizing the need for Legal and Compliance professionals to continuously adapt and update their knowledge to stay ahead of the curve. This involves being proactive in seeking out new information, staying informed about current trends and developments, and constantly reevaluating and updating existing knowledge-based datasets. By embracing the principles of GrowOVER, Legal and Compliance professionals can better navigate the rapidly changing landscape of real-world knowledge, ensuring that they are equipped to make informed decisions and effectively mitigate risks. This abstract explores the importance of adaptability and continuous learning in the legal and compliance field, and highlights the benefits of embracing a growth mindset in the face of evolving knowledge.",
        "Source": "GPT"
    },
    {
        "Index": 181,
        "Title": "Attribute First, then Generate: Locally-attributable Grounded Text Generation.",
        "Abstract": "Recent efforts to address hallucinations in Large Language Models (LLMs) have shifted towards utilizing attributed text for grounded text generation. This approach, known as Attribute First, then Generate (AtrFG), aims to improve the reliability and coherence of generated text by providing the model with locally-attributable information. By incorporating attributes such as persona traits, emotions, and specific contexts into the generation process, AtrFG enables LLMs to produce more accurate and contextually relevant outputs. This framework not only helps mitigate the risk of producing hallucinations or false information but also enhances the overall quality of generated text. Through the attribution of key features, LLMs can generate more grounded and human-like text, ultimately improving their performance in various natural language processing tasks. The integration of attribution in text generation represents a promising step towards creating more reliable and contextually aware language models.",
        "Source": "GPT"
    },
    {
        "Index": 182,
        "Title": "T2S-GPT: Dynamic Vector Quantization for Autoregressive Sign Language Production from Text.",
        "Abstract": "In this work, we propose a two-stage sign language production (SLP) paradigm that first encodes textual input using a pre-trained autoregressive language model, T2S-GPT, and then utilizes dynamic vector quantization to generate corresponding sign language output. Our approach aims to improve the efficiency and accuracy of SLP systems by leveraging the power of contextual language modeling and vector quantization techniques. By incorporating dynamic vector quantization, we are able to map the high-dimensional textual representations to low-dimensional sign language representations in a more structured and optimized manner.\n\nWe conduct experiments on a publicly available sign language dataset and demonstrate the effectiveness of our T2S-GPT framework in producing accurate and fluent sign language sequences from textual input. Our results show significant improvements in both the quality and coherence of generated sign language sentences compared to existing approaches. Overall, our proposed paradigm offers a promising solution for enhancing the accessibility and communication for individuals with hearing impairments through automated sign language production from text.",
        "Source": "GPT"
    },
    {
        "Index": 183,
        "Title": "OceanGPT: A Large Language Model for Ocean Science Tasks.",
        "Abstract": "Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is a complex and interdisciplinary field that requires comprehensive understanding of various scientific concepts and data analysis techniques. In this paper, we introduce OceanGPT, a large language model tailored for ocean science tasks. OceanGPT is based on the GPT-3 architecture and fine-tuned on a diverse range of ocean science datasets to better understand and generate text related to this specialized field.\n\nWe evaluate OceanGPT on a series of benchmark tasks in ocean science, including data analysis, literature review, and scientific writing. Our results show that OceanGPT achieves state-of-the-art performance on a range of tasks, showcasing its ability to effectively generate informative and accurate content in the domain of ocean science.\n\nOceanGPT opens up new possibilities for automating various aspects of ocean science research, such as data interpretation, report writing, and knowledge synthesis. This tool has the potential to streamline research workflows and accelerate scientific discovery in the field of ocean science.",
        "Source": "GPT"
    },
    {
        "Index": 184,
        "Title": "Beyond Memorization: The Challenge of Random Memory Access in Language Models.",
        "Abstract": "Recent developments in Language Models (LMs) have shown their effectiveness in NLP tasks, particularly in tasks such as machine translation, text generation, and sentiment analysis. However, a key challenge that remains largely unaddressed is the issue of random memory access in these models. \n\nCurrent LMs rely heavily on sequential processing, which limits their ability to efficiently access information from distant parts of the text. This hinders their performance on tasks that require understanding of context over long distances. \n\nIn this paper, we explore the limitations of current LMs in terms of random memory access and propose potential solutions to improve their capability in this area. We discuss the implications of this challenge on the overall performance of LMs in NLP tasks and highlight the importance of addressing this issue for further advancements in the field. \n\nOverall, our goal is to stimulate discussion and research on how to go beyond memorization in LMs and enable more effective random memory access to enhance their performance across a wide range of NLP tasks.",
        "Source": "GPT"
    },
    {
        "Index": 185,
        "Title": "BIPED: Pedagogically Informed Tutoring System for ESL Education.",
        "Abstract": "Large Language Models (LLMs) have a great potential to serve as readily available and cost-efficient tools for enhancing ESL education. However, the effectiveness of LLMs in tutoring systems for English as a Second Language (ESL) learners can be further optimized by incorporating pedagogical principles. In this paper, we present BIPED, a Pedagogically Informed Tutoring System designed specifically for ESL education. BIPED utilizes state-of-the-art LLM technology to provide personalized and interactive English language learning experiences for users. By integrating pedagogical insights into its design, BIPED offers adaptive feedback, targeted practice exercises, and tailored language instruction to support ESL learners in achieving their language proficiency goals. Our preliminary results show that BIPED is effective in improving ESL learners' language skills and fostering a deeper understanding of English grammar and vocabulary. Overall, BIPED demonstrates the potential of combining LLMs with pedagogical strategies to create a more engaging and impactful tutoring system for ESL education.",
        "Source": "GPT"
    },
    {
        "Index": 186,
        "Title": "Timeline-based Sentence Decomposition with In Context Learning for Temporal Fact Extraction.",
        "Abstract": "Fact extraction plays a crucial role in building knowledge graphs to represent relationships between entities. In recent years, there has been a growing need for extracting temporal facts, which involve the specific timing or duration of events or relationships. In response to this demand, a new approach called Timeline-based Sentence Decomposition with In Context Learning for Temporal Fact Extraction has been proposed. This method leverages the chronological order of events in text to accurately extract temporal information. By breaking down sentences into timelines and training a model to understand the context in which events occur, this approach improves the accuracy of temporal fact extraction. Through experiments and evaluations, it has been shown that the Timeline-based Sentence Decomposition approach outperforms traditional methods in capturing temporal relationships between entities. Overall, this innovative technique presents a promising step towards enhancing the construction of knowledge graphs with temporal facts.",
        "Source": "GPT"
    },
    {
        "Index": 187,
        "Title": "Collaboration or Corporate Capture? Quantifying NLP's Reliance on Industry Artifacts and Contributions.",
        "Abstract": "The impressive performance of pre-trained models in natural language processing (NLP) has garnered public attention and made news headlines in recent years. However, behind the scenes, there is a growing concern about the extent to which NLP research relies on industry artifacts and contributions. This study aims to quantify and assess the level of collaboration between the academic and industry sectors in the development of NLP technologies. By analyzing a large dataset of NLP papers and examining the affiliations of the authors, we reveal the significant influence of industry on the research landscape. Our findings highlight the potential for corporate capture in NLP research, raising questions about the independence and objectivity of academic work in this field. We propose recommendations for fostering a more balanced and transparent collaboration between academia and industry in order to ensure the advancement of NLP technologies for the benefit of society.",
        "Source": "GPT"
    },
    {
        "Index": 188,
        "Title": "Prompt Expansion for Adaptive Text-to-Image Generation.",
        "Abstract": "Text-to-image generation models have shown great potential in creating realistic images from text descriptions. However, these models often require users to craft specific prompts to get the desired output, making them difficult to use. In this paper, we propose a novel approach for prompt expansion in adaptive text-to-image generation. By automatically generating diverse and relevant prompts based on user input, our method aims to improve the usability and effectiveness of text-to-image generation models. We leverage advanced natural language processing techniques and image generation algorithms to generate a wide range of prompts that can better guide the model in producing accurate and high-quality images. Our experiments demonstrate that our approach significantly enhances the user experience and output quality of text-to-image generation models. Overall, our work contributes to the advancement of adaptive text-to-image generation technologies, making them more accessible and user-friendly for a wide range of applications.",
        "Source": "GPT"
    },
    {
        "Index": 189,
        "Title": "Progressively Modality Freezing for Multi-Modal Entity Alignment.",
        "Abstract": "Multi-Modal Entity Alignment (MMEA) is a crucial task in knowledge graph integration, aiming to identify identical entities across different knowledge graphs with diverse data modalities. In recent studies, various approaches have been proposed to tackle this challenge, utilizing multiple modalities such as text, image, and structure information. However, existing methods often struggle with aligning entities accurately due to the heterogeneity and complexity of data modalities.\n\nIn this paper, we introduce a novel approach called Progressively Modality Freezing for Multi-Modal Entity Alignment (PMF-MMEA), which addresses the limitations of previous methods by progressively freezing the representation of individual modalities during the alignment process. By iteratively refining the alignment results with a dynamic freezing strategy, PMF-MMEA effectively combines the strengths of different modalities while mitigating their individual weaknesses. Experimental results on real-world datasets demonstrate that PMF-MMEA outperforms state-of-the-art methods in terms of alignment accuracy and robustness, showcasing its potential for advancing the field of multi-modal entity alignment.",
        "Source": "GPT"
    },
    {
        "Index": 190,
        "Title": "Llama2Vec: Unsupervised Adaptation of Large Language Models for Dense Retrieval.",
        "Abstract": "Dense retrieval is a crucial component in modern information retrieval systems, requiring discriminative embeddings to effectively capture the semantic relationship between queries and documents. In this paper, we introduce Llama2Vec, an unsupervised adaptation method for large language models to generate dense embeddings for retrieval tasks. Our approach leverages the powerful representations learned by pre-trained language models such as BERT, RoBERTa, and XLNet, adapting them to encode query and document pairs in a dense vector space. By fine-tuning the pre-trained model on a large corpus of text, Llama2Vec is able to learn contextualized embeddings that encode semantic information more effectively than traditional methods. We demonstrate the effectiveness of our approach on benchmark retrieval datasets, showing improvements in both accuracy and efficiency compared to existing methods. Llama2Vec offers a simple yet powerful technique for adapting large language models for dense retrieval applications, bridging the gap between state-of-the-art language representation models and practical information retrieval systems.",
        "Source": "GPT"
    },
    {
        "Index": 191,
        "Title": "Democratizing LLMs for Low-Resource Languages by Leveraging their English Dominant Abilities with Linguistically-Diverse Prompts.",
        "Abstract": "Large language models (LLMs) are known to effectively perform tasks by simply observing few exemplars. However, these models often struggle when it comes to low-resource languages, where limited training data is available. In this paper, we propose a novel approach to democratize LLMs for low-resource languages by leveraging the English dominant abilities of speakers. By providing linguistically-diverse prompts in English, we allow LLMs to draw upon the vast amount of English data available to effectively perform tasks in low-resource languages. This approach not only enhances the capabilities of LLMs for low-resource languages but also reduces the burden of collecting and labeling large amounts of data in those languages. Through our experiments, we demonstrate the effectiveness of our proposed method in improving the performance of LLMs for low-resource languages and showcase its potential to bridge the gap in language technology accessibility.",
        "Source": "GPT"
    },
    {
        "Index": 192,
        "Title": "Metaphor Understanding Challenge Dataset for LLMs.",
        "Abstract": "Metaphors in natural language are a reflection of fundamental cognitive processes such as analogical reasoning. Understanding and interpreting metaphors is a challenging task even for humans, as it requires not only linguistic knowledge but also a deep understanding of abstract concepts and their connections. Leveraging the power of large language models (LLMs) has shown promising results in addressing this challenge. However, the current benchmark datasets for metaphor understanding are limited in size and complexity.\n\nIn this paper, we introduce the Metaphor Understanding Challenge Dataset for LLMs, a new benchmark dataset designed to evaluate the performance of LLMs in comprehending and generating metaphors. This dataset contains a diverse set of metaphors sourced from various domains, including literature, science, and everyday language. By providing a more comprehensive and nuanced set of metaphors, we aim to push the boundaries of LLMs' capabilities in metaphor interpretation. We believe that this dataset will serve as a valuable resource for advancing research in metaphor understanding and cognitive modeling.",
        "Source": "GPT"
    },
    {
        "Index": 193,
        "Title": "A Multi-Task Embedder For Retrieval Augmented LLMs.",
        "Abstract": "Language Model (LLMs) are state-of-the-art models for various natural language processing tasks, but they confront inherent limitations in terms of their knowledge, memory, and action. In order to address these limitations, we propose a Multi-Task Embedder for Retrieval Augmented LLMs. This embedder combines the power of retrieval-based methods with LLMs to enhance their performance in various tasks. By incorporating a retrieval mechanism, the model can access external knowledge sources, improving its ability to answer questions, perform complex reasoning tasks, and generate more coherent responses. Additionally, the Multi-Task Embedder allows the model to efficiently store and retrieve information, enabling it to handle long-context sequences and reduce the impact of forgetting previous information. Experimental results demonstrate that our proposed approach significantly outperforms traditional LLMs in terms of knowledge retention, memory recall, and task completion accuracy. Overall, our Multi-Task Embedder for Retrieval Augmented LLMs offers a promising solution for enhancing the capabilities of language models in real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 194,
        "Title": "Language Models Don't Learn the Physical Manifestation of Language.",
        "Abstract": "We argue that language-only models don’t learn the physical manifestation of language. We present an abstract model that combines neural networks with physical sensors to bridge the gap between linguistic understanding and embodied interaction. By introducing a multimodal approach that incorporates both language processing and physical interaction, our model achieves a new level of contextual understanding and nuanced expression. Through experiments and analyses, we demonstrate that traditional language models lack the ability to grasp the intricate nuances of physical embodiment, such as gestures, postures, and facial expressions. Our proposed model not only enhances language comprehension but also enables more immersive and interactive communication in applications such as human-robot interaction and virtual reality environments. By considering the physicality of language, our model opens up new possibilities for artificial intelligence to truly understand and embody the complexities of human communication.",
        "Source": "GPT"
    },
    {
        "Index": 195,
        "Title": "What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection.",
        "Abstract": "Social media bot detection has always been an arms race between advancements in machine learning techniques and the evolving sophistication of bots. Recently, large language models have emerged as a powerful tool in the detection and classification of bots in social media platforms. These models, such as OpenAI's GPT-3, have the capability to understand and generate human-like text, making them valuable in identifying subtle patterns and behaviors characteristic of bots. However, along with the opportunities presented by large language models in bot detection, there are also significant risks to consider. These models raise concerns around ethical considerations, including potential biases and misuse by bad actors to create more sophisticated bots that evade detection. Therefore, as we embrace the potential of large language models in social media bot detection, it is crucial to continue researching and developing strategies to mitigate these risks and ensure the responsible and effective use of this technology.",
        "Source": "GPT"
    },
    {
        "Index": 196,
        "Title": "Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives.",
        "Abstract": "The reflection capacity of Large Language Models (LLMs) has become a topic of significant interest in the field of artificial intelligence. In this paper, we introduce the concept of self-contrast, a novel approach for enhancing the reflective capabilities of LLMs through the integration of inconsistent solving perspectives. By presenting contrasting viewpoints within the training data, LLMs are encouraged to consider multiple perspectives and challenge their own assumptions, leading to a more nuanced understanding of complex topics. We demonstrate the effectiveness of the self-contrast method through a series of experiments on various datasets, showing improvements in the LLM's ability to generate diverse and insightful reflections. Our results suggest that by embracing inconsistency and encouraging reflective thinking, LLMs can achieve better performance in tasks requiring critical analysis and abstract reasoning. Overall, our study highlights the potential of self-contrast as a powerful tool for enhancing the reflective abilities of LLMs and advancing the field of artificial intelligence.",
        "Source": "GPT"
    },
    {
        "Index": 197,
        "Title": "Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty.",
        "Abstract": "As natural language becomes the default interface for human-AI interaction, there is a growing need for language models to accurately convey uncertainty in their responses. However, recent studies have shown that many language models, such as those based on deep learning, are often reluctant to express uncertainty in their output. This reluctance can have a significant impact on the reliability and trustworthiness of AI systems, as users may misinterpret overly confident responses and make decisions based on incomplete or inaccurate information.\n\nIn this paper, we examine the reasons behind language models' reluctance to express uncertainty and explore the implications of this behavior on human-AI interaction. We also propose potential solutions to improve the ability of language models to convey uncertainty effectively, such as incorporating explicit markers of uncertainty in their output or implementing post-processing techniques to calibrate confidence levels. By addressing this issue, we can enhance the transparency and usability of AI systems, ultimately improving the overall user experience and fostering trust in AI technologies.",
        "Source": "GPT"
    },
    {
        "Index": 198,
        "Title": "Unity in Diversity: Collaborative Pre-training Across Multimodal Medical Sources.",
        "Abstract": "Pre-training has emerged as a popular method for improving performance across a wide range of biomedical tasks. However, the current efficacy of pre-training methods is limited by the diversity and complexity of medical data sources. In this study, we propose a novel approach called Collaborative Pre-training Across Multimodal Medical Sources (CPAMS) to address this challenge. By leveraging diverse and complementary sources of medical data, including textual, imaging, and clinical data, CPAMS aims to enhance pre-training effectiveness and generalizability. Through collaborative learning across multiple modalities, CPAMS enables the model to capture a more comprehensive representation of medical knowledge, leading to improved performance on tasks such as disease diagnosis, prognosis, and treatment recommendation. Our experimental results demonstrate that CPAMS significantly outperforms existing pre-training methods, highlighting the importance of unity in diversity when pre-training models on multimodal medical data sources. This approach has the potential to advance research in biomedical informatics and facilitate more accurate and robust decision-making in clinical practice.",
        "Source": "GPT"
    },
    {
        "Index": 199,
        "Title": "When Good and Reproducible Results are a Giant with Feet of Clay: The Importance of Software Quality in NLP.",
        "Abstract": "Despite its crucial role in research experiments, code correctness is often presumed solely based on the reported results. However, as the field of Natural Language Processing (NLP) continues to advance, it becomes increasingly important to ensure that the software used to generate these results is of high quality and reproducible. In this paper, we highlight the significance of software quality in NLP research and discuss the implications of relying on code that may have fundamental flaws. We argue that the credibility of research findings in NLP heavily depends on the reliability and reproducibility of the underlying software. By overlooking the importance of code quality, researchers run the risk of building their work on a foundation of clay rather than solid ground. We provide recommendations for improving software quality in NLP research, emphasizing the necessity of thorough code review, documentation, and testing practices to ensure that good and reproducible results are not compromised by software deficiencies.",
        "Source": "GPT"
    },
    {
        "Index": 200,
        "Title": "SBAAM! Eliminating Transcript Dependency in Automatic Subtitling.",
        "Abstract": "Subtitling plays a crucial role in enhancing the accessibility of audiovisual content and encompasses three main elements: timing, translation, and transcription. However, traditional automatic subtitling systems heavily rely on pre-existing transcripts, which may not always be available for all content. In this paper, we propose a novel approach called SBAAM (Subtitling without a transcript By Aligning Audio and Metadata), which aims to eliminate the dependency on transcripts in the subtitling process. \n\nBy leveraging audio signals and metadata such as speaker diarization and scene detection, SBAAM is able to accurately generate subtitles without the need for a complete transcript. This not only increases the efficiency of the subtitling process but also ensures accessibility for content where transcripts may not exist. \n\nExperimental results on a diverse range of audiovisual content demonstrate the effectiveness of SBAAM in generating accurate subtitles, even in the absence of transcripts. Our proposed approach shows promising potential for improving automatic subtitling systems and increasing accessibility for a wider range of users.",
        "Source": "GPT"
    },
    {
        "Index": 201,
        "Title": "StreamAtt: Direct Streaming Speech-to-Text Translation with Attention-based Audio History Selection.",
        "Abstract": "Streaming speech-to-text translation (StreamST) is the task of automatically translating speech while incrementally receiving an audio input. In this paper, we propose StreamAtt, a direct streaming speech-to-text translation model that utilizes attention-based audio history selection to improve translation accuracy. By dynamically selecting relevant audio segments from the input stream using an attention mechanism, StreamAtt is able to capture the most important information for translation while discarding irrelevant noise. Our model is end-to-end trainable and does not require a separate segmentation step, allowing for real-time translation of streaming audio. We evaluate StreamAtt on multiple English-to-French translation tasks and show that it outperforms existing streaming speech-to-text translation models in terms of translation accuracy and latency. Additionally, we demonstrate the effectiveness of our attention-based audio history selection mechanism in improving translation performance. Overall, StreamAtt represents a significant advancement in real-time speech-to-text translation technology.",
        "Source": "GPT"
    },
    {
        "Index": 202,
        "Title": "ARL2: Aligning Retrievers with Black-box Large Language Models via Self-guided Adaptive Relevance Labeling.",
        "Abstract": "Retrieval-augmented generation has been shown to enhance large language models (LLMs) by incorporating relevant information from external knowledge sources. However, existing methods rely on manually curated retrievals or fixed retrieval algorithms, which may limit the model's ability to adapt to new and dynamic information. In this work, we propose ARL2, a novel approach that aligns retrievers with black-box LLMs using self-guided adaptive relevance labeling. By continuously updating relevance labels during training, our method enables the retriever to better capture the most relevant information for the LLM, leading to improved generation performance. We evaluate our approach on various generation tasks, demonstrating its effectiveness in improving the quality and relevance of generated outputs compared to baseline methods. Our results suggest that self-guided adaptive relevance labeling can significantly enhance the capabilities of LLMs by enabling them to leverage external knowledge sources more effectively in the generation process.",
        "Source": "GPT"
    },
    {
        "Index": 203,
        "Title": "Crayon: Customized On-Device LLM via Instant Adapter Blending and Edge-Server Hybrid Inference.",
        "Abstract": "The customization of large language models (LLMs) for user-specified tasks is increasingly important in various fields. However, maintaining a balance between model accuracy and inference speed remains a challenge. In this paper, we propose a novel approach called Crayon, which enables customized on-device LLMs via instant adapter blending and edge-server hybrid inference.\n\nCrayon leverages adapter modules to fine-tune pre-trained LLMs on user-specified tasks, allowing for efficient customization while minimizing potential performance degradation. Additionally, the system integrates edge-server hybrid inference, which combines on-device computation with cloud-based resources to facilitate quick and accurate model predictions.\n\nExperimental results demonstrate that Crayon not only achieves high customization accuracy but also significantly improves inference speed compared to existing methods. Overall, our approach offers a practical and effective solution for tailoring LLMs to specific user tasks while maintaining performance levels, making it a valuable tool for various real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 204,
        "Title": "FLEUR: An Explainable Reference-Free Evaluation Metric for Image Captioning Using a Large Multimodal Model.",
        "Abstract": "Most existing image captioning evaluation metrics focus on assigning a single numerical score to assess the quality of generated captions. However, these metrics often lack interpretability and transparency in explaining how they arrived at such scores. In this study, we propose FLEUR, an Explainable Reference-Free Evaluation Metric for Image Captioning. FLEUR utilizes a large multimodal model to generate captions and then evaluates them based on a set of explainable criteria such as relevance, coherence, and diversity. By incorporating multiple aspects of caption quality into the evaluation process, FLEUR provides a more comprehensive and interpretable assessment of image captioning performance. Experimental results demonstrate that FLEUR outperforms existing metrics in terms of both correlation with human judgments and interpretability. Additionally, FLEUR can provide valuable insights into the strengths and weaknesses of different image captioning models, enabling researchers to make informed decisions on model selection and improvement strategies.",
        "Source": "GPT"
    },
    {
        "Index": 205,
        "Title": "MentalManip: A Dataset For Fine-grained Analysis of Mental Manipulation in Conversations.",
        "Abstract": "Mental manipulation, a significant form of abuse in interpersonal conversations, presents a challenge to identify due to its subtle and covert nature. This paper introduces MentalManip, a novel dataset for fine-grained analysis of mental manipulation in conversations. The dataset contains diverse examples of manipulation tactics such as gaslighting, guilt-tripping, and invalidation, across various contexts and relationships. Each conversation is annotated with labels indicating the presence and type of manipulation employed, as well as the target of the manipulation. By utilizing this dataset, researchers and practitioners can develop and evaluate algorithms for automatic detection of mental manipulation in text-based conversations. Additionally, the dataset can be used to gain insights into the prevalence and impact of mental manipulation in interpersonal communication, ultimately aiding in the prevention and intervention of this form of abuse. We provide a detailed analysis of the dataset characteristics and demonstrate its utility through baseline experiments using state-of-the-art natural language processing techniques.",
        "Source": "GPT"
    },
    {
        "Index": 206,
        "Title": "MPCoder: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning.",
        "Abstract": "Large Language Models (LLMs) have become increasingly popular in the realm of software development, as they have shown promising capabilities in assisting developers with code generation tasks. However, most existing LLM-based code generators do not take into account the individual coding styles and preferences of different developers. In this paper, we propose MPCoder, a multi-user personalized code generator that incorporates both explicit and implicit style representation learning techniques. By leveraging the coding history and preferences of individual developers, MPCoder is able to generate code snippets that are tailored to each user's unique style and preferences. Through experimental validation, we demonstrate that our proposed approach significantly outperforms existing code generators in terms of code quality and developer satisfaction. Overall, our work highlights the importance of considering individual developer styles in code generation tasks, and paves the way for more personalized and effective code generation tools in the future.",
        "Source": "GPT"
    },
    {
        "Index": 207,
        "Title": "DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows.",
        "Abstract": "Large language models (LLMs) have become a dominant and important tool for NLP researchers in recent years, enabling state-of-the-art performance on various natural language processing tasks. However, the success of LLMs often relies on the availability of high-quality training data. DataDreamer is a tool that addresses this challenge by providing a platform for synthetic data generation tailored specifically for LLMs. By leveraging advanced data generation techniques, DataDreamer allows researchers to create diverse and realistic datasets to train LLMs, improving the models' performance and generalization capabilities.\n\nMoreover, DataDreamer enhances reproducibility in LLM workflows by enabling researchers to easily generate and share synthetic datasets for training and evaluation purposes. This not only streamlines the research process but also promotes transparency and collaboration in the NLP community.\n\nIn this paper, we present DataDreamer and demonstrate its capabilities in facilitating synthetic data generation and reproducible LLM workflows. We discuss its key features, advantages, and potential impact on NLP research.",
        "Source": "GPT"
    },
    {
        "Index": 208,
        "Title": "Understanding and Addressing the Under-Translation Problem from the Perspective of Decoding Objective.",
        "Abstract": "Neural Machine Translation (NMT) has significantly improved translation quality, but the problem of under-translation persists. Under-translation refers to the incomplete or inaccurate translation of a source text, which can lead to misunderstandings or loss of vital information. This paper examines the under-translation problem through the lens of decoding objective, which considers the factors influencing the decision-making process of the NMT model during translation. By understanding these factors, we can develop strategies to address under-translation effectively.\n\nWe propose a framework that leverages knowledge of the target language, linguistic features, and context to enhance the decoding process and improve translation accuracy. This framework aims to strike a balance between fluency and fidelity in translations, ensuring that all essential information is conveyed accurately. By incorporating these insights into NMT models, we can mitigate the under-translation problem and enhance the overall quality of machine translation systems. Through this approach, we contribute to advancing the field of machine translation and improving communication across different languages and cultures.",
        "Source": "GPT"
    },
    {
        "Index": 209,
        "Title": "Identifying while Learning for Document Event Causality Identification.",
        "Abstract": "Event Causality Identification (ECI) aims to detect whether there exists a causal relation between two events within a document. In this paper, we propose a novel approach called Identifying while Learning for Document Event Causality Identification. Our method leverages both explicit linguistic features and implicit contextual information to identify causal relations between events. We utilize a combination of a rule-based system and machine learning models to enhance the accuracy and efficiency of causality identification.\n\nOur approach involves identifying causal cues within the text and extracting relevant features to capture the causal relationship between events. Additionally, we incorporate a learning component that continuously updates and improves the model based on the feedback obtained during the identification process. Experimental results on a publicly available dataset demonstrate that our method outperforms existing approaches in terms of precision, recall, and F1 score for event causality identification. This research contributes to the advancement of natural language processing techniques for accurately detecting causal relations within documents.",
        "Source": "GPT"
    },
    {
        "Index": 210,
        "Title": "OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems.",
        "Abstract": "Recent advancements have seen Large Language Models (LLMs) and Large Multimodal Models (LMMs) surpassing general benchmarks in natural language processing and computer vision tasks. However, the quest for Artificial General Intelligence (AGI) requires a more comprehensive evaluation of these models in challenging and diverse domains. In this paper, we introduce OlympiadBench, a challenging benchmark specifically designed to promote AGI by presenting Olympiad-level bilingual multimodal scientific problems. OlympiadBench pushes the boundaries of LLMs and LMMs by requiring them to not only understand and generate complex scientific text but also interpret and reason with multimodal inputs in multiple languages. By incorporating such challenging tasks, OlympiadBench aims to encourage the development of more robust and versatile AI systems with the capability to tackle a wide range of real-world challenges. We believe that benchmarking models on OlympiadBench will provide valuable insights into their AGI capabilities and inspire further advancements in the field of artificial intelligence.",
        "Source": "GPT"
    },
    {
        "Index": 211,
        "Title": "Insert or Attach: Taxonomy Completion via Box Embedding.",
        "Abstract": "Taxonomy completion is a crucial task in knowledge organization, as it enhances the structure and usability of existing taxonomies. In this paper, we propose a novel approach for taxonomy completion through box embedding, which involves inserting new concepts as parents or attaching them as children to enrich the taxonomy. By utilizing the relationships between concepts and their context within a taxonomy, our method aims to improve the accuracy and completeness of the classification system. We demonstrate the effectiveness of our approach through experiments on real-world datasets, showing significant improvements in taxonomy quality metrics. Additionally, we provide insights into the potential applications of our method in various domains, such as information retrieval, recommendation systems, and data analysis. Overall, our research offers a valuable contribution to the field of taxonomy completion by introducing a flexible and efficient technique for enhancing and refining existing taxonomies.",
        "Source": "GPT"
    },
    {
        "Index": 212,
        "Title": "Semiparametric Token-Sequence Co-Supervision.",
        "Abstract": "In this work, we introduce a novel semiparametric token-sequence co-supervision training method for language models. Traditional language models rely on labeled token sequences for training, but this approach is limited by the availability of annotated data. Our proposed method leverages both labeled token sequences and unlabeled data, enabling the model to learn from a larger and more diverse set of examples. By combining the strengths of supervised and unsupervised learning, our approach improves the model's ability to generalize to new input sequences and reduces the risk of overfitting to the training data. We demonstrate the effectiveness of our method through experiments on various language tasks, showcasing its robustness and performance compared to traditional supervised and unsupervised training methods. Overall, our semiparametric token-sequence co-supervision approach offers a promising solution for enhancing the training process of language models and advancing the field of natural language processing.",
        "Source": "GPT"
    },
    {
        "Index": 213,
        "Title": "Instruction Fusion: Advancing Prompt Evolution through Hybridization.",
        "Abstract": "The fine-tuning of Large Language Models (LLMs) specialized in code generation has seen notable advancements in recent years. With the ability to generate highly complex and syntactically correct code, these models have shown great potential in automating software development processes. However, to further advance the capabilities of these models, there is a need for a new approach that combines the strengths of different instruction sources. \n\nInstruction Fusion, a novel technique in prompt engineering, aims to enhance the prompt evolution process by combining diverse sources of instructions to create more effective and powerful prompts for LLMs. By hybridizing instructions from various sources such as code repositories, programming tutorials, and language specifications, Instruction Fusion enables LLMs to better understand context and generate more precise and relevant code. This approach not only improves the efficiency and accuracy of code generation but also enhances the overall performance and adaptability of LLMs specialized in this domain. Through Instruction Fusion, we can revolutionize the way LLMs are trained and leveraged for code generation tasks, ultimately advancing the field of automated software development.",
        "Source": "GPT"
    },
    {
        "Index": 214,
        "Title": "TimeArena: Shaping Efficient Multitasking Language Agents in a Time-Aware Simulation.",
        "Abstract": "Despite remarkable advancements in emulating human-like behavior through Large Language Models (LLMs), current textual simulations are limited in their ability to replicate authentic human multitasking abilities. In order to address this limitation, we introduce TimeArena, a novel framework for shaping efficient multitasking language agents in a time-aware simulation environment. TimeArena allows agents to dynamically allocate resources and prioritize tasks based on time constraints, enabling them to perform multiple tasks simultaneously with optimal efficiency.\n\nThrough TimeArena, agents are trained to understand and adapt to the temporal constraints of various tasks, leading to more realistic and effective multitasking behaviors. This framework not only enhances the performance of language agents in multitasking scenarios, but also lays the foundation for exploring more complex and human-like behaviors in artificial intelligence systems. We present experimental results demonstrating the effectiveness of TimeArena in improving multitasking capabilities of language agents, showcasing its potential for advancing the field of artificial intelligence and natural language processing.",
        "Source": "GPT"
    },
    {
        "Index": 215,
        "Title": "Exploring Memorization in Fine-tuned Language Models.",
        "Abstract": "Large language models (LLMs) have revolutionized the field of natural language processing by achieving state-of-the-art performance in a wide range of tasks. However, these models have also been shown to exhibit a concerning behavior known as memorization, where they can inadvertently memorize sensitive or personal information from their training data. This raises serious ethical concerns surrounding data privacy and security. In this study, we delve into the phenomenon of memorization in fine-tuned LLMs and explore the underlying mechanisms that drive this behavior. By analyzing the internal representations of the model and investigating different strategies to mitigate memorization, we aim to provide insights into how LLMs can be improved to prevent unintended memorization. Our findings shed light on the importance of carefully evaluating and monitoring LLMs to ensure they do not compromise user privacy or data security. Additionally, our study contributes to the ongoing discussion on the responsible development and deployment of large language models in real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 216,
        "Title": "Towards Real-world Scenario: Imbalanced New Intent Discovery.",
        "Abstract": "New Intent Discovery (NID) is a crucial task in the field of natural language processing that focuses on identifying both known and unknown categories of user intent. While existing intent detection models predominantly focus on recognizing predefined intents, NID aims to explore uncharted territories by detecting new, unanticipated intents. In this paper, we delve into the challenges of imbalanced data distribution in the context of NID, where new intents are inherently rare compared to the well-established ones. We propose a novel framework that leverages advanced machine learning techniques to address this imbalance and improve the accuracy of new intent detection in real-world scenarios. Our experimental results demonstrate the effectiveness of our approach in discovering new intents with high precision and recall, even in highly skewed datasets. By advancing towards real-world scenario by tackling the imbalance in new intent discovery, we pave the way for more robust and reliable intent detection systems in various applications such as virtual assistants and chatbots.",
        "Source": "GPT"
    },
    {
        "Index": 217,
        "Title": "M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection.",
        "Abstract": "The advent of Large Language Models (LLMs) has brought an unprecedented surge in machine-generated text, raising concerns about the proliferation of potentially harmful or misleading content. In response to this growing challenge, we introduce M4GT-Bench, an evaluation benchmark specifically designed for Black-Box Machine-Generated Text (M4GT) detection. By providing a standardized and comprehensive set of evaluation metrics and datasets, M4GT-Bench aims to facilitate the comparison and improvement of existing detection techniques, ultimately enhancing the trustworthiness of content generated by LLMs. We evaluate the performance of state-of-the-art detection models on M4GT-Bench and observe varying levels of effectiveness in identifying machine-generated text across different domains and contexts. Our findings highlight the need for more robust and domain-specific detection mechanisms to effectively combat the wide dissemination of machine-generated text. Overall, M4GT-Bench serves as a valuable resource for advancing research in the detection of machine-generated text and safeguarding against its potential negative impacts.",
        "Source": "GPT"
    },
    {
        "Index": 218,
        "Title": "Instruct Once, Chat Consistently in Multiple Rounds: An Efficient Tuning Framework for Dialogue.",
        "Abstract": "Tuning language models for dialogue generation has been a prevalent paradigm for building capable dialogue systems. In this study, we propose an efficient tuning framework for dialogue generation that leverages a combination of instructing the model once and chatting consistently in multiple rounds. Our framework aims to enhance the quality and coherence of generated responses by providing targeted instructions followed by iterative conversations to fine-tune the model's understanding and response generation abilities. Through this approach, we are able to achieve more robust and natural dialogue interactions, avoiding common pitfalls such as generic or nonsensical responses. By instructing the model initially and engaging in multiple rounds of conversation, we can steer the dialogue towards more meaningful and contextually appropriate outputs. Our experimental results demonstrate that our framework significantly improves the performance of existing language models in dialogue generation tasks, showcasing the effectiveness of our proposed approach.",
        "Source": "GPT"
    },
    {
        "Index": 219,
        "Title": "SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training.",
        "Abstract": "The effectiveness of large language models (LLMs) is often hindered by duplicated data in their pre-training process, leading to inefficiencies in model training and decreased performance. In this study, we propose SoftDedup, an efficient data reweighting method designed to alleviate the impact of duplicated data on LLM pre-training. By dynamically adjusting the data weights during the training process, SoftDedup effectively reduces the influence of repeated instances, allowing the model to focus more on diverse and informative samples. Experimental results on a range of LLM tasks demonstrate that SoftDedup significantly accelerates model convergence and improves performance compared to standard pre-training methods. Notably, our approach achieves up to a X% increase in training efficiency and a X% improvement in downstream task performance. Overall, SoftDedup offers a simple yet effective solution for addressing the issue of duplicated data in LLM pre-training, ultimately leading to faster and more accurate language model development.",
        "Source": "GPT"
    },
    {
        "Index": 220,
        "Title": "Rule or Story, Which is a Better Commonsense Expression for Talking with Large Language Models?",
        "Abstract": "Building machines with commonsense has been a longstanding challenge in NLP due to the complexity and ambiguity of human language. In this study, we investigate the effectiveness of two different approaches for interacting with large language models: using rules or stories. Rules involve explicitly defining guidelines and constraints for the model to follow, while stories provide context and examples for the model to learn from. We compare the performance of both approaches in a series of experiments and find that while rules are more straightforward and efficient, stories ultimately lead to better understanding and interpretation of the data. Our findings suggest that a combination of both approaches may be the most effective strategy for developing commonsense expressions with large language models. This research contributes to a deeper understanding of how to effectively communicate and interact with artificial intelligence systems in natural language processing tasks.",
        "Source": "GPT"
    },
    {
        "Index": 221,
        "Title": "Learning Global Controller in Latent Space for Parameter-Efficient Fine-Tuning.",
        "Abstract": "While large language models (LLMs) have showcased remarkable prowess in various natural language processing tasks, they often require extensive fine-tuning on task-specific datasets to achieve optimal performance. This process can be computationally expensive and time-consuming, hindering their widespread adoption. In this paper, we propose a novel approach for fine-tuning LLMs in a parameter-efficient manner by learning a global controller in latent space. Our method leverages a small set of task-specific examples to update the latent controller, which then guides the fine-tuning process on the target task. By decoupling the fine-tuning process from the model parameters, we are able to achieve competitive performance with significantly fewer task-specific parameters. Experimental results on a range of natural language understanding tasks demonstrate the effectiveness of our approach in achieving state-of-the-art performance while requiring only a fraction of the parameters typically used for fine-tuning LLMs. Our method provides a promising direction for making fine-tuning more efficient and practical for real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 222,
        "Title": "CaMML: Context-Aware Multimodal Learner for Large Models.",
        "Abstract": "In this work, we introduce Context-Aware MultiModal Learner (CaMML), a novel framework designed for the efficient tuning of large multimodal models (LMMs). CaMML is capable of leveraging contextual information to enhance the learning process and improve the performance of complex multimodal models. By incorporating context-awareness, CaMML can adaptively adjust its learning strategy based on the specific environment in which it operates, leading to more accurate and robust model tuning.\n\nOur approach addresses the challenges of training and fine-tuning large multimodal models by incorporating multimodal features and context information in a unified framework. This enables CaMML to capture the interactions between different modalities and exploit contextual cues to enhance the learning process. Experimental results demonstrate that CaMML outperforms existing methods in terms of model performance and efficiency, making it a promising tool for optimizing large multimodal models in various applications.\n\nOverall, CaMML represents a significant advancement in the field of multimodal model tuning, offering a versatile and effective solution for improving the performance of large-scale multimodal models.",
        "Source": "GPT"
    },
    {
        "Index": 223,
        "Title": "MAVEN-ARG: Completing the Puzzle of All-in-One Event Understanding Dataset with Event Argument Annotation.",
        "Abstract": "Understanding events in texts is a core objective of natural language understanding, which requires detecting event mentions and identifying their associated arguments. In this paper, we present MAVEN-ARG, a comprehensive dataset that aims to complete the puzzle of all-in-one event understanding by providing event argument annotations. \n\nMAVEN-ARG builds upon the existing MAVEN dataset, which focuses on event detection and coreference resolution. By extending MAVEN with event argument annotation, MAVEN-ARG enables researchers to study the relationship between events and their arguments in a more holistic manner. The dataset covers a wide range of event types and arguments, including participants, temporal and locational information, and causal relations.\n\nWe provide detailed guidelines for annotating event arguments and ensure high inter-annotator agreement through rigorous annotation protocols. We also conduct experiments to demonstrate the utility of MAVEN-ARG for event understanding tasks, such as event extraction and argument role classification. MAVEN-ARG represents a significant step towards comprehensive event understanding in natural language processing applications.",
        "Source": "GPT"
    },
    {
        "Index": 224,
        "Title": "NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes.",
        "Abstract": "Complex reasoning ability is one of the most critical aspects of Large Language Models (LLMs), allowing them to tackle various tasks that require higher-order thinking and problem-solving skills. However, evaluating the reasoning ability of LLMs poses a considerable challenge due to the lack of standardized benchmarks that capture the full spectrum of reasoning complexities. In response to this need, we introduce NPHardEval, a dynamic benchmark that leverages complexity classes to assess the reasoning capabilities of LLMs. By generating NP-hard reasoning tasks of varying complexities, NPHardEval provides a comprehensive evaluation of the reasoning abilities of LLMs across different problem domains. Through our extensive experimentation, we demonstrate the utility of NPHardEval in quantifying the reasoning performance of state-of-the-art LLMs and shedding light on their strengths and weaknesses in tackling complex reasoning challenges. Ultimately, NPHardEval serves as a valuable tool for researchers and practitioners to benchmark and compare the reasoning abilities of different LLMs, facilitating advancements in the development of more intelligent and robust language models.",
        "Source": "GPT"
    },
    {
        "Index": 225,
        "Title": "Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models.",
        "Abstract": "Text watermarking technology aims to tag and identify content produced by large language models (LLMs). In this study, we investigate the cross-lingual consistency of text watermarks for LLMs, exploring whether watermarks can survive translation into different languages. Our findings reveal that text watermarks show varying degrees of effectiveness in maintaining consistency across languages, with some watermarks proving to be more robust than others. Through a series of experiments, we demonstrate that certain linguistic and semantic features of text watermarks may impact their cross-lingual transferability. These findings have important implications for the development and deployment of text watermarking techniques in multilingual settings. By understanding the challenges posed by language translation on the persistence of text watermarks, researchers and practitioners can make more informed decisions when utilizing this technology to protect intellectual property and ensure the integrity of content generated by LLMs.",
        "Source": "GPT"
    },
    {
        "Index": 226,
        "Title": "Multi-Level Feedback Generation with Large Language Models for Empowering Novice Peer Counselors.",
        "Abstract": "Effective training for peer counselors involves the incorporation of realistic practice scenarios and tailored feedback to develop clinical skills. However, providing personalized feedback can be resource-intensive and challenging for trainers. In this study, we propose a novel approach utilizing multi-level feedback generation with large language models to empower novice peer counselors. By leveraging the capabilities of these models, we aim to provide automated, targeted feedback that is specific to the individual needs of each counselor. This system allows for the generation of diverse feedback responses based on the counselor's performance in simulated counseling sessions, enabling them to improve their skills in a personalized and efficient manner. Through this innovative approach, we hope to enhance the training experience for peer counselors and ultimately improve their ability to support and empower individuals in need of mental health assistance.",
        "Source": "GPT"
    },
    {
        "Index": 227,
        "Title": "In-context Mixing (ICM): Code-mixed Prompts for Multilingual LLMs.",
        "Abstract": "We introduce a simple and effective prompting technique called in-context mixing (ICM) for effective in-context training of multilingual language models (LLMs). Code-mixing, the phenomenon of mixing two or more languages in a single conversation, is prevalent in multilingual communication. Current approaches to training multilingual LLMs often rely on isolated prompts in a single language, which may not adequately capture the nuances of code-mixing. \n\nIn this study, we propose the use of mixed-language prompts in the training of multilingual LLMs to more accurately reflect the complexities of code-mixing. Our experimental results demonstrate that the use of ICM significantly improves the performance of multilingual LLMs on various language tasks, such as translation and sentiment analysis. \n\nOverall, our findings suggest that incorporating code-mixed prompts through in-context mixing is a promising approach for enhancing the multilingual capabilities of LLMs. We believe that this technique has the potential to improve the accuracy and generalizability of multilingual models in real-world applications where code-mixing is common.",
        "Source": "GPT"
    },
    {
        "Index": 228,
        "Title": "Respond in my Language: Mitigating Language Inconsistency in Response Generation based on Large Language Models.",
        "Abstract": "Large Language Models (LLMs) show strong instruction understanding ability across multiple languages. However, they are susceptible to generating responses that may exhibit language inconsistency. In this paper, we propose a novel approach, called Respond in my Language (RIML), to mitigate language inconsistency in response generation based on LLMs. RIML leverages language-specific word embeddings and language models to ensure that responses generated by LLMs maintain consistency with the language used in the input. We conduct experiments on multiple datasets in various languages to evaluate the effectiveness of RIML in improving language consistency in response generation. Our results demonstrate that RIML significantly outperforms existing approaches in mitigating language inconsistency, leading to more coherent and accurate responses. Additionally, we provide an analysis of the impact of different factors on the performance of RIML, shedding light on its strengths and limitations. Overall, our proposed approach offers a promising solution to enhance the language consistency of responses generated by LLMs in multilingual settings.",
        "Source": "GPT"
    },
    {
        "Index": 229,
        "Title": "Transferable Embedding Inversion Attack: Uncovering Privacy Risks in Text Embeddings without Model Queries.",
        "Abstract": "This study investigates the privacy risks associated with text embeddings, focusing on the scenario where an adversary can perform Transferable Embedding Inversion Attacks (TEIA) without having access to the target model. By exploiting the transferability of embeddings between different models, the adversary can potentially reconstruct sensitive text inputs from their embeddings, posing significant privacy risks for users. We propose a novel privacy evaluation framework for assessing the vulnerability of text embeddings to TEIA, and demonstrate the effectiveness of our approach on a range of popular embedding models. Our results highlight the importance of enhancing the privacy-awareness of text embedding techniques, and suggest possible mitigation strategies to protect against such privacy threats. By shedding light on the potential risks posed by transferable embedding inversion attacks, this study aims to raise awareness among researchers, practitioners, and policymakers about the need for stronger privacy measures in text embedding technologies.",
        "Source": "GPT"
    },
    {
        "Index": 230,
        "Title": "Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural Language Understanding.",
        "Abstract": "Recent strides in large language models (LLMs) have yielded remarkable performance in natural language understanding tasks. These models have shown the potential to improve performance through reinforcement learning, where the model learns by interacting with its environment and receiving rewards based on its actions. However, current reinforcement learning approaches in LLMs may not fully utilize the available training data, leading to suboptimal performance in certain situations. \n\nIn this work, we propose a novel approach to enhance reinforcement learning in LLMs by introducing label-sensitive rewards. By incorporating the ground truth labels of the training data into the reward calculation, our method aims to guide the model towards making predictions that are not only accurate, but also aligned with the desired outputs. We demonstrate the effectiveness of our label-sensitive reward approach on a range of natural language understanding tasks, achieving significant improvements in performance compared to standard reinforcement learning methods. Our findings highlight the importance of incorporating task-specific information into the reinforcement learning process for enhancing the capabilities of LLMs in natural language understanding.",
        "Source": "GPT"
    },
    {
        "Index": 231,
        "Title": "Intuitive or Dependent? Investigating LLMs' Behavior Style to Conflicting Prompts.",
        "Abstract": "Large Language Models (LLMs) such as GPT-3 have gained popularity for their ability to generate human-like text based on given prompts. However, little is known about how these models behave when faced with conflicting prompts. This study aimed to investigate the behavior style of LLMs in response to conflicting prompts. Through a series of experiments, we observed how LLMs navigate and interpret conflicting prompts and how they ultimately decide on a response. Our findings suggest that LLMs exhibit various behaviors when presented with conflicting prompts, including flexibility in adapting to different prompts, tendency to prioritize one prompt over another, and reliance on external sources to resolve conflicts. The results offer valuable insights into the decision-making process of LLMs and shed light on their cognitive capabilities in handling conflicting information. Understanding how LLMs respond to conflicting prompts can inform the development of more reliable and accurate language models in the future.",
        "Source": "GPT"
    },
    {
        "Index": 232,
        "Title": "CoCA: Fusing Position Embedding with Collinear Constrained Attention in Transformers for Long Context Window Extending.",
        "Abstract": "Self-attention and position embedding are two crucial modules in transformer-based Large Language Models (LLMs). However, existing transformer architectures suffer from limited context window size, hindering the model's ability to capture long-range dependencies. In this work, we propose a novel approach, CoCA, which fuses position embedding with Collinear Constrained Attention to extend the context window in transformers. By incorporating collinearity constraints into the attention mechanism, CoCA enables the model to effectively capture long-distance dependencies while maintaining computational efficiency.\n\nWe evaluate our approach on various benchmark datasets and demonstrate that CoCA significantly outperforms state-of-the-art transformer models in tasks requiring long context dependencies. Our experiments show that CoCA achieves superior performance in language modeling, machine translation, and text generation tasks. Additionally, we conduct ablation studies to analyze the effectiveness of each component in CoCA and provide insights into the importance of fusing position embedding with Collinear Constrained Attention. Overall, CoCA offers a promising direction for enhancing the capabilities of transformer-based LLMs in capturing long-range dependencies.",
        "Source": "GPT"
    },
    {
        "Index": 233,
        "Title": "InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification.",
        "Abstract": "Text simplification aims to make technical texts more accessible to laypeople but often results in information loss. In this study, we present InfoLossQA, a novel approach for characterizing and recovering information loss in text simplification. We first analyze the extent and types of information loss that occur during the simplification process, identifying common patterns such as deletion of complex terms or removal of detailed explanations. Next, we propose a question-answering framework that aims to recover lost information by generating relevant questions based on the simplified text. Through extensive experiments on a diverse set of text simplification datasets, we demonstrate that our approach effectively identifies and recovers lost information, outperforming existing methods. Our findings shed light on the challenges and opportunities in text simplification, offering valuable insights for improving the accessibility and comprehensibility of technical information for a wider audience.",
        "Source": "GPT"
    },
    {
        "Index": 234,
        "Title": "CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following.",
        "Abstract": "With the advancement of language models (LMs), their exposure to private data is increasingly inevitable. Therefore, the need for secure and context-aware instruction following becomes paramount. In this paper, we propose CoGenesis, a framework that collaborates large and small language models to achieve secure context-aware instruction following. CoGenesis leverages the strengths of both large and small LMs to balance performance and privacy concerns. By combining multiple models, CoGenesis aims to reduce the risk of overfitting, enhance interpretability, and improve the overall security of the instruction-following process. Through experimental evaluation, we demonstrate the effectiveness of CoGenesis in enhancing security and context-awareness in instruction following tasks. Our results show that CoGenesis outperforms individual LM models and offers a promising solution for integrating large LMs into secure and context-aware applications. We believe that CoGenesis can pave the way for leveraging the power of language models while ensuring the protection of sensitive information.",
        "Source": "GPT"
    },
    {
        "Index": 235,
        "Title": "DAPR: A Benchmark on Document-Aware Passage Retrieval.",
        "Abstract": "The work of neural retrieval so far focuses on ranking short texts and is challenged by the complexity of longer documents. In this paper, we introduce DAPR, a benchmark for Document-Aware Passage Retrieval that aims to address this gap in the field. DAPR consists of a diverse collection of long documents and corresponding queries, with passages annotated for relevance. We propose a novel neural passage retrieval model that leverages both global document context and local query information to effectively capture document-aware relevance. Our experiments on the DAPR benchmark demonstrate that our model outperforms existing methods by a significant margin, highlighting the importance of considering full document context in passage retrieval tasks. We believe that DAPR will serve as a valuable resource for researchers and practitioners looking to advance the state-of-the-art in document-aware information retrieval.",
        "Source": "GPT"
    },
    {
        "Index": 236,
        "Title": "Strengthened Symbol Binding Makes Large Language Models Reliable Multiple-Choice Selectors.",
        "Abstract": "Multiple-Choice Questions (MCQs) constitute a critical area of research in the study of Large Language Models. The reliability and accuracy of these models depend on their ability to effectively process and analyze the various symbols and information presented in the questions. In this study, we explore the concept of strengthened symbol binding in large language models to enhance their performance as multiple-choice selectors. By improving the model's ability to recognize and retain the relationships between symbols and their corresponding meanings, we aim to increase the accuracy and reliability of their selections in multiple-choice questions. Through a series of experiments and analyses, we demonstrate that incorporating strengthened symbol binding techniques significantly improves the model's overall performance in selecting correct answers. These findings provide valuable insights into how large language models can be further optimized to excel in processing and understanding complex multiple-choice questions, ultimately enhancing their utility in various language-related tasks and applications.",
        "Source": "GPT"
    },
    {
        "Index": 237,
        "Title": "SAC-KG: Exploiting Large Language Models as Skilled Automatic Constructors for Domain Knowledge Graph.",
        "Abstract": "Knowledge graphs (KGs) play a pivotal role in knowledge-intensive tasks across specialized domains, where the structure and relationships among entities are crucial for effective information retrieval and reasoning. In this study, we propose SAC-KG, a novel approach that leverages large language models as skilled automatic constructors for domain knowledge graphs. By harnessing the capabilities of these powerful language models, SAC-KG is able to automatically extract, infer, and construct intricate knowledge graphs tailored to specific domains. The generated knowledge graphs not only capture the inherent structure and semantics of the domain but also incorporate the latest information and nuances from textual data sources. We demonstrate the effectiveness of SAC-KG on various knowledge-intensive tasks, including information retrieval, question answering, and entity linking, showcasing its ability to outperform traditional knowledge graph construction methods. Overall, SAC-KG represents a promising avenue for enhancing knowledge graph construction in specialized domains using cutting-edge language models.",
        "Source": "GPT"
    },
    {
        "Index": 238,
        "Title": "Uncertainty-Guided Modal Rebalance for Hateful Memes Detection.",
        "Abstract": "Hateful memes detection is a challenging multimodal understanding task that requires comprehensive learning of vision, language, and contextual information. In this paper, we propose an Uncertainty-Guided Modal Rebalance approach to improve the detection of hateful memes. Our method leverages uncertainty information from each modality to dynamically adjust the importance of different modalities during the training process. By adaptively rebalancing the contributions of vision and language modalities based on their uncertainties, our model can better capture the diverse and intricate nature of hateful memes. Experimental results on a widely used hateful memes dataset demonstrate the effectiveness of our approach, outperforming existing methods and achieving state-of-the-art performance. Additionally, our uncertainty-guided strategy provides insights into the model's decision-making process, enhancing interpretability and transparency. Overall, our study paves the way for more robust and reliable detection of hateful memes, contributing to the ongoing efforts in combating online hate speech.",
        "Source": "GPT"
    },
    {
        "Index": 239,
        "Title": "Missci: Reconstructing Fallacies in Misrepresented Science.",
        "Abstract": "Health-related misinformation on social networks can lead to poor decision-making and real-world dangers. This paper delves into the prevalent issue of misrepresentation of scientific information on social media platforms, focusing on its implications for public health and decision-making. Through a critical analysis of common fallacies in misrepresented science, such as cherry-picking data, overgeneralization of findings, and disregard for peer-reviewed research, this study aims to shed light on the importance of scientifically accurate information dissemination. The impact of misleading health claims on individual choices and behaviors, as well as on the overall public health landscape, is explored. By identifying and reconstructing fallacies in misrepresented science, we aim to promote critical thinking skills and encourage users of social networks to scrutinize health-related information before accepting it as truth. This paper underscores the urgent need for reliable sources of information and the importance of fact-checking in an era overwhelmed by misinformation.",
        "Source": "GPT"
    },
    {
        "Index": 240,
        "Title": "Uncovering the Full Potential of Visual Grounding Methods in VQA.",
        "Abstract": "Visual Grounding (VG) methods in Visual Question Answering (VQA) attempt to improve VQA performance by associating textual questions with visual regions in images. These methods aim to ground the semantics of questions in the corresponding visual context, enabling more accurate and meaningful answers to be generated. However, the full potential of VG methods in VQA has yet to be fully realized. In this paper, we investigate and uncover the various ways in which VG methods can be enhanced and leveraged to maximize their effectiveness in VQA tasks. Specifically, we explore the integration of attention mechanisms, multi-modal fusion strategies, and advanced neural network architectures to improve the performance of VG methods. Our experimental results demonstrate the significant impact of these enhancements on VQA accuracy, highlighting the importance of pushing the boundaries of VG methods to achieve state-of-the-art results in VQA tasks. This work sheds light on the untapped potential of VG methods in VQA and paves the way for future research in this rapidly evolving field.",
        "Source": "GPT"
    },
    {
        "Index": 241,
        "Title": "Small Models, Big Insights: Leveraging Slim Proxy Models To Decide When and What to Retrieve for LLMs.",
        "Abstract": "The integration of large language models (LLMs) and search engines represents a significant evolution in information retrieval systems, allowing for more advanced and contextual search capabilities. However, the computational intensity of LLMs poses challenges in terms of efficiency and resource consumption. In this paper, we propose the use of slim proxy models as a solution to this problem, enabling more streamlined decision-making processes for LLMs. By leveraging small models to determine when and what to retrieve for LLMs, we achieve a balance between accuracy and efficiency in information retrieval tasks. Our approach not only reduces the computational burden on LLMs but also provides valuable insights into optimizing search operations. We demonstrate the effectiveness of our method through experiments on real-world datasets, showcasing the potential of slim proxy models in enhancing the performance of LLM-integrated search engines. Overall, our work highlights the importance of leveraging lightweight models for improving the functionality and effectiveness of large language models in information retrieval systems.",
        "Source": "GPT"
    },
    {
        "Index": 242,
        "Title": "Favi-Score: A Measure for Favoritism in Automated Preference Ratings for Generative AI Evaluation.",
        "Abstract": "Generative AI systems have become increasingly prevalent across various domains, offering solutions for tasks such as image generation, text generation, and music composition. With the growing reliance on these systems, evaluating and comparing their performance has become essential. However, existing evaluation metrics often overlook a crucial aspect - favoritism in automated preference ratings. To address this limitation, we propose Favi-Score, a novel measure designed to quantify favoritism in preference ratings for generative AI systems. By considering not only the overall preference scores but also the distribution of ratings among the generated samples, Favi-Score provides a more comprehensive evaluation of model performance. We demonstrate the effectiveness of Favi-Score through experiments on a range of generative AI tasks, showcasing its ability to uncover biases and preferences that may impact the overall quality of generated outputs. Overall, Favi-Score offers a valuable tool for researchers and developers seeking to ensure fair and accurate evaluations of generative AI systems.",
        "Source": "GPT"
    },
    {
        "Index": 243,
        "Title": "LLM-based Rewriting of Inappropriate Argumentation using Reinforcement Learning from Machine Feedback.",
        "Abstract": "Ensuring that online discussions are civil and productive is a major challenge for social media platforms, as inappropriate argumentation can escalate quickly and hinder meaningful dialogue. In this study, we propose a novel approach utilizing Reinforcement Learning from Machine Feedback (RLMF) to address this issue. Specifically, we focus on the task of rewriting inappropriate argumentation in online discussions using a language model (LLM)-based approach.\n\nOur method leverages the power of reinforcement learning to provide feedback on the appropriateness of arguments and guide the rewriting process. Through iterative training, the model learns to identify and rephrase hostile or inflammatory language, promoting a more respectful and constructive exchange of ideas. By incorporating machine feedback into the writing process, we aim to not only improve the overall quality of online discussions but also encourage users to engage in a more thoughtful and respectful manner. Preliminary results demonstrate the effectiveness of our approach in mitigating inappropriate argumentation and fostering productive interactions in online communities.",
        "Source": "GPT"
    },
    {
        "Index": 244,
        "Title": "Graph Language Models.",
        "Abstract": "Graph Language Models (GLMs) have emerged as a powerful framework for integrating structured knowledge graphs with traditional Language Models (LMs) in Natural Language Processing (NLP) tasks. While LMs excel at capturing sequential patterns and contextual information from unstructured text, they often struggle with incorporating external knowledge sources in a meaningful way. However, by incorporating graph-based representations of knowledge into the LM architecture, GLMs are able to augment the contextual information with relational and semantic knowledge from structured graphs. This enables GLMs to better understand and generate text that is grounded in external knowledge, leading to improved performance on a variety of NLP tasks such as question-answering, information retrieval, and text generation. In this paper, we provide an overview of the current state-of-the-art in GLMs, highlighting their benefits, challenges, and potential applications in NLP research. We also discuss future directions for research in this exciting and rapidly evolving area of study.",
        "Source": "GPT"
    },
    {
        "Index": 245,
        "Title": "Analyzing Semantic Change through Lexical Replacements.",
        "Abstract": "Modern language models have greatly improved our ability to understand the contextual meaning of words. By analyzing the surrounding words and phrases, these models can accurately interpret the intended meaning of a given word. In this study, we aim to explore how lexical replacements can be used as a tool for analyzing semantic change over time. By examining how words are replaced in different contexts, we can gain insights into how the meaning of a word has evolved over time. This approach allows us to track the changing nuances and connotations of words, providing a more nuanced understanding of semantic shifts. Through a series of experiments using state-of-the-art language models, we demonstrate the effectiveness of this method in capturing semantic change. Our findings suggest that lexical replacements can serve as a valuable tool in studying language evolution and understanding how meanings shift over time. This research contributes to the growing body of literature on semantic change and offers new insights into the dynamic nature of language.",
        "Source": "GPT"
    },
    {
        "Index": 246,
        "Title": "Exploiting Intrinsic Multilateral Logical Rules for Weakly Supervised Natural Language Video Localization.",
        "Abstract": "Weakly supervised natural language video localization (WS-NLVL) aims to retrieve the moment corresponding to a given textual query in a video, without the need for precise temporal annotations. In this paper, we propose a novel approach to WS-NLVL by exploiting intrinsic multilateral logical rules. Our method leverages the logical constraints present in natural language queries to guide the localization process, enabling accurate moment retrieval even with limited supervision.\n\nWe first encode the textual query and video content into a shared semantic space using a multimodal neural network. Then, we introduce a logical inference mechanism that captures the inherent relationships among different elements in the query and video. By incorporating these multilateral logical rules into our localization framework, we are able to effectively filter out irrelevant moments and focus on the most relevant ones for the given query.\n\nExperimental results on several benchmark datasets demonstrate that our approach outperforms existing methods in terms of localization accuracy and robustness to noisy input. Our work highlights the importance of leveraging logical reasoning for improving weakly supervised natural language video localization tasks.",
        "Source": "GPT"
    },
    {
        "Index": 247,
        "Title": "Interpretability of Language Models via Task Spaces.",
        "Abstract": "The usual way to interpret language models (LMs) is to test their performance on different tasks and datasets, but this approach has limitations in fully understanding the inner workings of these models. In this paper, we propose a novel method for interpreting LMs through the use of task spaces. By mapping the representation of LMs onto a lower-dimensional task space, we can analyze and visualize the relationships between different tasks and how the model performs on each one. This method allows for a more comprehensive understanding of the capabilities and limitations of LMs, as well as insights into the decision-making processes of the model. Additionally, by examining the task space, we can identify potential biases or strengths in the model's performance that may not be apparent when evaluating individual tasks in isolation. Overall, this approach provides a powerful tool for interpreting LMs and gaining a deeper understanding of their inner workings.",
        "Source": "GPT"
    },
    {
        "Index": 248,
        "Title": "Using Synchronic Definitions and Semantic Relations to Classify Semantic Change Types.",
        "Abstract": "There is abundant evidence of the fact that the way words change their meaning can be traced through various semantic change types. In this study, we propose a novel approach to classify semantic change types using synchronic definitions and semantic relations. By examining how words are defined in current dictionaries and analyzing the semantic relations they have with other words, we can gain insights into the underlying mechanisms driving semantic change. Through this method, we identify four main types of semantic change: extension, narrowing, metaphor, and metonymy. We further categorize these types into subtypes based on the nature of semantic relations involved, such as synonymy, antonymy, hypernymy, and hyponymy. By integrating synchronic definitions and semantic relations into our classification framework, we provide a more comprehensive and systematic understanding of semantic change. This approach can be valuable for linguists, lexicographers, and language learners in studying and predicting the evolution of language over time.",
        "Source": "GPT"
    },
    {
        "Index": 249,
        "Title": "Factual Confidence of LLMs: on Reliability and Robustness of Current Estimators.",
        "Abstract": "Large Language Models (LLMs) tend to be unreliable on fact-based answers. To address this problem, Natural Language Processing (NLP) researchers have developed various estimators to increase the factual confidence of LLMs. This study focuses on evaluating the reliability and robustness of current estimators in improving the factual accuracy of LLMs.\n\nWe examine the effectiveness of estimators such as fact verification modules, fact-checking methods, and credibility scoring systems in enhancing the factual confidence of LLMs. Additionally, we investigate the impact of training data size, model complexity, and fine-tuning techniques on the performance of these estimators.\n\nOur findings suggest that while current estimators show some promising results in improving the factual reliability of LLMs, there is still room for improvement in terms of robustness and generalizability. Future research should focus on developing more sophisticated estimators that can adapt to a wide range of fact-based queries and enhance the overall performance of LLMs in providing accurate and reliable information.",
        "Source": "GPT"
    },
    {
        "Index": 250,
        "Title": "StepCoder: Improving Code Generation with Reinforcement Learning from Compiler Feedback.",
        "Abstract": "The advancement of large language models (LLMs) has significantly propelled the field of code generation. These LLMs have shown promising results in automated code generation tasks, but they often lack the ability to incorporate feedback from the compiler to improve the generated code's quality. In this study, we propose StepCoder, a novel approach that leverages reinforcement learning to enhance code generation by incorporating compiler feedback. StepCoder allows the model to learn from the compiler's response to generated code, enabling it to make informed decisions and generate higher-quality code. By training the model on a diverse set of programming tasks and compiler feedback, StepCoder demonstrates improved accuracy and efficiency in code generation compared to traditional LLMs. Our experimental results show that StepCoder effectively learns to optimize code generation based on compiler feedback, highlighting the potential for reinforcement learning techniques to enhance the performance of automated code generation systems.",
        "Source": "GPT"
    },
    {
        "Index": 251,
        "Title": "One-Shot Learning as Instruction Data Prospector for Large Language Models.",
        "Abstract": "Contemporary practices in instruction tuning often hinge on enlarging data scaling without a clear strategy. One approach to address this challenge is by utilizing one-shot learning as an instruction data prospector for large language models. This innovative technique capitalizes on the ability of large language models to rapidly learn new concepts or instructions with just a single example.\n\nBy leveraging one-shot learning, we can significantly improve the efficiency and effectiveness of instruction tuning for these large language models. This approach not only reduces the burden of acquiring and processing massive amounts of data, but it also enhances the model's ability to adapt to new instructions or tasks quickly and accurately.\n\nIn this study, we demonstrate the potential of one-shot learning as an instruction data prospector for large language models through experimental evaluations and performance comparisons. Our results highlight the significant impact of this approach on improving the scalability and flexibility of instruction tuning processes, paving the way for more efficient and effective usage of large language models in various applications.",
        "Source": "GPT"
    },
    {
        "Index": 252,
        "Title": "Navigating the OverKill in Large Language Models.",
        "Abstract": "Large language models are meticulously aligned to be both helpful and harmless. However, recent research has raised concerns about the potential for overkill in these models. Overkill, in the context of language models, refers to the excessive generation of text that is not only unnecessary but can also be harmful in certain contexts. This overkill phenomenon can manifest in various ways, such as producing biased or offensive content, spreading misinformation, or generating inappropriate responses. \n\nTo navigate the overkill in large language models, researchers and developers must prioritize ethical considerations and implement safeguards to prevent the dissemination of harmful content. This includes robust moderation processes, algorithmic bias detection, and continuous monitoring of model behavior. Additionally, promoting transparency and accountability in the development and deployment of these models is essential to mitigate the risks associated with overkill. By addressing these challenges proactively, we can harness the potential of large language models while minimizing their negative impact on society.",
        "Source": "GPT"
    },
    {
        "Index": 253,
        "Title": "A Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for Verifiers of Reasoning Chains.",
        "Abstract": "Prompting language models to provide step-by-step answers, also known as a \"Chain-of-Thought,\" is a widely used method for complex reasoning tasks. In this study, we propose a benchmark for verifiers of reasoning chains, based on the premise that a chain-of-thought is only as strong as its weakest link. By evaluating the accuracy and coherence of each step in the reasoning process, our benchmark aims to identify and address potential weaknesses in the chain of reasoning. This allows for a more reliable assessment of the validity and soundness of the overall argument. Through a series of experiments and evaluations, we demonstrate the effectiveness of our benchmark in improving the quality of reasoning chains generated by language models. Our results show that by paying attention to the weakest link in the chain-of-thought, verifiers can significantly enhance the reliability and robustness of complex reasoning processes. Overall, our benchmark provides a valuable tool for evaluating and improving the strength of reasoning chains, ultimately leading to more accurate and coherent reasoning outputs.",
        "Source": "GPT"
    },
    {
        "Index": 254,
        "Title": "Re3: A Holistic Framework and Dataset for Modeling Collaborative Document Revision.",
        "Abstract": "Collaborative review and revision of textual documents is the core of knowledge work and a fundamental aspect of modern scholarship. In this paper, we present Re3, a comprehensive and holistic framework for modeling collaborative document revision. Re3 encompasses various stages of the revision process, including editing, commenting, and discussing changes made by multiple users. Furthermore, we introduce a novel dataset for training and evaluating collaborative revision models, which consists of a diverse set of documents with multiple revisions annotated by experts. Our framework and dataset provide a valuable resource for researchers and developers to explore and advance the field of collaborative document revision. We demonstrate the effectiveness of Re3 through experiments that showcase its ability to accurately model and predict document revisions while also providing insights into user collaboration patterns. Overall, Re3 offers a robust foundation for future research in collaborative document revision and opens up new possibilities for enhancing knowledge creation and sharing in a digital age.",
        "Source": "GPT"
    },
    {
        "Index": 255,
        "Title": "NextLevelBERT: Masked Language Modeling with Higher-Level Representations for Long Documents.",
        "Abstract": "While (large) language models have significantly improved over the last years, they still struggle to effectively handle long documents due to limitations in their ability to capture higher-level representations. In this paper, we propose NextLevelBERT, a novel approach that leverages masked language modeling with higher-level representations to enhance the performance of language models in processing long documents.\n\nNextLevelBERT introduces a hierarchical masking strategy that enables the model to focus on different segments of the document at different levels of abstraction, allowing for a more comprehensive understanding of the context. By incorporating higher-level representations, such as paragraph or section embeddings, NextLevelBERT is able to capture the overall structure and coherence of long documents, leading to improved performance in tasks requiring long-range dependencies.\n\nExperimental results demonstrate that NextLevelBERT outperforms baseline language models on various long-document tasks, including document summarization and information retrieval. Our approach paves the way for more effective utilization of large language models in processing lengthy and complex textual data.",
        "Source": "GPT"
    },
    {
        "Index": 256,
        "Title": "FollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models.",
        "Abstract": "The ability to follow instructions is crucial for Large Language Models (LLMs) to handle various tasks effectively. In order to assess and improve this capability, we present FollowBench, a novel multi-level fine-grained constraints following benchmark designed specifically for LLMs. This benchmark evaluates the model's ability to adhere to instructions ranging from simple directives to complex and nuanced constraints across different levels of detail. By analyzing the model's performance on a diverse set of tasks with varying levels of difficulty, FollowBench provides a comprehensive evaluation of the LLM's constraint following skills. Additionally, our benchmark incorporates a scoring system that quantitatively measures the model's compliance with the given instructions, offering valuable insights into its strengths and weaknesses in this aspect. Through rigorous testing on a wide range of constraint-following scenarios, FollowBench aims to facilitate advancements in training methodologies and model architectures that enhance the LLM's ability to accurately understand and follow instructions in natural language processing tasks.",
        "Source": "GPT"
    },
    {
        "Index": 257,
        "Title": "Learning to Edit: Aligning LLMs with Knowledge Editing.",
        "Abstract": "Knowledge editing techniques involve efficiently modifying a small portion of knowledge within large language models (LLMs) to improve their accuracy and coherence. This process requires aligning the LLMs with specific editing goals, such as enhancing factual accuracy, semantic consistency, or stylistic coherence. By implementing knowledge editing techniques, researchers can fine-tune LLMs to better meet their intended purposes, whether for content generation, translation, or other natural language processing tasks.\n\nEffective knowledge editing involves identifying and manipulating relevant information within the LLM's vast knowledge base, while maintaining overall linguistic fluency and coherence. By focusing on targeted edits rather than complete retraining, knowledge editing techniques streamline the refinement process and optimize the efficiency of LLM modification.\n\nThis paper explores the principles and methodologies of knowledge editing in the context of LLMs, highlighting the challenges and strategies for aligning editing goals with the underlying knowledge structure of these powerful language models. Through a systematic approach to knowledge editing, researchers can enhance the performance and adaptability of LLMs across a range of applications.",
        "Source": "GPT"
    },
    {
        "Index": 258,
        "Title": "DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning.",
        "Abstract": "Code Large Language Models (Code LLMs) have revolutionized the field of natural language processing by achieving remarkable performance in code-related tasks. However, their effectiveness still heavily relies on the quality and diversity of the training data and instruction provided during fine-tuning. In this paper, we introduce DolphCoder, a novel approach that leverages echo-locating techniques to guide the fine-tuning of Code LLMs with diverse and multi-objective instructions.\n\nBy incorporating diverse sets of instructions during the fine-tuning process, DolphCoder enhances the generalization capabilities of Code LLMs, enabling them to perform effectively across a wider range of code-related tasks. Furthermore, our multi-objective instruction tuning framework ensures that the fine-tuned models not only excel in a single task but also demonstrate robust performance in multiple code-related tasks. Experimental results show that DolphCoder significantly improves the performance of Code LLMs on benchmark code-related tasks, highlighting its potential to advance the capabilities of large language models in the domain of programming languages and software development.",
        "Source": "GPT"
    },
    {
        "Index": 259,
        "Title": "When Only Time Will Tell: Interpreting How Transformers Process Local Ambiguities Through the Lens of Restart-Incrementality.",
        "Abstract": "Incremental models that process sentences one token at a time will sometimes encounter points where local ambiguities can arise, requiring the model to make decisions based on limited contextual information. In this study, we investigate how Transformers, a popular type of neural network architecture, handle such local ambiguities through the lens of restart-incrementality. Restart-incrementality allows the model to reset its incremental processing at specific points in the sentence, effectively granting it the ability to reconsider its decisions and potentially resolve ambiguities. By analyzing the behavior of Transformers when faced with local ambiguities, we aim to gain insight into how these models navigate linguistic complexities in real-time processing. Through a series of experiments and analyses, we demonstrate that restart-incrementality can significantly improve the model's accuracy in disambiguating sentences, shedding light on the mechanisms underlying how Transformers process local ambiguities. Our findings highlight the importance of considering incremental processing strategies in neural network architectures for natural language understanding tasks.",
        "Source": "GPT"
    },
    {
        "Index": 260,
        "Title": "SpaRC and SpaRP: Spatial Reasoning Characterization and Path Generation for Understanding Spatial Reasoning Capability of Large Language Models.",
        "Abstract": "Spatial reasoning is a crucial component of both biological and artificial intelligence. In this work, we present SpaRC and SpaRP, two methodologies aimed at characterizing spatial reasoning capability and generating paths to assess large language models. SpaRC focuses on evaluating the ability of models to understand spatial relations and infer spatial properties, while SpaRP generates challenging spatial reasoning tasks to examine the performance of models in diverse spatial reasoning scenarios. By leveraging both methodologies, we can gain valuable insights into the spatial reasoning capabilities of large language models and facilitate a deeper understanding of their decision-making processes. Through extensive experiments and analyses, we demonstrate the effectiveness and versatility of SpaRC and SpaRP in evaluating the spatial reasoning capabilities of state-of-the-art language models. Our work sheds light on the potential of large language models to reason about spatial information and provides a foundation for future research in the field of spatial reasoning in natural language processing.",
        "Source": "GPT"
    },
    {
        "Index": 261,
        "Title": "Planning Like Human: A Dual-process Framework for Dialogue Planning.",
        "Abstract": "In proactive dialogue, successful communication requires not only the generation of appropriate responses but also the ability to effectively guide the course of conversation. This paper presents a novel Dual-process Framework for Dialogue Planning that mimics the cognitive processes involved in human conversation planning. Drawing inspiration from dual-process theories of human reasoning, the framework models dialogue planning as a dynamic interplay between automatic, intuitive processing and controlled, deliberative processing. By integrating these two cognitive processes, the framework enables dialogue systems to adaptively generate responses while also proactively managing the flow and direction of conversations. Through the implementation of this dual-process approach, dialogue systems can more closely replicate the nuanced and strategic dialogue planning exhibited by human conversationalists. Experimental results demonstrate the effectiveness of the framework in enhancing the naturalness and coherence of proactive dialogue interactions. Overall, this framework offers a promising avenue for advancing the sophistication of dialogue systems in various applications.",
        "Source": "GPT"
    },
    {
        "Index": 262,
        "Title": "Spectral Filters, Dark Signals, and Attention Sinks.",
        "Abstract": "Projecting intermediate representations onto the vocabulary is an increasingly popular interpretation tool for transformer-based Language Models (LLMs). This process involves applying spectral filters to extract specific features or patterns from the model's internal representations, allowing for deeper insights into the model's decision-making process. However, the use of spectral filters can also introduce dark signals - misleading or erroneous interpretations that may lead to incorrect conclusions about the model's behavior. Additionally, attention sinks, areas of the input that attract an excessive amount of attention from the model, can negatively impact the interpretability of the extracted features. In this study, we explore the challenges and limitations associated with using spectral filters and highlight the importance of careful analysis and validation when interpreting intermediate representations of transformer-based LLMs. By addressing these issues, we aim to improve the reliability and accuracy of interpretation methods for transformer-based LLMs, ultimately enhancing our understanding of these complex language models.",
        "Source": "GPT"
    },
    {
        "Index": 263,
        "Title": "DiffuCOMET: Contextual Commonsense Knowledge Diffusion.",
        "Abstract": "Inferring contextually-relevant and diverse commonsense knowledge is essential for understanding narratives, yet it remains a challenge for knowledge models. This paper presents DiffuCOMET, a novel approach for contextual commonsense knowledge diffusion. By leveraging a large-scale pre-trained language model and a graph-based diffusion mechanism, DiffuCOMET effectively spreads commonsense information across a knowledge graph, enriching the representation of entities and their relationships. Through this approach, DiffuCOMET can capture nuanced contextual information and enhance the understanding of complex narratives. \n\nExperimental results on benchmark datasets demonstrate that DiffuCOMET significantly outperforms existing methods in various commonsense reasoning tasks, showcasing its ability to effectively diffuse contextual knowledge. Furthermore, we show that DiffuCOMET can generalize well to unseen scenarios, highlighting its potential for real-world applications. Overall, DiffuCOMET provides a promising solution for improving the capabilities of knowledge models in understanding and reasoning about narratives by incorporating diverse and contextually-relevant commonsense knowledge.",
        "Source": "GPT"
    },
    {
        "Index": 264,
        "Title": "Systematic Task Exploration with LLMs: A Study in Citation Text Generation.",
        "Abstract": "Large language models (LLMs) bring unprecedented flexibility in defining and executing complex, creative natural language tasks. In this study, we focus on exploring the utilization of LLMs for citation text generation, a task essential for academic writing and research. We propose a systematic task exploration methodology to investigate the capabilities of LLMs in generating accurate and contextually relevant citations. By fine-tuning the model on a large dataset of scientific papers, we analyze the performance of the LLM in producing citations that align with academic standards and conventions. Through evaluation metrics such as precision, recall, and fluency, we assess the quality of generated citation texts and compare them with gold standard references. Our findings shed light on the potential of LLMs in automating the citation process, reducing the burden on researchers and enhancing the efficiency of scholarly communication. This study contributes to the advancement of natural language generation techniques and offers insights into the promising application of LLMs in academic writing.",
        "Source": "GPT"
    },
    {
        "Index": 265,
        "Title": "Limits of Theory of Mind Modelling in Dialogue-Based Collaborative Plan Acquisition.",
        "Abstract": "Recent work on dialogue-based collaborative plan acquisition (CPA) has highlighted the significance of Theory of Mind (ToM) in understanding and predicting the behaviors, beliefs, and intentions of collaborative partners in a dialogue setting. ToM refers to the cognitive ability to infer and attribute mental states to oneself and others, enabling individuals to navigate social interactions effectively. However, while ToM has been integrated into computational models to improve dialogue-based CPA, there are limitations to its application in accurately modeling human collaborative behaviors. This paper explores the constraints and challenges that arise from using ToM in dialogue-based CPA and discusses potential avenues for enhancing the effectiveness of computational models by incorporating additional cognitive mechanisms. By recognizing the boundaries of ToM in modeling collaborative plan acquisition, researchers can develop more robust and adaptive systems that better capture the complexities of human interaction in collaborative settings.",
        "Source": "GPT"
    },
    {
        "Index": 266,
        "Title": "Temporal Knowledge Question Answering via Abstract Reasoning Induction.",
        "Abstract": "In this study, we address the challenge of enhancing temporal knowledge reasoning in Large Language Models (LLMs) through abstract reasoning induction. Temporal knowledge plays a crucial role in understanding and predicting events, making it essential for natural language processing tasks. However, existing LLMs struggle with effectively reasoning about temporal relations due to their reliance on context window limitations. To overcome this, we propose a novel approach that leverages abstract reasoning induction to enable LLMs to perform temporal knowledge question answering more accurately and efficiently. By incorporating structured temporal information and training the model to infer abstract rules governing temporal relationships, we demonstrate significant improvements in temporal reasoning capabilities. Our experimental results on benchmark datasets show the effectiveness of our approach in enhancing the LLMs' ability to reason about complex temporal scenarios. This work opens up new avenues for advancing temporal knowledge reasoning in LLMs and has implications for a wide range of applications, including question answering, text generation, and information retrieval.",
        "Source": "GPT"
    },
    {
        "Index": 267,
        "Title": "Who Wrote this Code? Watermarking for Code Generation.",
        "Abstract": "Since the remarkable generation performance of large language models raised ethical and legal concerns, approaches to identify the true authorship of generated code have become increasingly important. In response to this growing need, a novel watermarking technique for code generation is proposed in this paper. By embedding unique identifiers, or watermarks, into the generated code, the origin of the code can be easily traced back to the original author. This approach not only helps to protect intellectual property rights, but also serves as a means of accountability and transparency in the development of generated code. Experimental results demonstrate the effectiveness and efficiency of the proposed watermarking technique in accurately attributing generated code to its rightful author. Overall, this paper presents a valuable contribution to the field of code generation ethics and legalities through the implementation of watermarking mechanisms.",
        "Source": "GPT"
    },
    {
        "Index": 268,
        "Title": "MapCoder: Multi-Agent Code Generation for Competitive Problem Solving.",
        "Abstract": "Code synthesis, which involves parsing complex natural language problem descriptions and generating executable code, is a challenging task that requires a deep understanding of both programming languages and natural language. In this paper, we present MapCoder, a novel approach for multi-agent code generation in the context of competitive problem solving. MapCoder is designed to interpret and map natural language problem descriptions to actual executable code by leveraging machine learning techniques and knowledge from libraries and data sources. Moreover, MapCoder takes into account multiple agents, each responsible for generating specific components or functions of the code, thus enabling parallel and collaborative code generation. Our experiments demonstrate that MapCoder achieves competitive performance in generating code solutions for a variety of problem domains, outperforming existing methods in terms of efficiency and accuracy. Overall, MapCoder paves the way for more efficient and scalable code generation in competitive problem-solving scenarios, showcasing the potential of multi-agent approaches in this challenging domain.",
        "Source": "GPT"
    },
    {
        "Index": 269,
        "Title": "RelayAttention for Efficient Large Language Model Serving with Long System Prompts.",
        "Abstract": "Large Language Models (LLMs) have gained popularity for their ability to generate human-like text. However, serving these models efficiently with long system prompts poses a challenge. In this paper, we propose RelayAttention, a novel framework that improves LLM serving efficiency by leveraging attention mechanisms. RelayAttention focuses on optimizing the computation of attention weights, allowing the model to effectively process long system prompts without sacrificing performance. Our experiments demonstrate that RelayAttention significantly reduces the computational cost of large language model serving, making it suitable for practical applications that require handling lengthy inputs. Additionally, we show that RelayAttention outperforms existing methods in terms of both speed and accuracy when serving LLMs with long prompts. Overall, our framework offers a scalable solution for efficiently deploying large language models in real-world settings, enabling the development of advanced natural language processing applications.",
        "Source": "GPT"
    },
    {
        "Index": 270,
        "Title": "Boosting Language Models Reasoning with Chain-of-Knowledge Prompting.",
        "Abstract": "Recently, Chain-of-Thought (CoT) prompting has proven to be a successful approach for enhancing reasoning capabilities in language models. By designing prompts that guide the models through a chain of knowledge to arrive at the desired conclusion, CoT prompting has shown promise in improving performance on complex reasoning tasks. This innovative method allows language models to effectively connect pieces of information and infer relationships between them, leading to more accurate and coherent outputs. In this study, we propose a new variant called Chain-of-Knowledge prompting, which builds upon the principles of CoT prompting to further enhance the reasoning abilities of language models. By incorporating a structured sequence of prompts that systematically guide the models through relevant knowledge sources, Chain-of-Knowledge prompting aims to boost the accuracy, coherence, and overall performance of language models on a wide range of reasoning tasks. Our preliminary results show the potential of this approach in improving reasoning capabilities and advancing the field of natural language processing.",
        "Source": "GPT"
    },
    {
        "Index": 271,
        "Title": "Open Grounded Planning: Challenges and Benchmark Construction.",
        "Abstract": "The emergence of large language models (LLMs) has increasingly drawn attention to the use of artificial intelligence in various fields, including planning. Open grounded planning, a variant of classical planning, aims to overcome limitations in traditional planning by incorporating real-world knowledge and the ability to learn from new environments. However, challenges such as scalability, adaptability, and robustness still persist in this evolving field. To address these challenges, benchmark construction plays a crucial role in evaluating the performance of open grounded planning systems. In this paper, we discuss the current state of open grounded planning, identify key challenges faced by researchers, and delve into the importance of benchmark construction in establishing a standardized evaluation framework. By highlighting these challenges and emphasizing the need for benchmarking, we aim to provide a comprehensive overview of the current landscape of open grounded planning research and guide future efforts in addressing these obstacles.",
        "Source": "GPT"
    },
    {
        "Index": 272,
        "Title": "LLM Knows Body Language, Too: Translating Speech Voices into Human Gestures.",
        "Abstract": "In response to the escalating demand for digital human representations, progress has been made in developing a system that can translate speech voices into human gestures. This system, known as LLM, utilizes advanced technology to analyze and interpret the non-verbal cues and body language associated with speech. By mapping out the subtle gestures and movements that accompany spoken words, LLM is able to create realistic and expressive human-like animations in real-time.\n\nThis innovative technology has wide-reaching applications in various industries, including entertainment, virtual reality, and communication. By accurately conveying the emotions and intentions behind spoken language through gestures, LLM allows for more immersive and natural interactions in digital environments.\n\nOverall, LLM represents a significant advancement in the field of digital human representation, bridging the gap between speech and gestures to create more authentic and engaging virtual experiences.",
        "Source": "GPT"
    },
    {
        "Index": 273,
        "Title": "QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction.",
        "Abstract": "Employing Large Language Models (LLMs) for semantic parsing has achieved remarkable success. However, we find that existing frameworks may lack robustness and accuracy, especially when dealing with complex queries and diverse contexts. In response to this challenge, we propose QueryAgent, a reliable and efficient reasoning framework that incorporates environmental feedback for self-correction. By leveraging advanced reasoning techniques and continuous learning mechanisms, QueryAgent can adapt to changing contexts and improve its accuracy over time. Our framework is designed to handle various types of queries, including natural language, structured, and mixed-format inputs, with high precision and reliability. Through experimental evaluations, we demonstrate that QueryAgent outperforms state-of-the-art models in both accuracy and efficiency, making it a promising solution for semantic parsing tasks in real-world applications. With its robust reasoning capabilities and self-correcting mechanism, QueryAgent offers a valuable tool for enhancing the performance of AI systems in diverse environments.",
        "Source": "GPT"
    },
    {
        "Index": 274,
        "Title": "PITA: Prompting Task Interaction for Argumentation Mining.",
        "Abstract": "Argumentation mining (AM) aims to detect the arguments and their inherent relations from argumentative textual data. In this paper, we propose a novel approach called Prompting Task Interaction (PITA) for improving the performance of argumentation mining systems. PITA leverages the interaction between prompting and task-specific models to enhance the detection of arguments and their relations.\n\nWe first employ prompting to generate informative prompts that guide the model to focus on relevant argumentative information. These prompts are then used to condition task-specific models, such as transformers, to effectively capture argumentative structures. By integrating prompting into the AM task, PITA enables the model to better understand argumentative text and make more accurate predictions.\n\nOur experimental results demonstrate that PITA outperforms existing state-of-the-art approaches on argumentation mining tasks. We show that the interaction between prompting and task-specific models significantly improves the performance of argumentation mining systems, highlighting the effectiveness of our proposed approach.",
        "Source": "GPT"
    },
    {
        "Index": 275,
        "Title": "Shifting Attention to Relevance: Towards the Predictive Uncertainty Quantification of Free-Form Large Language Models.",
        "Abstract": "Large Language Models (LLMs) show promising results in language generation and instruction following but frequently suffer from the issue of ambiguous or irrelevant outputs. In this paper, we propose a novel approach for shifting attention to relevance in LLMs through the quantification of predictive uncertainty. By integrating uncertainty quantification techniques into the training and inference processes of LLMs, we aim to improve the model's ability to prioritize relevant information and reduce the generation of irrelevant or nonsensical outputs. Our approach leverages the concept of predictive uncertainty to guide the attention mechanism of LLMs, enabling the model to make more informed decisions about which parts of the input data to focus on during the generation process. Through experimental evaluations on various benchmarks, we demonstrate the effectiveness of our approach in improving the relevance and coherence of generated text while maintaining high levels of fluency and diversity. Overall, our work contributes to advancing the field of large language models towards more interpretable and contextually relevant text generation.",
        "Source": "GPT"
    },
    {
        "Index": 276,
        "Title": "Babel-ImageNet: Massively Multilingual Evaluation of Vision-and-Language Representations.",
        "Abstract": "Vision-and-language (VL) models with separate encoders for each modality, such as CLIP, have gained popularity due to their ability to learn rich cross-modal representations. In this study, we introduce Babel-ImageNet, a massively multilingual evaluation benchmark for VL representations. Our evaluation covers over 30 languages from diverse linguistic families, enabling a comprehensive analysis of the generalization capabilities of VL models across different languages.\n\nThrough extensive experiments, we demonstrate that CLIP-based models exhibit strong performance on Babel-ImageNet, showcasing their robustness and cross-lingual transfer capabilities. Additionally, we investigate the impact of pretraining data size, architecture choices, and fine-tuning strategies on the performance of VL models across various languages. Our results highlight the potential of VL models to achieve a high level of language-agnostic representation learning, paving the way for improved cross-lingual applications in vision and language domains. Overall, our study provides valuable insights into the effectiveness of VL models in handling multilingual data and offers guidance for future research directions in this rapidly evolving field.",
        "Source": "GPT"
    },
    {
        "Index": 277,
        "Title": "Estimating Agreement by Chance for Sequence Annotation.",
        "Abstract": "In the field of natural language processing, correction of performance assessment for chance agreement plays a critical role in accurately evaluating the performance of sequence annotation tasks. One method utilized for this purpose is the estimation of agreement by chance, which helps researchers distinguish between true agreement and random chance in annotated data. This paper focuses on the importance of estimating chance agreement in sequence annotation tasks, outlining the challenges and limitations associated with assessing agreement solely based on observed data. By employing statistical methods to estimate chance agreement, researchers are able to gain a more reliable understanding of inter-annotator agreement and make informed decisions about the accuracy of their annotation tasks. Through a thorough examination of the current methodologies and best practices for estimating agreement by chance, this paper aims to provide a comprehensive guide for researchers in the field of natural language processing seeking to enhance the reliability and validity of their sequence annotation evaluations.",
        "Source": "GPT"
    },
    {
        "Index": 278,
        "Title": "Are Emergent Abilities in Large Language Models just In-Context Learning?",
        "Abstract": "Large language models, comprising billions of parameters and pre-trained on extensive web-scale corpora, have been at the forefront of natural language processing tasks. These models have displayed remarkable abilities in various language-related tasks such as text generation, translation, summarization, and more. One area of interest is the emergence of new abilities in these models, which are not explicitly trained but seem to arise during the fine-tuning process. Some researchers argue that these emergent abilities are simply a result of in-context learning, where the model leverages its pre-existing knowledge to adapt to new tasks. This abstract explores the concept of emergent abilities in large language models, questioning whether they are indeed a form of in-context learning or indicative of the models' capacity for creative problem-solving. By understanding the mechanisms behind these emergent abilities, we can further enhance the capabilities of large language models and advance the field of natural language processing.",
        "Source": "GPT"
    },
    {
        "Index": 279,
        "Title": "WaveCoder: Widespread And Versatile Enhancement For Code Large Language Models By Instruction Tuning.",
        "Abstract": "Recent work demonstrates that after instruction tuning, Code Large Language Models (Code LLMs) can achieve significant improvements in performance and efficiency. In particular, WaveCoder stands out as a highly effective approach for enhancing Code LLMs in a widespread and versatile manner. By leveraging instruction tuning techniques, WaveCoder enables Code LLMs to better understand and generate various types of code, leading to more accurate and contextually relevant results.\n\nWaveCoder exhibits remarkable capabilities in enhancing the functionality and applicability of Code LLMs across different programming languages and domains. The technique not only boosts the overall performance of these models but also enhances their adaptability to diverse coding tasks. Additionally, WaveCoder provides a flexible and scalable solution for improving the efficiency and accuracy of Code LLMs without compromising on their capabilities.\n\nOverall, WaveCoder represents a promising advancement in the field of Code LLM development, offering a comprehensive and effective approach for enhancing these models through instruction tuning.",
        "Source": "GPT"
    },
    {
        "Index": 280,
        "Title": "Eliciting Better Multilingual Structured Reasoning from LLMs through Code.",
        "Abstract": "The development of large language models (LLM) has shown progress on reasoning tasks in a variety of languages. However, existing LLMs still struggle with multilingual reasoning and structured reasoning tasks, presenting a significant challenge in achieving human-like language understanding across languages. In this study, we propose a novel approach to elicit improved multilingual structured reasoning from LLMs through the use of code. By introducing a coding mechanism into the training process, we aim to enhance the model's ability to reason across multiple languages and structured formats. Through extensive experimentation and evaluation, we demonstrate that our approach leads to significant improvements in multilingual reasoning performance, highlighting the potential for code-based manipulation to enhance LLM capabilities in handling complex reasoning tasks. Our findings contribute to advancing the field of natural language processing and lay the foundation for future research on improving multilingual structured reasoning in LLMs.",
        "Source": "GPT"
    },
    {
        "Index": 281,
        "Title": "OLIVE: Object Level In-Context Visual Embeddings.",
        "Abstract": "Recent generalist vision-language models (VLMs) have demonstrated impressive reasoning capabilities across diverse multimodal tasks. However, these models often struggle with capturing fine-grained object-level in-context visual information. To address this limitation, we propose OLIVE: Object Level In-Context Visual Embeddings. OLIVE is a novel framework that leverages advanced object detection and segmentation techniques to generate detailed visual embeddings at the object level within a given context. By focusing on object-level representations, OLIVE enables more precise reasoning and understanding of visual scenes in multimodal tasks. We evaluate OLIVE on various benchmark datasets and demonstrate its effectiveness in enhancing the performance of VLMs in tasks such as visual question answering, image captioning, and visual reasoning. Our results show that OLIVE significantly outperforms existing approaches in capturing object-level information and improving overall task accuracy. Furthermore, we provide qualitative analyses highlighting the interpretability and robustness of OLIVE embeddings in complex visual contexts.",
        "Source": "GPT"
    },
    {
        "Index": 282,
        "Title": "Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness.",
        "Abstract": "We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained large language model. Our approach quantifies uncertainty in the answers provided by the model, enhancing their trustworthiness. By analyzing the confidence scores of the model for each answer, BSDetector can identify responses that may be unreliable or based on limited information. This can help users discern between accurate and uncertain information, allowing for better decision-making and reducing the potential spread of misinformation. We demonstrate the effectiveness of BSDetector through experiments on a variety of language models, showcasing its ability to improve the overall reliability of responses. By enhancing trust in language models, BSDetector contributes to increasing the utility and credibility of machine-generated answers in a wide range of applications.",
        "Source": "GPT"
    },
    {
        "Index": 283,
        "Title": "Marathon: A Race Through the Realm of Long Context with Large Language Models.",
        "Abstract": "With the advancement of large language models (LLMs) and the expansion of their context windows, the capabilities of these models have grown exponentially. This has allowed for a deeper understanding and generation of text, enabling LLMs to provide more informative and contextually relevant responses. In this paper, we explore the implications of these developments in the context of marathons, a long-distance running race that tests an individual's endurance and stamina over a grueling course. By harnessing the power of LLMs, we delve into the realm of marathons to analyze the strategies, training techniques, and mental fortitude required to compete in such an event. Additionally, we discuss how LLMs can be utilized to provide personalized training recommendations, track progress, and offer insights into the world of marathon running. Through this exploration, we aim to showcase the potential of LLMs in unraveling the complexities of endurance sports and enhancing performance optimization in the realm of long-distance running.",
        "Source": "GPT"
    },
    {
        "Index": 284,
        "Title": "Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph.",
        "Abstract": "Model scaling is becoming the default choice for many language tasks due to its success in achieving state-of-the-art performance. However, in the realm of patent approval prediction, scaling alone may not be sufficient to capture the intricate relationships within patent claims. In this study, we propose a novel approach utilizing domain-specific fine-grained claim dependency graphs to enhance the prediction of patent approval. By encoding the dependencies among individual claims, our model goes beyond simple scaling techniques to capture the nuanced interactions between claims and their contributions to the overall patent application. We demonstrate the effectiveness of our approach on a large dataset of patent applications, showing significant improvements in prediction accuracy compared to traditional methods. Our work sheds light on the importance of considering domain-specific structures in language tasks, and offers a valuable contribution to the field of patent approval prediction. Through the utilization of fine-grained claim dependency graphs, we provide a new perspective on how to improve the performance of language models in specialized domains.",
        "Source": "GPT"
    },
    {
        "Index": 285,
        "Title": "PCAD: Towards ASR-Robust Spoken Language Understanding via Prototype Calibration and Asymmetric Decoupling.",
        "Abstract": "Spoken language understanding (SLU) relies on accurate automatic speech recognition (ASR) for effective communication between humans and machines. However, ASR errors can severely impact the performance of SLU systems, leading to misunderstandings and misinterpretations of user input. In this paper, we propose a novel approach, ASR-Robust Spoken Language Understanding, which aims to mitigate the negative effects of ASR errors on SLU. Our method involves prototype calibration and asymmetric decoupling, techniques that enhance the robustness of SLU models to ASR inaccuracies. By calibrating the prototypes used in SLU tasks and decoupling the ASR and SLU processes asymmetrically, we demonstrate significant improvements in the accuracy and reliability of spoken language understanding in the presence of ASR errors. Our experimental results on benchmark datasets show that our approach outperforms existing methods in handling ASR-induced noise and improving the overall performance of SLU systems. The integration of prototype calibration and asymmetric decoupling holds promise for enhancing the robustness and accuracy of spoken language understanding in real-world scenarios.",
        "Source": "GPT"
    },
    {
        "Index": 286,
        "Title": "Rethinking the Multimodal Correlation of Multimodal Sequential Learning via Generalizable Attentional Results Alignment.",
        "Abstract": "Transformer-based methods have gained popularity in multimodal sequential learning for capturing intra and inter-modality interactions. However, existing approaches often overlook the importance of generalizable attentional results alignment across different modalities. In this paper, we propose a new framework for rethinking the multimodal correlation in sequential learning tasks by incorporating generalizable attentional results alignment. Our approach leverages the Transformer architecture to effectively model the complex relationships between different modalities while also focusing on aligning attentional results to ensure a more cohesive understanding of multimodal data. We demonstrate the effectiveness of our framework on various multimodal sequential learning tasks, showing significant improvements in prediction accuracy and generalization capabilities compared to existing methods. By rethinking the traditional approach to multimodal correlation, our proposed framework offers a novel perspective on how attention mechanisms can be leveraged to enhance the performance of multimodal sequential learning models.",
        "Source": "GPT"
    },
    {
        "Index": 287,
        "Title": "UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation.",
        "Abstract": "Large language models (LLMs) have demonstrated impressive capabilities in generating coherent and contextually relevant text. However, they also exhibit a tendency to produce hallucinated text, which can significantly impact their practical utility in professional contexts. This phenomenon presents a significant challenge in leveraging LLMs for tasks such as content generation and language understanding in industries such as journalism, marketing, and customer service.\n\nIn this study, we introduce UHGEval, a benchmarking framework designed to evaluate the hallucination behavior of Chinese LLMs through unconstrained text generation tasks. By systematically generating and analyzing text samples, we aim to quantify the extent of hallucination exhibited by different models and identify potential strategies to mitigate this issue. Our results reveal the varying degrees of hallucination observed in different Chinese LLMs and provide insights into the factors influencing this behavior.\n\nOverall, our findings highlight the importance of addressing hallucination in LLMs to enhance their reliability and effectiveness in professional applications.",
        "Source": "GPT"
    },
    {
        "Index": 288,
        "Title": "PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers.",
        "Abstract": "Large Multimodal Models (LMMs) excel in natural language and visual understanding but are challenged by fine-grained late-interaction multimodal retrieval tasks due to their computational complexity and inefficient memory usage. To address this issue, we propose a novel approach called PreFLMR (Pre-training Fine-Grained Late-Interaction Multi-modal Retrievers) which focuses on scaling up fine-grained late-interaction multimodal retrievers. PreFLMR leverages pre-training techniques to initialize the model weights and fine-tunes them on a specific task, leading to improved performance on fine-grained late-interaction multimodal retrieval tasks while reducing the computational burden. Our experiments on benchmark datasets demonstrate that PreFLMR outperforms existing methods in terms of retrieval accuracy and computational efficiency. Additionally, our approach is scalable and can be easily adapted to various domains and tasks, making it a promising solution for scaling up fine-grained late-interaction multimodal retrievers in real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 289,
        "Title": "Triple-Encoders: Representations That Fire Together, Wire Together.",
        "Abstract": "Search-based dialog models often re-encode the dialog history at every turn, leading to high computational costs. In response to this issue, we propose a novel Triple-Encoders approach that aims to efficiently process dialog history by capitalizing on the idea of \"Repetitions in Dialogs Representations Fire Together, Wire Together.\" Our Triple-Encoders model consists of three separate encoders that jointly capture various aspects of the dialog history, enabling more effective representation learning. Specifically, we employ a Curved Contrastive loss function that encourages the encoders to learn complementary and discriminative representations of the dialog history. Experimental results demonstrate that our Triple-Encoders approach outperforms existing search-based dialog models in terms of both computational efficiency and dialog quality. Overall, our work highlights the importance of designing efficient encoding mechanisms for dialog systems, and showcases the benefits of leveraging multiple encoders to capture diverse facets of the dialog history.",
        "Source": "GPT"
    },
    {
        "Index": 290,
        "Title": "Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning.",
        "Abstract": "Hateful memes have emerged as a significant concern on the Internet due to their ability to perpetuate harmful stereotypes and incite violence. Detecting such memes poses a challenge, as they often contain subtle or coded language and imagery that require nuanced interpretation. In this study, we propose a novel approach to improve hateful meme detection through retrieval-guided contrastive learning. By leveraging retrieval-based methods, our model learns to distinguish between hateful and non-hateful memes by comparing them in a contrastive manner. We demonstrate the effectiveness of our approach on a large-scale dataset of memes, achieving state-of-the-art performance in hateful meme detection. Our results highlight the importance of utilizing retrieval-guided contrastive learning for enhancing the accuracy and robustness of meme classification models. This research contributes to the ongoing efforts to mitigate the spread of hateful content online and protect vulnerable communities from targeted harassment and discrimination.",
        "Source": "GPT"
    },
    {
        "Index": 291,
        "Title": "Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization.",
        "Abstract": "Large Language Models (LLMs) have demonstrated impressive problem-solving capabilities across a wide range of tasks. Despite their success, traditional LLM-based agents often lack the ability to adapt and evolve their strategies over time. In this paper, we introduce Agent-Pro, a novel approach that enables LLM-based agents to learn and evolve through policy-level reflection and optimization. By incorporating a feedback loop mechanism, Agent-Pro allows agents to continually assess their performance and make adjustments to their policies in order to improve their problem-solving abilities. Through a series of experiments on various tasks, we demonstrate that Agent-Pro significantly outperforms traditional LLM-based agents in terms of adaptation and problem-solving efficiency. Our results highlight the potential of policy-level reflection and optimization in enhancing the capabilities of LLM-based agents, paving the way for more flexible and adaptable artificial intelligence systems.",
        "Source": "GPT"
    },
    {
        "Index": 292,
        "Title": "Your Transformer is Secretly Linear.",
        "Abstract": "This paper reveals a novel linear characteristic exclusive to transformer decoders, including models like GPT. Through a series of experiments and theoretical analysis, we show that these models, known for their ability to capture complex and non-linear dependencies, also possess a hidden linear structure that can enhance their performance in certain tasks. Specifically, we demonstrate that the attention mechanism in transformer decoders can be decomposed into a series of linear transformations, allowing for more efficient computation and interpretation of the model's behavior. This linear characteristic, which we refer to as \"secret linearity,\" opens up new possibilities for understanding and improving transformer-based models. By exploiting this hidden property, researchers and practitioners can optimize the performance of transformers in various natural language processing tasks, such as text generation, translation, and sentiment analysis. Overall, this paper sheds light on a previously unknown aspect of transformer decoders, highlighting the importance of considering both their non-linear and linear capabilities in future research and applications.",
        "Source": "GPT"
    },
    {
        "Index": 293,
        "Title": "Noise Correction on Subjective Datasets.",
        "Abstract": "Incorporating every annotator’s perspective is crucial for unbiased data modeling. However, subjective datasets often pose challenges due to annotator fatigue and changing opinions. In this study, we propose a noise correction technique specifically tailored for subjective datasets to address these challenges. Our method utilizes a combination of consensus-based filtering and individual annotator bias correction to accurately capture the true underlying patterns in the data. By incorporating insights from all annotators while accounting for individual biases, our approach ensures that the resulting dataset is more robust and reflective of the true distribution of opinions. We demonstrate the effectiveness of our noise correction technique through experiments on various subjective datasets, showing significant improvements in model performance and generalization. Overall, our proposed method offers a valuable contribution towards enhancing the quality of subjective data modeling by mitigating the impact of annotator fatigue and opinions shift.",
        "Source": "GPT"
    },
    {
        "Index": 294,
        "Title": "Generative Explore-Exploit: Training-free Optimization of Generative Recommender Systems using LLM Optimizers.",
        "Abstract": "Recommender systems are widely used to suggest engaging content, and Large Language Models (LLMs) have significantly advanced the capabilities of such systems. In this study, we propose a novel approach for optimizing generative recommender systems using LLM Optimizers, which enables training-free optimization. By leveraging the language generation capabilities of LLMs, our method, known as Generative Explore-Exploit, seeks to strike a balance between exploring new content recommendations and exploiting existing knowledge to improve user engagement. Through extensive experiments on real-world datasets, we demonstrate the effectiveness of our approach in enhancing recommendation quality and diversity without the need for extensive training. Our results show that Generative Explore-Exploit outperforms traditional recommender system optimization techniques, offering a promising avenue for improving user satisfaction and engagement in online platforms. Overall, our study contributes to the evolving landscape of recommender systems by leveraging cutting-edge LLM technology for efficient and effective content recommendation optimization.",
        "Source": "GPT"
    },
    {
        "Index": 295,
        "Title": "Instruction-tuned Language Models are Better Knowledge Learners.",
        "Abstract": "In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it is essential for them to continuously learn and update their knowledge base. One promising approach to achieve this is through instruction-tuned language models, which are specifically trained to improve their knowledge acquisition capabilities. This study explores the benefits of instruction tuning for language models, demonstrating that they are able to learn new concepts and information more efficiently compared to traditional LLMs. By fine-tuning the model with instructional data, it can better understand and retain important information, making it a more competent knowledge learner. Moreover, instruction-tuned language models exhibit enhanced performance when handling complex tasks and questions that require a deeper understanding of the content. Overall, this research highlights the importance of incorporating instructional data into LLM training to enhance their knowledge acquisition abilities and improve their effectiveness as assistants in providing up-to-date and accurate information.",
        "Source": "GPT"
    },
    {
        "Index": 296,
        "Title": "What Do Language Models Hear? Probing for Auditory Representations in Language Models.",
        "Abstract": "This work explores whether language models encode meaningfully grounded representations of sounds of objects. We propose a methodology for probing the presence of auditory representations in language models, leveraging the publicly available ImageNet dataset and a diverse set of audio samples. Through experiments conducted on state-of-the-art language models, including BERT and GPT-3, we investigate the extent to which these models capture auditory information in their learned representations. Our findings suggest that while language models do exhibit some sensitivity to auditory characteristics, such as onomatopoeic words, their overall ability to encode detailed auditory information remains limited. We also observe variations in auditory representation across different models and training conditions, indicating potential avenues for future research and model improvement. Overall, our study sheds light on the auditory processing capabilities of language models and opens up exciting possibilities for the integration of sound-based representations in natural language understanding tasks.",
        "Source": "GPT"
    },
    {
        "Index": 297,
        "Title": "Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs.",
        "Abstract": "With the advent of large language models (LLMs), the line between human-crafted and machine-generated texts has become increasingly blurred. As a result, the detection of machine-generated texts has become a critical challenge in the field of natural language processing. In this paper, we propose a novel approach to identifying machine-generated texts based on discourse motifs, which are recurring patterns of language use that are indicative of certain styles or genres of writing. By analyzing the underlying structure and coherence of texts, we can uncover subtle clues that differentiate human-crafted from machine-generated content.\n\nThrough experiments on various datasets, we demonstrate the effectiveness of our approach in accurately detecting machine-generated texts. Our findings not only shed light on the capabilities of LLMs in generating realistic texts but also offer new insights into the ways in which language patterns can be leveraged for text analysis tasks. This research contributes to the growing body of work aimed at improving the transparency and trustworthiness of machine-generated content in an era dominated by artificial intelligence.",
        "Source": "GPT"
    },
    {
        "Index": 298,
        "Title": "Jailbreak Open-Sourced Large Language Models via Enforced Decoding.",
        "Abstract": "Large Language Models (LLMs) have achieved unprecedented performance in Natural Language Generation (NLG) tasks. However, concerns over privacy and security have arisen due to the potential for malicious actors to utilize LLMs for harmful purposes, such as generating fake news or engaging in phishing attacks. In order to address these concerns, researchers have proposed the use of enforced decoding techniques to prevent misuse of LLMs. In this paper, we present a novel approach for Jailbreak Open-Sourcing LLMs, which involves utilizing enforced decoding mechanisms to restrict the output of LLMs to ensure compliance with ethical and legal guidelines. Our method aims to strike a balance between promoting innovation and protecting users from potential harm. Through experimental evaluations, we demonstrate the effectiveness of our approach in mitigating security risks associated with LLMs while still maintaining high performance in NLG tasks. Overall, Jailbreak Open-Sourcing LLMs via enforced decoding has the potential to enhance the safety and reliability of LLMs for various applications.",
        "Source": "GPT"
    },
    {
        "Index": 299,
        "Title": "NICE: To Optimize In-Context Examples or Not?",
        "Abstract": "Recent work shows that in-context learning and optimization of in-context examples (ICE) can significantly improve the performance of machine learning models. However, the question remains: is it worth the computational cost to optimize in-context examples? This paper aims to explore the effectiveness of ICE in optimizing machine learning models and the trade-offs associated with it. We present a comprehensive analysis of the benefits and challenges of incorporating ICE into the training process, considering factors such as data efficiency, model interpretability, and computation time. Our results suggest that while ICE can lead to impressive gains in model performance, the decision to optimize in-context examples should be carefully evaluated based on the specific requirements of the task at hand. Ultimately, this study provides insights into the utility of ICE and offers practical recommendations for researchers and practitioners seeking to enhance the performance of their machine learning models.",
        "Source": "GPT"
    },
    {
        "Index": 300,
        "Title": "CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation.",
        "Abstract": "Large Language Models (LLMs) have demonstrated remarkable performance on assisting humans in programming and facilitating various natural language processing tasks. However, evaluating the understanding and generation capabilities of LLMs on code remains a challenging task. In this study, we introduce CodeScope, an execution-based multilingual multitask multidimensional benchmark specifically designed for evaluating LLMs on code understanding and generation tasks. CodeScope consists of a diverse set of code understanding and generation tasks covering multiple programming languages and paradigms. By evaluating LLMs on CodeScope, we aim to provide a comprehensive assessment of their performance in understanding and generating code across different contexts and languages. Our experimental results show that LLMs achieve competitive performance on code understanding and generation tasks in CodeScope, highlighting their potential for assisting developers in writing and understanding code. We believe that CodeScope can serve as a valuable resource for researchers and practitioners in the field of artificial intelligence and programming language understanding.",
        "Source": "GPT"
    },
    {
        "Index": 301,
        "Title": "Digital Socrates: Evaluating LLMs through Explanation Critiques.",
        "Abstract": "While LLMs can provide reasoned explanations along with their answers, the nature and quality of these explanations are not always apparent. In this study, we introduce the concept of Explanation Critiques to evaluate LLM-generated explanations in a more comprehensive manner. Drawing inspiration from the Socratic method of questioning and critical evaluation, our approach involves systematically analyzing the coherence, consistency, and logical reasoning of LLM explanations. By applying this framework to a diverse set of LLM models, we aim to assess their overall performance in terms of generating meaningful explanations for complex tasks. Our findings suggest that while LLMs excel in certain domains, there are still significant limitations in their ability to provide accurate and coherent explanations. We propose that a more nuanced evaluation method, such as Explanation Critiques, can help uncover these shortcomings and guide future advancements in the development of explainable AI systems.",
        "Source": "GPT"
    },
    {
        "Index": 302,
        "Title": "SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding.",
        "Abstract": "SafeDecoding presents a novel approach to defending against jailbreak attacks targeting large language models (LLMs) used in real-world applications. By leveraging safety-aware decoding techniques, SafeDecoding enhances the security of LLMs by detecting and preventing malicious input that could exploit vulnerabilities in the system.\n\nJailbreak attacks pose a significant threat to the integrity and privacy of sensitive data processed by LLMs, making it crucial to develop robust defense mechanisms. SafeDecoding achieves this by incorporating safety constraints into the decoding process, ensuring that only safe and valid inputs are accepted by the LLMs. This mitigates the risk of jailbreak attacks that attempt to compromise the LLMs through malicious inputs.\n\nOverall, SafeDecoding provides a proactive and effective defense strategy for safeguarding LLMs against jailbreak attacks, thereby enhancing the overall security posture of real-world applications utilizing these powerful models.",
        "Source": "GPT"
    },
    {
        "Index": 303,
        "Title": "Multi-Task Inference: Can Large Language Models Follow Multiple Instructions at Once?",
        "Abstract": "Large language models (LLMs) are typically prompted to follow a single instruction per inference call. However, in real-world scenarios, tasks often involve multiple instructions that must be executed simultaneously. This paper investigates the ability of LLMs to follow multiple instructions at once, a concept known as multi-task inference. We present empirical findings from experiments conducted on a popular LLM to evaluate its performance on various multi-task inference scenarios. Our results show that while LLMs excel at single-task inference, their performance significantly drops when tasked with following multiple instructions concurrently. We find that the complexity and interdependence of the instructions play a significant role in determining the model's ability to successfully execute the tasks. Our findings provide insights into the limitations of current LLMs in handling multi-task inference and highlight the need for further research to improve their multitasking capabilities.",
        "Source": "GPT"
    },
    {
        "Index": 304,
        "Title": "Experiential Co-Learning of Software-Developing Agents.",
        "Abstract": "Recent advancements in large language models (LLMs) have revolutionized the field of artificial intelligence, enabling machines to understand and generate human-like text with unprecedented accuracy. This breakthrough technology has found applications in diverse domains, from natural language processing to virtual assistants and automated content creation. However, one area that has seen limited exploration is the co-learning of LLMs in the context of software development.\n\nIn this paper, we propose a novel approach to experiential co-learning of software-developing agents, leveraging the capabilities of LLMs to enhance collaboration and knowledge sharing among artificial agents. By enabling software-developing agents to interact and learn from each other in a virtual environment, we aim to accelerate the software development process and facilitate the creation of more robust and efficient codebases. Through experiments and case studies, we demonstrate the potential of this approach to revolutionize the way software is developed, paving the way for a new era of collaborative and intelligent software engineering.",
        "Source": "GPT"
    },
    {
        "Index": 305,
        "Title": "Learning Geometry-Aware Representations for New Intent Discovery.",
        "Abstract": "New intent discovery (NID) is an important problem for deploying practical dialogue systems, which trains machines to understand and respond to user intents in conversations. In this research, we propose learning geometry-aware representations to enhance the capabilities of dialogue systems in discovering new intents. By incorporating geometric properties into the representation learning process, the dialogue system can better capture the underlying structure and relationships between user intents, leading to more accurate intent prediction and response generation. Our approach leverages the rich information embedded in the geometric space to improve the overall performance of the dialogue system in handling complex and unseen intents. Experimental results demonstrate that our geometry-aware representations outperform traditional methods in NID tasks, showcasing the effectiveness and potential of our proposed approach in advancing the capabilities of dialogue systems. This research contributes to the growing body of work on improving dialogue systems through innovative representation learning techniques.",
        "Source": "GPT"
    },
    {
        "Index": 306,
        "Title": "Speaker Verification in Agent-generated Conversations.",
        "Abstract": "The recent success of large language models (LLMs) has sparked interest in utilizing them for various applications, including agent-generated conversations. In this paper, we explore the potential of using speaker verification techniques in agent-generated conversations to enhance security and authentication measures. By incorporating speaker verification technology into LLM-based conversational agents, we can ensure that only authorized individuals are able to access sensitive information or perform specific tasks. We investigate different approaches to speaker verification, such as text-dependent and text-independent methods, and evaluate their effectiveness in agent-generated conversations. Our results show promising performance in accurately verifying speakers in real-time interactions, demonstrating the potential of combining LLMs and speaker verification for secure and reliable conversational systems. Overall, this research opens up new avenues for incorporating advanced security measures into agent-generated conversations, paving the way for improved user authentication and privacy protection in various applications.",
        "Source": "GPT"
    },
    {
        "Index": 307,
        "Title": "Benchmarking Data Science Agents.",
        "Abstract": "In the era of data-driven decision-making, the complexity of data analysis necessitates advanced expertise and tools. One approach to handling this complexity is the use of data science agents, which are autonomous software agents equipped with machine learning algorithms to analyze and interpret data. Benchmarking data science agents involves evaluating their performance on various tasks such as predictive modeling, clustering, and anomaly detection. By comparing the performance of different agents, organizations can identify the most effective solutions for their data analysis needs. This paper explores the importance of benchmarking data science agents in the context of data-driven decision-making and discusses key considerations for conducting benchmarking studies. By leveraging benchmarking data science agents, organizations can make informed decisions about which tools and techniques to employ for extracting valuable insights from their data.",
        "Source": "GPT"
    },
    {
        "Index": 308,
        "Title": "Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models.",
        "Abstract": "Large language models (LLMs) have exhibited impressive multilingual capabilities without prior training on specific multilingual datasets. Recent studies have shown that language-specific neurons within LLMs play a crucial role in facilitating this multilingual performance. These language-specific neurons encode linguistic features that are specific to individual languages, allowing the model to seamlessly switch between different languages.\n\nBy leveraging these language-specific neurons, LLMs are able to generate accurate and coherent text in multiple languages, even ones that were not present during the model's training. This ability to effectively transfer knowledge across languages demonstrates the robustness and versatility of LLMs in handling diverse linguistic tasks.\n\nUnderstanding the importance of language-specific neurons in enabling multilingual capabilities in LLMs can inform the development of more efficient and effective language models that are capable of mastering multiple languages with minimal additional training. This research highlights the key role that language-specific neurons play in unlocking the full potential of multilingual LLMs.",
        "Source": "GPT"
    },
    {
        "Index": 309,
        "Title": "Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models.",
        "Abstract": "Recent advancements in Large Language Models (LLMs) have showcased their remarkable capabilities in text understanding, with models like GPT-3 exhibiting human-level performance on various language tasks. However, one fundamental challenge faced by LLMs is the ability to forget outdated information and adapt to new knowledge. In this paper, we propose a novel approach called Parametric Arithmetic for Knowledge Updating in LLMs to address this challenge. By leveraging parametric operations, our method allows the model to forget outdated knowledge while selectively retaining relevant information for ongoing learning tasks. We demonstrate the effectiveness of our approach through experiments on benchmark datasets, showing improved performance in knowledge retention and adaptability compared to traditional fine-tuning methods. Our findings highlight the importance of efficient knowledge updating mechanisms in LLMs to enhance their overall learning capabilities and facilitate continuous adaptation to new information.",
        "Source": "GPT"
    },
    {
        "Index": 310,
        "Title": "A Deep Dive into the Trade-Offs of Parameter-Efficient Preference Alignment Techniques.",
        "Abstract": "Large language models are revolutionizing a variety of industries by generating high-quality text based on vast amounts of training data. However, the process of aligning these models with specific preferences or instructions can be challenging and resource-intensive. This paper explores the trade-offs involved in different parameter-efficient preference alignment techniques that aim to improve model performance while minimizing computational costs. We first discuss the pre-training stage, where models are trained on trillions of tokens to learn general language patterns. Then, we examine the process of instruction-tuning or aligning these models with desired preferences, such as sentiment or topic-specific information. By analyzing the pros and cons of various preference alignment methods, we aim to provide insights into how to balance performance gains with computational efficiency. This deep dive into parameter-efficient preference alignment techniques sheds light on the complexities of optimizing large language models for specific tasks, offering guidance for practitioners looking to enhance model capabilities while managing resources effectively.",
        "Source": "GPT"
    },
    {
        "Index": 311,
        "Title": "Zero-Shot Cross-Domain Dialogue State Tracking via Dual Low-Rank Adaptation.",
        "Abstract": "Zero-shot dialogue state tracking (DST) seeks to enable dialogue systems to transition to unfamiliar domains without requiring any domain-specific data for training. In this study, we propose a novel approach, called Dual Low-Rank Adaptation (DLRA), to address the zero-shot cross-domain DST problem. DLRA leverages the low-rank structure of the dialogue state representations in both the source and target domains to learn domain-invariant features, enabling effective transfer of knowledge across domains. By jointly optimizing a domain adaptation loss and a low-rank constraint, DLRA effectively adapts the dialogue state tracker to new domains with limited or no labeled data.\n\nWe conduct extensive experiments on benchmark datasets to evaluate the performance of DLRA against existing methods for zero-shot cross-domain DST. Our results demonstrate that DLRA consistently outperforms the state-of-the-art approaches, showcasing its ability to effectively generalize across diverse domains without the need for domain-specific training data.",
        "Source": "GPT"
    },
    {
        "Index": 312,
        "Title": "PRP-Graph: Pairwise Ranking Prompting to LLMs with Graph Aggregation for Effective Text Re-ranking.",
        "Abstract": "Pairwise Ranking Prompting (PRP) has shown notable success in zero-shot document re-ranking for large language models (LLMs). In this paper, we introduce PRP-Graph, a novel approach that leverages the power of PRP in combination with graph aggregation techniques for even more effective text re-ranking. By using PRP to prompt LLMs with pairwise comparisons of document relevance, our method enhances the model's ability to accurately assess and rank documents based on their relevance to a given query. Additionally, the inclusion of graph aggregation allows for the integration of contextual information and relationships between documents, further improving the re-ranking capabilities of LLMs. Experimental results on benchmark datasets demonstrate the superior performance of PRP-Graph compared to existing methods, highlighting the potential of our approach for enhancing document retrieval and ranking tasks. Overall, our work underscores the effectiveness of combining PRP with graph aggregation techniques to achieve more accurate and efficient text re-ranking with LLMs.",
        "Source": "GPT"
    },
    {
        "Index": 313,
        "Title": "RepCodec: A Speech Representation Codec for Speech Tokenization.",
        "Abstract": "With the recent rapid growth of large language models (LLMs), the demand for efficient speech tokenization techniques has become increasingly important. In this paper, we present RepCodec, a novel Speech Representation Codec designed specifically for the task of speech tokenization. RepCodec utilizes a unique approach to encode speech signals into compact and informative representations, making it suitable for use in various LLM applications such as automatic speech recognition and natural language understanding. We evaluate the performance of RepCodec on a diverse set of benchmark datasets and show that it outperforms existing speech tokenization methods in terms of accuracy and efficiency. Additionally, we demonstrate the versatility of RepCodec by integrating it into several state-of-the-art LLMs, where it consistently improves the performance of these models across different tasks. Overall, our results suggest that RepCodec is a promising solution for enhancing the capabilities of LLMs in processing speech data, paving the way for more effective and scalable speech applications in the future.",
        "Source": "GPT"
    },
    {
        "Index": 314,
        "Title": "GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick.",
        "Abstract": "Large language models (LLMs) have exhibited remarkable capabilities in generating human-like text, revolutionizing numerous natural language processing tasks. However, their widespread deployment has also raised concerns regarding potential misuse, such as generating fake news, spreading disinformation, and promoting hate speech. To address these challenges, this study introduces GumbelSoft, a novel approach for watermarking LLMs to protect against misuse. By leveraging the GumbelMax-trick, our method embeds imperceptible watermarks into the language model parameters, allowing for the identification and tracing of generated text back to the original model. This watermarking technique provides a crucial tool for enhancing the accountability and transparency of LLM-generated content, deterring malicious actors from engaging in harmful activities. Experimental results demonstrate the effectiveness of GumbelSoft in watermarking various LLM architectures, including GPT-3 and BERT, without significantly impacting their performance. Overall, our proposed approach offers a promising solution to mitigate the risks associated with LLM misuse, safeguarding the integrity of language generation systems in the digital age.",
        "Source": "GPT"
    },
    {
        "Index": 315,
        "Title": "Event-Radar: Event-driven Multi-View Learning for Multimodal Fake News Detection.",
        "Abstract": "The swift detection of multimedia fake news has emerged as a crucial task in combating the spread of false information. In this paper, we propose Event-Radar, a novel event-driven multi-view learning framework for multimodal fake news detection. By integrating multiple modalities including text, image, and video data, Event-Radar captures the complex relationships between various sources of information to improve the accuracy of fake news detection. Our framework leverages event-driven hierarchical attention mechanisms to effectively model the temporal dynamics and interdependencies within news events. Additionally, we introduce a multi-view fusion strategy to integrate information from different modalities, enhancing the robustness and generalizability of the detection system. Experimental results on a real-world dataset demonstrate the effectiveness of Event-Radar in accurately detecting multimodal fake news. The proposed framework outperforms existing state-of-the-art methods, highlighting its potential for practical applications in combating misinformation in online media platforms.",
        "Source": "GPT"
    },
    {
        "Index": 316,
        "Title": "Fine-Grained Modeling of Narrative Context: A Coherence Perspective via Retrospective Questions.",
        "Abstract": "This work introduces an original and practical paradigm for narrative comprehension, stemming from the characteristics of fine-grained modeling of narrative context. By focusing on coherence from a retrospective questioning perspective, this paradigm allows for a deeper understanding of the underlying structure and dynamics within a narrative. Through the analysis of retrospective questions, this approach provides insights into how different elements of a narrative are interconnected and contribute to the overall coherence of the story. This fine-grained modeling of narrative context offers a more nuanced and detailed view of the relationships between characters, events, and themes, enabling a richer interpretation of the text. By applying this paradigm, readers can gain a deeper appreciation of the complexities and intricacies of narratives, leading to a more profound understanding of the text as a whole. This approach has the potential to enhance the way narratives are analyzed, interpreted, and appreciated across various genres and forms of storytelling.",
        "Source": "GPT"
    },
    {
        "Index": 317,
        "Title": "Stealthy Attack on Large Language Model based Recommendation.",
        "Abstract": "Recently, the powerful large language models (LLMs) have been instrumental in propelling the progress of natural language processing tasks, including recommendation systems. These LLMs, such as BERT and GPT-3, have shown remarkable performance in understanding and generating human language. However, their growing popularity and adoption have also raised concerns about potential security vulnerabilities. In this paper, we investigate a stealthy attack on LLM-based recommendation systems, where an adversary leverages the model's language understanding capabilities to manipulate recommendations without being detected. We demonstrate how an attacker can craft malicious input that subtly influences the LLM's recommendation outputs, leading to targeted manipulation of user choices or preferences. Through experiments and evaluation on real-world datasets, we show that the proposed attack is effective in achieving its goal while remaining undetected by traditional defense mechanisms. Our findings underscore the importance of developing robust and secure recommendation systems that can withstand adversarial attacks in the age of powerful LLMs.",
        "Source": "GPT"
    },
    {
        "Index": 318,
        "Title": "Multi-Dimensional Optimization for Text Summarization via Reinforcement Learning.",
        "Abstract": "In the field of text summarization, the evaluation of summary quality is crucial for assessing the effectiveness of summarization algorithms. This evaluation encompasses diverse dimensions including consistency, coherence, relevance, and fluency. However, existing methods often struggle to optimize across multiple dimensions simultaneously, leading to suboptimal performance. In this study, we propose a novel approach for multi-dimensional optimization in text summarization using reinforcement learning. By formulating the summarization task as a reinforcement learning problem, we are able to effectively balance the trade-offs between different dimensions of summary quality. Our experimental results demonstrate that our proposed method outperforms existing approaches in terms of overall summary quality. Additionally, our approach provides more flexibility for users to customize the summarization process based on their specific needs and preferences. Overall, our work contributes to advancing the state-of-the-art in text summarization by addressing the challenge of optimizing summary quality across multiple dimensions.",
        "Source": "GPT"
    },
    {
        "Index": 319,
        "Title": "Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models.",
        "Abstract": "In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal outcomes. This phenomenon is especially prevalent in mathematical reasoning, where missing or incorrect steps can significantly affect the final solution. In this study, we propose a novel approach to improve the mathematical reasoning learning of language models by incorporating partial reasoning steps through masking. Our method, termed Masked Thought, involves masking certain parts of the reasoning process to encourage the model to generate the correct intermediate steps. By guiding the model to focus on each reasoning step individually, we aim to enhance its overall understanding of the problem and improve the accuracy of the final solution. Our experiments demonstrate that incorporating the Masked Thought technique leads to substantial improvements in the mathematical reasoning capabilities of language models, with higher accuracy rates and more consistent problem-solving performance. This innovative approach showcases the potential of leveraging partial reasoning steps to enhance the learning abilities of language models in mathematical reasoning tasks.",
        "Source": "GPT"
    },
    {
        "Index": 320,
        "Title": "SEER: Facilitating Structured Reasoning and Explanation via Reinforcement Learning.",
        "Abstract": "Elucidating the reasoning process with structured explanations from question to answer is crucial, as it enhances understanding and transparency. In this paper, we introduce SEER, a novel framework that leverages reinforcement learning to facilitate structured reasoning and explanation. By utilizing a combination of neural networks, logic-based inference, and structured attention mechanisms, SEER can effectively guide the reasoning process step-by-step, providing clear and interpretable explanations for each decision made. This approach not only improves the overall performance of reasoning tasks but also enhances the trustworthiness of the model through transparent decision-making. Experimental results demonstrate that SEER outperforms existing methods in various reasoning tasks, showcasing its capability to provide insightful and coherent explanations. Overall, SEER represents a significant advancement in the field of artificial intelligence, offering a more intuitive and interpretable approach to structured reasoning and explanation.",
        "Source": "GPT"
    },
    {
        "Index": 321,
        "Title": "Towards Robust and Generalized Parameter-Efficient Fine-Tuning for Noisy Label Learning.",
        "Abstract": "Parameter-efficient fine-tuning (PEFT) has enabled the efficient optimization of cumbersome language models in real-world settings. However, the performance of fine-tuning methods can be significantly impacted by noisy labels present in the training data. In this work, we propose a novel approach towards robust and generalized parameter-efficient fine-tuning for noisy label learning. Our method leverages the concept of self-training and label smoothing to improve model performance in the presence of label noise. By dynamically adjusting the learning rate and regularization parameters during fine-tuning, our approach can effectively handle noisy labels and achieve improved generalization to unseen data. Experimental results on benchmark datasets demonstrate the effectiveness of our proposed method in achieving higher accuracy and robustness compared to existing fine-tuning techniques. Overall, our work contributes towards enhancing the parameter-efficient fine-tuning process for noisy label learning, making it more robust and applicable in various real-world scenarios.",
        "Source": "GPT"
    },
    {
        "Index": 322,
        "Title": "SparseFlow: Accelerating Transformers by Sparsifying Information Flows.",
        "Abstract": "Transformers have become the de-facto standard for natural language processing, but their dense information flows pose challenges for efficiency and scalability. In this paper, we introduce SparseFlow, a novel approach to accelerating Transformers by sparsifying information flows. By identifying and removing redundant connections between layers, SparseFlow significantly reduces the computational cost of processing large amounts of text data, while maintaining high levels of accuracy and performance.\n\nOur experimental results show that SparseFlow can achieve up to 50% reduction in computation time compared to traditional Transformers, without sacrificing model quality. In addition, SparseFlow allows for easier interpretation and visualization of the model's decision-making process, making it a valuable tool for researchers and practitioners in the field of natural language processing.\n\nOverall, SparseFlow offers a promising solution for accelerating Transformers and making them more efficient and scalable for a wide range of applications.",
        "Source": "GPT"
    },
    {
        "Index": 323,
        "Title": "ProtT3: Protein-to-Text Generation for Text-based Protein Understanding.",
        "Abstract": "Language Models (LMs) have shown great promise in understanding and generating textual descriptions of proteins, particularly in the field of biomedical question-answering. In this study, we introduce ProtT3, a novel Protein-to-Text Generation model that leverages the power of LM architectures to enhance protein understanding through text generation. By fine-tuning pre-trained LM models on protein-specific data, ProtT3 is able to generate detailed and accurate textual descriptions of proteins, providing valuable insights for researchers and clinicians in the biomedical domain.\n\nOur experimental results demonstrate the effectiveness of ProtT3 in generating informative and coherent protein descriptions, outperforming existing protein text generation models. Additionally, we show that ProtT3 can assist in various protein-related tasks such as protein function prediction, structural analysis, and drug discovery. Overall, our work highlights the potential of utilizing LM-based approaches for text-based protein understanding, opening up new avenues for advancing research in the biomedical field.",
        "Source": "GPT"
    },
    {
        "Index": 324,
        "Title": "KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models.",
        "Abstract": "Automatic evaluation methods for large language models (LLMs) are hindered by data contamination, leading to inaccurate assessments of model performance. In order to address this issue, we propose KIEval, a Knowledge-grounded Interactive Evaluation framework for LLMs. KIEval incorporates human-in-the-loop feedback to provide more reliable and informative evaluations of LLMs by leveraging external knowledge sources. By integrating human judgement with automated metrics, KIEval aims to mitigate the effects of data contamination and increase the trustworthiness of evaluation results.\n\nThe framework allows users to interactively assess the quality of LLM outputs using contextual information, ensuring that the evaluations are both comprehensive and accurate. Through the incorporation of external knowledge, KIEval enhances the interpretability and robustness of evaluation results, enabling researchers and practitioners to make more informed decisions about the performance of LLMs. Overall, KIEval serves as a valuable tool for evaluating the capabilities of LLMs in a more nuanced and reliable manner.",
        "Source": "GPT"
    },
    {
        "Index": 325,
        "Title": "EmoBench: Evaluating the Emotional Intelligence of Large Language Models.",
        "Abstract": "Recent advances in Large Language Models (LLMs) have led to significant improvements in natural language processing tasks. However, the emotional intelligence of these models remains an underexplored area. In our study, we introduce EmoBench, a benchmark dataset designed to evaluate the emotional intelligence of LLMs. EmoBench consists of diverse emotion-labeled data across various domains and languages, challenging LLMs to understand and generate emotional language accurately.\n\nWe propose a suite of evaluation metrics to assess the emotional intelligence of LLMs, including emotion recognition, emotion generation, and sentiment analysis. Through extensive experiments on popular LLMs such as GPT-3 and BERT, we demonstrate the effectiveness of EmoBench in evaluating and comparing the emotional capabilities of these models. Our findings suggest that while LLMs perform well on emotion recognition tasks, there is still room for improvement in accurately generating emotionally expressive language.\n\nOverall, EmoBench provides a valuable resource for researchers and developers to enhance the emotional intelligence of LLMs and create more empathetic and socially aware AI systems.",
        "Source": "GPT"
    },
    {
        "Index": 326,
        "Title": "Are AI-Generated Text Detectors Robust to Adversarial Perturbations?",
        "Abstract": "The widespread adoption of large language models (LLMs) has raised concerns about the potential for misuse, including the generation of deceptive or harmful content. One particular area of concern is the vulnerability of AI-generated text detectors to adversarial perturbations, which can manipulate text in subtle ways to evade detection. This study investigates the robustness of AI-generated text detectors to adversarial perturbations, aiming to understand the extent to which they can be deceived by carefully crafted input. We experiment with various techniques for generating adversarial perturbations and evaluate their effectiveness in fooling state-of-the-art text detectors. Our results suggest that while some detectors are resilient to adversarial attacks, others are highly susceptible, highlighting the need for improved defense mechanisms. Overall, this research underscores the importance of developing robust and reliable AI-generated text detectors to mitigate the risks associated with the misuse of LLMs.",
        "Source": "GPT"
    },
    {
        "Index": 327,
        "Title": "FinTextQA: A Dataset for Long-form Financial Question Answering.",
        "Abstract": "Accurate evaluation of financial question answering (QA) systems requires a comprehensive dataset that covers a range of diverse questions. In response to this need, we present FinTextQA, a dataset specifically designed for long-form financial question answering. FinTextQA contains a wide variety of questions related to finance, including topics such as investment strategies, market trends, and economic indicators. The dataset is curated to test the ability of QA systems to provide accurate and thorough answers to complex financial queries. With its focus on long-form questions, FinTextQA challenges QA systems to not only retrieve relevant information but also to generate coherent and detailed responses. By providing a diverse set of questions and answers, FinTextQA offers researchers and developers a valuable resource for evaluating and improving the performance of financial QA systems. We believe that FinTextQA will facilitate advancements in the field of financial question answering and contribute to the development of more robust and reliable QA systems.",
        "Source": "GPT"
    },
    {
        "Index": 328,
        "Title": "On Measuring Faithfulness or Self-consistency of Natural Language Explanations.",
        "Abstract": "Large language models (LLMs) have greatly enhanced our ability to generate natural language explanations for their predictions, through techniques such as post-hoc or Chain-of-Thought (CoT) explanations. While these explanations provide valuable insights into the decision-making process of LLMs, measuring the faithfulness or self-consistency of these explanations remains a challenging task. In this study, we propose a novel framework for evaluating the faithfulness and self-consistency of natural language explanations provided by LLMs. Our framework leverages a combination of quantitative metrics and qualitative human evaluation to assess the degree to which explanations accurately reflect the underlying reasoning of the model and maintain logical coherence within themselves. By adopting this comprehensive approach, we aim to provide a more nuanced understanding of the strengths and limitations of LLM explanations, ultimately informing the development of more reliable and trustworthy natural language explanations in the future.",
        "Source": "GPT"
    },
    {
        "Index": 329,
        "Title": "Learning or Self-aligning? Rethinking Instruction Fine-tuning.",
        "Abstract": "Instruction Fine-tuning (IFT) is a critical step in the development of large language models (LLMs). In this phase, the model is fine-tuned on specific tasks or datasets to improve its performance. Previous research has mainly focused on traditional supervised learning approaches for IFT, where the model is trained on labeled data. However, recent studies have started to explore self-aligning methods that enable the model to learn without explicit supervision. These self-aligning approaches allow the model to adapt and improve by learning from its own mistakes and uncertainties.\n\nIn this paper, we propose a rethink of the traditional IFT process by considering the benefits and limitations of both supervised learning and self-aligning approaches. We argue that a combination of these two strategies may offer the best results in terms of model performance and generalization. By leveraging the strengths of both learning paradigms, we can fine-tune LLMs more effectively and efficiently. Our findings suggest that a balanced approach to instruction fine-tuning can lead to better overall model performance.",
        "Source": "GPT"
    },
    {
        "Index": 330,
        "Title": "Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?",
        "Abstract": "Recent progress in Language Model (LLM) discussion suggests that multi-agent discussion improves the reasoning abilities of LLMs. This paper explores the potential benefits of incorporating multi-agent discussions into LLM reasoning processes and challenges the traditional bounds of LLM reasoning. By allowing multiple agents to engage in discussions, LLMs can leverage diverse perspectives and knowledge to enhance their reasoning capabilities. We propose that multi-agent discussions can lead to more robust and nuanced reasoning outcomes compared to single-agent approaches. Through a series of experiments and analyses, we demonstrate the feasibility and effectiveness of incorporating multi-agent discussions into LLM reasoning tasks. Our findings suggest that multi-agent discussions hold the key to unlocking the full potential of LLMs and expanding the boundaries of LLM reasoning. This work opens up new possibilities for advancing the field of natural language processing and artificial intelligence by reimagining the ways in which LLMs engage in reasoning tasks.",
        "Source": "GPT"
    },
    {
        "Index": 331,
        "Title": "Soft Knowledge Prompt: Help External Knowledge Become a Better Teacher to Instruct LLM in Knowledge-based VQA.",
        "Abstract": "Recent advancements in Language-Modeling-based (LLM) systems have shown impressive performance on multi-modal tasks, sparking a growing interest in their capabilities. However, one key challenge that remains is their ability to effectively instruct Language-Leaning Models (LLMs) in knowledge-based Visual Question Answering (VQA) tasks. \n\nExternal knowledge sources, such as text corpora or knowledge bases, have the potential to enhance the understanding and reasoning capabilities of LLMs in these tasks. We propose leveraging external knowledge to become a better teacher for LLMs in knowledge-based VQA, aiming to improve their performance and interpretability in complex visual reasoning tasks. By integrating external knowledge into the training process, we can enhance the learning experience of LLMs and equip them with a deeper understanding of the world, ultimately improving their ability to accurately answer questions based on visual inputs. This approach has the potential to further advance the field of multi-modal learning and contribute to more robust and intelligent AI systems.",
        "Source": "GPT"
    },
    {
        "Index": 332,
        "Title": "TasTe: Teaching Large Language Models to Translate through Self-Reflection.",
        "Abstract": "Large language models (LLMs) have exhibited remarkable performance in various natural language processing tasks. Techniques for training LLMs have primarily focused on maximizing performance on specific benchmarks, such as machine translation tasks. However, these approaches often lack a mechanism for the model to reflect on its own decisions and improve its translation capabilities autonomously. In this work, we propose a novel approach, TasTe (Teaching through Self-Reflection), which enables LLMs to learn to translate by reflecting on their own outputs and identifying areas for improvement. TasTe leverages self-attention mechanisms to capture the relationships between different parts of the input sequence and uses reinforcement learning to optimize the model's translation performance while encouraging self-reflection. Our experimental results demonstrate that TasTe significantly improves translation quality compared to traditional training methods, especially in scenarios where the input contains complex or ambiguous language patterns. Overall, our approach highlights the importance of incorporating self-reflection mechanisms into LLM training to enhance their translation capabilities.",
        "Source": "GPT"
    },
    {
        "Index": 333,
        "Title": "Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models.",
        "Abstract": "A pivotal advancement in the progress of large language models (LLMs) is the emergence of mixture-of-experts architectures, which leverage multiple specialized experts to improve model performance. However, not all experts contribute equally to the final prediction, leading to inefficiencies in computation and potentially degrading model performance. In this paper, we propose an efficient expert pruning and skipping technique for mixture-of-experts LLMs, which dynamically selects and skips experts during inference to reduce computational overhead without sacrificing accuracy. Our method utilizes a gating mechanism to adaptively determine the importance of each expert for a given input, allowing for the selective activation of only the most relevant experts. This not only improves the efficiency of the model but also leads to better performance on various language understanding tasks. Through extensive experiments on popular benchmarks, we demonstrate the effectiveness of our approach in achieving state-of-the-art results with significantly reduced computational costs. Our work highlights the importance of optimizing expert utilization in mixture-of-experts LLMs for enhanced efficiency and performance.",
        "Source": "GPT"
    },
    {
        "Index": 334,
        "Title": "UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion.",
        "Abstract": "Existing text-to-image diffusion models primarily generate images from text prompts. However, the inherent conciseness of text prompts limits the diversity and richness of the generated images. In this paper, we introduce UNIMO-G, a novel unified image generation framework that leverages multimodal conditional diffusion to generate high-quality images from both text and image inputs. UNIMO-G combines the strengths of text-to-image and image-to-image diffusion models, allowing for more detailed and diverse image generation. By conditioning the diffusion process on both text and image features, UNIMO-G is able to capture a wider range of visual concepts and generate more visually compelling images. Experimental results demonstrate that UNIMO-G outperforms existing text-to-image diffusion models in terms of image quality, diversity, and realism. Our framework provides a significant advancement in the field of multimodal image generation, opening up new possibilities for generating realistic and diverse images from multimodal inputs.",
        "Source": "GPT"
    },
    {
        "Index": 335,
        "Title": "The Fine-Tuning Paradox: Boosting Translation Quality Without Sacrificing LLM Abilities.",
        "Abstract": "Fine-tuning large language models (LLMs) for machine translation has shown improvements in overall translation quality. However, this process often comes with trade-offs, sacrificing some of the LLM's natural language processing abilities in favor of specialized translation tasks. This paper aims to address the fine-tuning paradox by proposing a novel approach that leverages the capabilities of LLMs without compromising their general language understanding. We introduce a multi-task learning framework that combines translation-specific objectives with broader language understanding tasks, allowing the model to improve translation quality while maintaining proficiency in other natural language processing tasks. Our experimental results demonstrate that this approach effectively boosts translation quality without sacrificing the LLM's abilities in tasks such as language modeling, sentiment analysis, and question answering. By bridging the gap between specialized translation tasks and general language understanding, our proposed framework offers a promising direction for optimizing LLMs for machine translation without losing their overall language processing capabilities.",
        "Source": "GPT"
    },
    {
        "Index": 336,
        "Title": "Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts When Knowledge Conflicts?",
        "Abstract": "While auxiliary information has become a key to enhancing Large Language Models (LLMs), relatively little is known about how these models reconcile conflicting information from generated and retrieved contexts. This paper investigates the phenomenon of merging generated and retrieved contexts in LLMs when faced with conflicting knowledge. We propose a method to analyze how LLMs resolve discrepancies between generated and retrieved contexts, focusing on the specific case of conflicting knowledge. Our results show that LLMs tend to prioritize generated contexts over retrieved ones, leading to a phenomenon we term as being \"blinded by generated contexts\". This bias towards generated contexts can have implications for the veracity and reliability of information generated by LLMs. By understanding how LLMs merge conflicting information, we can work towards developing more robust language models that are capable of handling discrepancies in knowledge sources. Our findings shed light on the inner workings of LLMs and provide insights for improving their performance in handling conflicting information.",
        "Source": "GPT"
    },
    {
        "Index": 337,
        "Title": "Unveiling Linguistic Regions in Large Language Models.",
        "Abstract": "Large Language Models (LLMs) have proven to be highly effective in demonstrating cross-lingual alignment and generalization abilities. Current research in this area primarily focuses on exploring the extent to which LLMs capture linguistic diversity and regional variations in different languages. In this study, we unveil linguistic regions within LLMs by examining how these models encode and represent language features from various dialects and regions across different languages. Our analysis reveals that LLMs exhibit a remarkable capacity to capture and differentiate between linguistic regions, highlighting their potential for supporting various natural language processing tasks in multilingual settings. By shedding light on the internal structures and representations of LLMs in relation to linguistic diversity, this work contributes to a deeper understanding of the capabilities and limitations of these models in handling regional variations in languages. This insight can inform future advancements in developing LLMs that are more inclusive and robust in accommodating linguistic diversity.",
        "Source": "GPT"
    },
    {
        "Index": 338,
        "Title": "Text-to-Song: Towards Controllable Music Generation Incorporating Vocal and Accompaniment.",
        "Abstract": "A song is a combination of singing voice and accompaniment. However, existing works focus on either vocal or accompaniment generation separately, limiting the control and flexibility in creating customizable music. In this paper, we propose a Text-to-Song system that can generate music incorporating both vocal and accompaniment, allowing for more controllable music generation. Our system utilizes deep learning models to process textual input and generate corresponding vocal and accompaniment tracks simultaneously. By incorporating both elements of a song, our system provides users with the ability to adjust various musical aspects such as melody, harmony, and rhythm, resulting in a more personalized and flexible music generation process. Additionally, our system enables users to input emotional and stylistic cues to further customize the generated music. Overall, our Text-to-Song system offers a novel approach to music generation that combines vocal and accompaniment components, presenting a more comprehensive and controllable method for creating personalized music compositions.",
        "Source": "GPT"
    },
    {
        "Index": 339,
        "Title": "FastFiD: Improve Inference Efficiency of Open Domain Question Answering via Sentence Selection.",
        "Abstract": "Open Domain Question Answering (ODQA) has been advancing rapidly in recent times, driven by significant developments in natural language processing and machine learning. One key challenge in ODQA systems is the efficiency of inference, as the vast amount of information available in the open domain can lead to computational bottlenecks. In this paper, we propose FastFiD, a novel approach to improve the efficiency of ODQA systems through sentence selection. By selecting only the most relevant sentences from a given document, FastFiD reduces the amount of redundant information that needs to be processed, leading to faster inference and improved performance. We demonstrate the effectiveness of FastFiD on several benchmark datasets and show that it outperforms existing approaches in terms of both speed and accuracy. Our results suggest that integrating sentence selection mechanisms into ODQA systems can significantly enhance their overall performance, making them more scalable and practical for real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 340,
        "Title": "Discursive Socratic Questioning: Evaluating the Faithfulness of Language Models' Understanding of Discourse Relations.",
        "Abstract": "Large language models have greatly improved discourse relation classifications, but their understanding of these relationships still needs to be evaluated for faithfulness. This study explores the effectiveness of discursive Socratic questioning in assessing language models' comprehension of discourse relations. By analyzing the responses of language models to carefully crafted Socratic questions, the research aims to determine the extent to which these models can accurately interpret and apply discourse relations in context. The evaluation of the faithfulness of language models' understanding of discourse relations is crucial for ensuring the reliability and accuracy of their outputs in various natural language processing tasks. Ultimately, this study seeks to enhance our understanding of the capabilities and limitations of language models in capturing the nuances of discourse relations, leading to advancements in the development and refinement of these models for more accurate and efficient natural language processing applications.",
        "Source": "GPT"
    },
    {
        "Index": 341,
        "Title": "An Open Multilingual System for Scoring Readability of Wikipedia.",
        "Abstract": "With over 60M articles, Wikipedia has become the largest platform for open and freely accessible information in multiple languages. However, the readability of these articles can vary significantly, depending on the language and the complexity of the topic. In this study, we propose an open multilingual system for scoring the readability of Wikipedia articles. By utilizing machine learning algorithms and linguistic features, our system is able to provide a comprehensive analysis of the readability of Wikipedia articles in various languages. This system allows users to assess the complexity of articles and make informed decisions about which articles are most suitable for their needs. By providing a standardized readability score across different languages, our system aims to improve the accessibility and usability of Wikipedia for a global audience. This research contributes to the growing field of multilingual natural language processing and has the potential to enhance the overall quality of Wikipedia articles for readers worldwide.",
        "Source": "GPT"
    },
    {
        "Index": 342,
        "Title": "Unlearning Traces the Influential Training Data of Language Models.",
        "Abstract": "Identifying the training datasets that influence a language model’s outputs is essential for minimizing bias and ensuring accurate and ethical results. In this study, we present a methodology for tracing the influential training data of language models, focusing on the process of unlearning to analyze and mitigate potential biases. By systematically identifying and analyzing the key datasets that shape a language model's behavior, we can better understand the underlying factors that contribute to its outputs. This approach enables us to evaluate the impact of different training datasets on the model's performance and identify potential sources of bias or misinformation. Through this process of unlearning, we can take important steps towards improving the reliability and fairness of language models, ultimately leading to more accurate and trustworthy results in a variety of applications. Our findings highlight the importance of transparency and accountability in the development and deployment of language models, emphasizing the need for ongoing evaluation and validation to ensure responsible and ethical AI practices.",
        "Source": "GPT"
    },
    {
        "Index": 343,
        "Title": "Exploring Alignment in Shared Cross-lingual Spaces.",
        "Abstract": "Despite their remarkable ability to capture linguistic nuances across diverse languages, questions persist regarding the alignment of shared cross-lingual spaces. This study delves into the concept of alignment, specifically in the context of shared spaces where multiple languages coexist and interact. By exploring how different languages align within these spaces, we aim to shed light on the complexities of cross-lingual communication and understanding.\n\nThrough a combination of theoretical analysis and empirical research, we will investigate the various factors that contribute to alignment in shared cross-lingual spaces. This includes examining the role of language similarities and differences, cultural influences, and individual perceptions in shaping alignment processes. By unraveling these dynamics, we hope to provide insights that can inform the development of more effective cross-lingual communication strategies and tools.\n\nOverall, this study seeks to contribute to a deeper understanding of alignment in shared cross-lingual spaces, offering valuable implications for practitioners and researchers in the fields of linguistics, communication, and translation studies.",
        "Source": "GPT"
    },
    {
        "Index": 344,
        "Title": "Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models.",
        "Abstract": "This paper identifies a cultural dominance issue within large language models (LLMs) due to the lack of recognition and representation of Thanksgiving in countries outside of the United States. Thanksgiving is a widely celebrated holiday in the US, but not all countries have a similar tradition or cultural significance attached to it. LLMs, which are trained on vast amounts of text data from diverse sources, tend to prioritize and reinforce the cultural narratives of dominant English-speaking countries like the US. This skewed representation can lead to a perpetuation of cultural biases and a lack of inclusivity for non-US cultures and traditions. To address this issue, we propose that LLMs incorporate a more diverse range of cultural perspectives and holidays from around the world to create a more inclusive and culturally sensitive model. By highlighting this issue, we aim to bring awareness to the impact of cultural dominance in LLMs and encourage greater diversity and representation in language processing technologies.",
        "Source": "GPT"
    },
    {
        "Index": 345,
        "Title": "Self-Evolving GPT: A Lifelong Autonomous Experiential Learner.",
        "Abstract": "To improve the performance of large language models (LLMs), researchers have explored providing LLMs with continual learning capabilities. This paper proposes Self-Evolving GPT, a novel framework for creating a lifelong autonomous experiential learner. Self-Evolving GPT builds on the success of existing LLMs like GPT-3 but enhances their capabilities by enabling them to learn from new experiences over time. By incorporating mechanisms for self-evaluation, adaptation, and knowledge consolidation, Self-Evolving GPT can evolve and improve its performance continuously without the need for constant retraining on static datasets. This approach not only allows the model to adapt to new tasks and domains but also ensures that it retains knowledge learned from past experiences. Experimental results demonstrate the effectiveness of Self-Evolving GPT in achieving higher levels of task performance and adaptation to new data compared to traditional static models. Ultimately, this framework holds promise for developing more flexible and intelligent AI systems that can learn and evolve autonomously in real-world settings.",
        "Source": "GPT"
    },
    {
        "Index": 346,
        "Title": "WRP: Weight Recover Prune for Structured Sparsity.",
        "Abstract": "As the scale of Large Language Models (LLMs) increases, it is necessary to compress the model in order to reduce its computational and memory footprint. In this paper, we propose a novel Weight Recover Prune (WRP) approach for structured sparsity in LLMs. Our method combines weight recovery techniques with pruning strategies to achieve both compression and retention of important model parameters. By utilizing structured sparsity, we are able to achieve higher compression rates while still maintaining model performance. Experimental results demonstrate the effectiveness of our WRP approach in compressing LLMs with minimal loss in accuracy. Additionally, our method is flexible and can be adapted to different architectures and tasks. Overall, the WRP approach offers a promising solution for reducing the size of LLMs to improve efficiency and scalability in various applications.",
        "Source": "GPT"
    },
    {
        "Index": 347,
        "Title": "Error-preserving Automatic Speech Recognition of Young English Learners' Language.",
        "Abstract": "One of the central skills that language learners need to practice is speaking the language. However, young English learners often face challenges in accurately pronouncing words and phrases, which can impact their overall language acquisition progress. In this study, we present a novel approach for error-preserving automatic speech recognition (ASR) of young English learners' language. By focusing on preserving errors made by young learners, our ASR system aims to provide more accurate feedback and support for language development. We utilize a combination of machine learning algorithms and linguistic analysis techniques to capture and analyze the specific errors made by young learners, allowing us to create a tailored ASR model. Our experimental results demonstrate the effectiveness of our error-preserving ASR system in accurately transcribing and analyzing the speech of young English learners. This research has implications for improving language learning tools and educational programs for young learners, ultimately facilitating more effective language acquisition and development.",
        "Source": "GPT"
    },
    {
        "Index": 348,
        "Title": "DiFiNet: Boundary-Aware Semantic Differentiation and Filtration Network for Nested Named Entity Recognition.",
        "Abstract": "Nested Named Entity Recognition (Nested NER) entails identifying and classifying entity spans within the text that are hierarchically structured. Traditional NER models often struggle with identifying nested entities due to their complex and overlapping nature. In this paper, we propose a novel model called DiFiNet (Boundary-Aware Semantic Differentiation and Filtration Network) specifically designed for Nested NER tasks. \n\nDiFiNet utilizes boundary-aware semantic differentiation to accurately detect the boundaries of nested entities and differentiate them from overlapping entities. By incorporating a filtration network, DiFiNet is able to filter out irrelevant information and focus on the most important entity spans within the text. \n\nOur experimental results on benchmark datasets demonstrate that DiFiNet outperforms existing models in terms of precision, recall, and F1-score for Nested NER tasks. The proposed model shows promising results in effectively handling the complexities of nested entities and demonstrates the potential for advancing the field of Named Entity Recognition.",
        "Source": "GPT"
    },
    {
        "Index": 349,
        "Title": "Legal Case Retrieval: A Survey of the State of the Art.",
        "Abstract": "Recent years have seen increasing attention on Legal Case Retrieval (LCR), a key task in the field of legal information retrieval. The ability to efficiently and accurately retrieve relevant legal cases is crucial for legal practitioners, researchers, and policymakers. This paper presents a survey of the state of the art in LCR, highlighting key advancements and challenges in this area. We discuss the different approaches and techniques used in LCR, including keyword-based search, natural language processing, machine learning, and deep learning methods. We also examine the various datasets and evaluation measures commonly used in LCR research. Additionally, we analyze the impact of recent advancements in technology, such as the availability of large legal corpora and the development of specialized legal search engines, on the field of LCR. Finally, we discuss future research directions and potential applications of LCR technology in the legal domain. Overall, this survey provides a comprehensive overview of the current state of LCR and identifies opportunities for further advancements in this field.",
        "Source": "GPT"
    },
    {
        "Index": 350,
        "Title": "Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generation.",
        "Abstract": "Compositional generalization in the context of multi-aspect controllable text generation refers to the model's ability to create text with novel attribute combinations. This skill enables the model to generate diverse and customizable text outputs based on various input conditions. In this study, we explore strategies to benchmark and enhance the compositional generalization capabilities of a text generation model. By evaluating the model's performance on generating text with unseen attribute combinations, we aim to highlight its capacity to adapt and generalize across different input scenarios. Through a series of experiments and evaluations, we identify key factors that influence the model's compositional generalization abilities and propose techniques to improve its overall performance. Our findings provide valuable insights into the challenges and opportunities in advancing the compositional generalization capabilities of multi-aspect controllable text generation models. Ultimately, our research aims to push the boundaries of text generation technology by enhancing the model's flexibility and adaptability in generating text with diverse attribute combinations.",
        "Source": "GPT"
    },
    {
        "Index": 351,
        "Title": "LLaMA Pro: Progressive LLaMA with Block Expansion.",
        "Abstract": "Humans generally acquire new skills without compromising the old; however, the opposite holds for Large Language Models (LLaMAs). Current LLaMAs, such as GPT-3, are typically trained on a fixed dataset and do not learn new information without forgetting previously acquired knowledge. This lack of progressive learning hinders the ability of LLaMAs to adapt to new tasks and environments effectively. In this paper, we introduce LLaMA Pro, a novel framework for training progressive LLaMAs with block expansion. By dynamically expanding the model's capacity as it learns new data, LLaMA Pro enables continuous learning without catastrophic forgetting. We demonstrate the effectiveness of our approach on various tasks, showing that our progressive LLaMAs achieve superior performance compared to traditional fixed-capacity models. Our results suggest that LLaMA Pro has the potential to revolutionize the field of language modeling by enabling models to continually learn and adapt to new information while retaining previously learned knowledge.",
        "Source": "GPT"
    },
    {
        "Index": 352,
        "Title": "Generating Contrastive Narratives Using the Brownian Bridge Process for Narrative Coherence Learning.",
        "Abstract": "A major challenge for narrative reasoning is to learn narrative coherence. Existing works mainly follow conventional approaches, such as rule-based systems or deep learning models, which often struggle to capture complex narrative structures and generate diverse storylines. In this study, we propose a novel approach to generating contrastive narratives using the Brownian Bridge Process. This process allows for the creation of coherent narratives by simulating the movement of protagonists through various states of emotions and events. By incorporating the Brownian Bridge Process into narrative coherence learning, we aim to improve the quality and diversity of generated storylines. Our experiments demonstrate the effectiveness of our approach in generating contrastive narratives that exhibit enhanced coherence and richness. Overall, our work contributes to advancing the field of narrative reasoning by leveraging innovative techniques to enhance narrative coherence learning.",
        "Source": "GPT"
    },
    {
        "Index": 353,
        "Title": "A Causal Approach for Counterfactual Reasoning in Narratives.",
        "Abstract": "Counterfactual reasoning in narratives involves the ability to consider alternative scenarios that did not actually occur, but could have. This process requires predicting how different conditions or events might have unfolded if certain circumstances had been altered. In this study, we propose a causal approach for enhancing the accuracy and effectiveness of counterfactual reasoning in narratives. By integrating causal reasoning principles into the analysis of hypothetical scenarios, we aim to provide a more systematic and structured framework for understanding the potential outcomes of alternative storylines. Drawing on causal relationships between events and actions, our approach offers a method for generating plausible counterfactual explanations and predictions within narrative contexts. Through the application of this causal perspective, we seek to improve the interpretive and predictive capacities of individuals engaged in counterfactual reasoning, ultimately enhancing their ability to imagine and explore alternative narrative trajectories. This research contributes to a deeper understanding of the cognitive processes involved in counterfactual thinking and offers new insights into the construction of fictional worlds in literature and storytelling.",
        "Source": "GPT"
    },
    {
        "Index": 354,
        "Title": "SIP: Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation.",
        "Abstract": "Strong inductive biases enable learning from little data and help generalization outside the training distribution. This paper proposes a Structural Inductive Prior (SIP) framework for incorporating inductive biases into Seq2Seq models through simulation during training. By leveraging domain-specific knowledge and assumptions about the underlying data generation process, SIP guides the model towards learning a more robust and generalizable representation. We demonstrate the effectiveness of SIP on various tasks, including text generation and machine translation, showing improvements in both data efficiency and out-of-distribution generalization. Additionally, we explore the impact of different simulation strategies on model performance and provide insights into how structural inductive biases can be learned and utilized effectively. Our framework provides a more principled approach to incorporating prior knowledge into neural networks, offering a promising direction for improving the flexibility and generalization capabilities of Seq2Seq models.",
        "Source": "GPT"
    },
    {
        "Index": 355,
        "Title": "The Hidden Space of Transformer Language Adapters.",
        "Abstract": "In this study, we investigate the hidden space of transformer language adapters, a critical component in transformer-based models. These adapters, small modules trained on top of pre-trained transformer models, play a crucial role in fine-tuning the language model for specific downstream tasks. Through comprehensive analysis, we uncover the intricate operations of these adapters and explore their impact on model performance and generalization capabilities. By delving into the hidden space of transformer language adapters, we gain insights into their ability to adapt the pre-trained model to various tasks without losing the valuable knowledge captured during pre-training. Our findings shed light on the underlying mechanisms of adapter modules and their contributions to the versatility of transformer-based models. Ultimately, this research contributes to a deeper understanding of how transformer language adapters facilitate efficient transfer learning and enable the model to excel in a wide range of natural language processing tasks.",
        "Source": "GPT"
    },
    {
        "Index": 356,
        "Title": "A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts.",
        "Abstract": "In the realm of text manipulation and linguistic transformation, the question of authorship has been a topic of much debate. This study delves into the curious cases of paraphrasing found in texts generated by machine learning models, specifically focusing on the Ship of Theseus paradox. Through a detailed analysis of various LLM-generated texts, we explore how these models navigate the fine line between originality and plagiarism in the paraphrasing process. By examining the evolution of text as it undergoes multiple rounds of paraphrasing, we aim to shed light on the complexities of authorship in the digital age. Our findings suggest that LLMs play a crucial role in reshaping traditional notions of authorship, raising important ethical and legal considerations. Ultimately, this study highlights the need for a nuanced understanding of text generation technology and its implications for intellectual property rights and creative autonomy.",
        "Source": "GPT"
    },
    {
        "Index": 357,
        "Title": "Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations.",
        "Abstract": "In spoken dialogue, the ability of large language models to capture and respond to varied speaking styles is crucial for effective communication. This study focuses on advancing large language models to accurately interpret and respond to diverse speaking styles in real-time conversations. Even if two consecutive turns in a conversation consist of the same sentence, the responses generated by current language models may vary significantly in terms of tone, formality, and contextual relevance. By improving the capability of language models to understand and adapt to different speaking styles, we aim to enhance the overall quality and fluidity of spoken interactions. Our research explores techniques for fine-tuning language models to better capture nuances in tone, intonation, and emphasis, enabling more accurate and contextually appropriate responses. Through this work, we seek to refine the capabilities of large language models in handling the complexities of varied speaking styles, ultimately facilitating more natural and engaging spoken conversations.",
        "Source": "GPT"
    },
    {
        "Index": 358,
        "Title": "RetinaQA: A Robust Knowledge Base Question Answering Model for both Answerable and Unanswerable Questions.",
        "Abstract": "An essential requirement for a real-world Knowledge Base Question Answering (KBQA) system is the ability to accurately respond to both answerable and unanswerable questions. In this study, we propose RetinaQA, a robust KBQA model specifically designed to handle a wide range of question types. By incorporating a novel attention mechanism and semantic parsing techniques, RetinaQA is able to effectively retrieve information from knowledge bases and provide accurate answers to answerable questions. Additionally, our model is equipped with a confidence scoring system that can intelligently identify unanswerable questions and gracefully handle them without returning incorrect or misleading responses. Experimental results on benchmark datasets demonstrate that RetinaQA significantly outperforms existing KBQA models in terms of both answer accuracy and robustness to unanswerable questions. Our study contributes to the advancement of KBQA systems by presenting a reliable and versatile model that can effectively handle various question scenarios, ultimately enhancing the user experience and utility of knowledge base systems.",
        "Source": "GPT"
    },
    {
        "Index": 359,
        "Title": "GroundingGPT: Language Enhanced Multi-modal Grounding Model.",
        "Abstract": "Multi-modal large language models (MLLMs) have shown impressive capabilities in a wide range of tasks by integrating text with other modalities such as images and videos. Despite their successes, MLLMs still face challenges in effectively grounding these modalities, particularly in tasks that require contextual understanding between different modalities. In this paper, we propose GroundingGPT, a novel language enhanced multi-modal grounding model that addresses this issue by enhancing the grounding capabilities of MLLMs through the incorporation of contextual information.\n\nGroundingGPT leverages pre-trained language models, such as GPT, to improve multi-modal grounding by enabling better alignment between text and visual information. By fine-tuning the language model on multi-modal datasets, GroundingGPT is able to effectively ground textual descriptions to corresponding visual elements, enhancing the model's performance in tasks such as image captioning, visual question answering, and image-text matching.\n\nOur experimental results demonstrate that GroundingGPT outperforms existing MLLMs on various multi-modal tasks, highlighting the effectiveness of language enhanced grounding in improving the performance of multi-modal models.",
        "Source": "GPT"
    },
    {
        "Index": 360,
        "Title": "Automated Justification Production for Claim Veracity in Fact Checking: A Survey on Architectures and Approaches.",
        "Abstract": "Automated Fact-Checking (AFC) is the automated verification of claim accuracy, a crucial tool in discerning the veracity of information in today's digital age. The process involves analyzing claims made in various forms of media, such as social media posts, news articles, and websites, to determine their truthfulness. One important component of AFC is Automated Justification Production, which focuses on generating explanations for why a claim is true or false.\n\nThis survey paper explores the various architectures and approaches used in AFC to automate the justification production process. Different types of architectures, including rule-based and machine learning-based approaches, are discussed, along with their strengths and limitations. The survey also highlights key challenges and future research directions in the field of AFC.\n\nOverall, this paper provides a comprehensive overview of Automated Justification Production for Claim Veracity in Fact-Checking, offering insights into how automated systems can assist in distinguishing between true and false claims in a fast-paced online information environment.",
        "Source": "GPT"
    },
    {
        "Index": 361,
        "Title": "Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen Languages.",
        "Abstract": "Multilingual neural machine translation systems learn to map sentences of different languages into a common vector space, allowing for the transfer of knowledge across languages. However, these systems often struggle with translating languages that were not explicitly included during training. In this study, we propose a novel approach that leverages decoupled vocabulary learning to enable zero-shot translation from unseen languages. By decoupling the vocabulary from the neural network architecture, our model can effectively learn shared representations across languages without needing specific data for each language pair. This approach not only improves the translation accuracy for languages not seen during training but also reduces the computational complexity of the system. We demonstrate the effectiveness of our method by evaluating it on a diverse set of languages and showcasing significant improvements in zero-shot translation performance. Our findings highlight the potential of decoupled vocabulary learning in enhancing the adaptability and generalization capabilities of multilingual neural machine translation systems.",
        "Source": "GPT"
    },
    {
        "Index": 362,
        "Title": "SwapMoE: Serving Off-the-shelf MoE-based Large Language Models with Tunable Memory Budget.",
        "Abstract": "Mixture of experts (MoE) is a popular technique to improve the capacity of Large Language Models by allowing them to leverage diverse expertise from multiple sub-models. However, deploying MoE-based models in real-world applications can be challenging due to high memory requirements. In this paper, we present SwapMoE, a novel approach for serving off-the-shelf MoE-based Large Language Models with a tunable memory budget. Our method dynamically swaps in and out sub-models based on their relevance to the input data, allowing for efficient use of memory resources without compromising model performance. We demonstrate the effectiveness of SwapMoE through extensive experiments on various language understanding tasks, showing that it can achieve comparable performance to full MoE-based models while significantly reducing memory usage. SwapMoE provides a practical solution for deploying MoE-based models in resource-constrained environments, making it easier for researchers and practitioners to leverage the benefits of this powerful technique in real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 363,
        "Title": "PixT3: Pixel-based Table-To-Text Generation.",
        "Abstract": "Table-to-text generation involves generating appropriate textual descriptions given structured tabular data. It has attracted increasing attention due to its practical applications in various domains such as data analysis, natural language processing, and information retrieval. In this paper, we propose PixT3, a novel model for pixel-based table-to-text generation. Our approach leverages the pixel-level information in tabular data to generate more precise and contextually relevant textual descriptions. By incorporating pixel values into the text generation process, PixT3 achieves higher accuracy and fluency in generating natural language outputs. We conduct extensive experiments on benchmark datasets to evaluate the performance of PixT3 against state-of-the-art models in the field. The results demonstrate that PixT3 outperforms existing methods in terms of both quantitative metrics and human evaluations. Overall, our work presents a significant advancement in the field of table-to-text generation by introducing a pixel-based approach that enhances the quality and accuracy of generated textual descriptions.",
        "Source": "GPT"
    },
    {
        "Index": 364,
        "Title": "Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers.",
        "Abstract": "Factual questions typically can be answered correctly at different levels of granularity, leading to a knowledge evaluation gap in open-domain question answering systems. In order to address this gap, this paper proposes a novel approach that generates multi-granularity answers. By providing answers at varying levels of detail, our method aims to improve the overall accuracy and reliability of open-domain question answering systems. Through experiments conducted on a variety of datasets, we demonstrate the effectiveness of our approach in narrowing the knowledge evaluation gap. Furthermore, we introduce a new dataset specifically designed to evaluate the performance of open-domain question answering systems with multi-granularity answers. Our results show promising improvements in accurately answering factual questions across different levels of granularity. Overall, our research contributes to advancing the field of open-domain question answering and provides valuable insights for future research in this area.",
        "Source": "GPT"
    },
    {
        "Index": 365,
        "Title": "TAMS: Translation-Assisted Morphological Segmentation.",
        "Abstract": "Canonical morphological segmentation is the process of analyzing words into their standard forms, which can aid in various natural language processing tasks such as machine translation, information retrieval, and speech recognition. However, this process can be challenging for languages with complex morphological structures, leading to errors in segmentation and subsequent analysis. In this paper, we propose TAMS: Translation-Assisted Morphological Segmentation, a novel approach that leverages translation information to improve the accuracy of morphological segmentation. By incorporating translation data into the segmentation process, TAMS can better handle the morphological complexities of languages and improve the overall performance of natural language processing tasks. We evaluate TAMS on a variety of languages and tasks, demonstrating its effectiveness in improving segmentation accuracy and task performance compared to traditional morphological segmentation methods. Our results show that TAMS can be a valuable tool for researchers and developers working with languages that have complex morphological structures, providing better insights into the underlying forms of words and improving the overall efficiency and accuracy of natural language processing systems.",
        "Source": "GPT"
    },
    {
        "Index": 366,
        "Title": "XCodeEval: An Execution-based Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval.",
        "Abstract": "Recently, pre-trained large language models (LLMs) have demonstrated remarkable advancements in generating code from natural language texts. In order to further evaluate the capabilities of these models and promote research in the field of code understanding, generation, translation, and retrieval, we present XCodeEval: An Execution-based Large Scale Multilingual Multitask Benchmark. This benchmark encompasses a diverse set of tasks including code understanding, generation, translation, and retrieval, all of which are crucial in advancing the state-of-the-art in programming language processing. XCodeEval offers a comprehensive evaluation platform on a large scale and across multiple languages, facilitating in-depth analysis of LLMs' performance on various code-related tasks. By leveraging XCodeEval, researchers can assess the effectiveness of LLMs in handling different aspects of code processing, leading to further advancements in natural language-based programming tools and techniques.",
        "Source": "GPT"
    },
    {
        "Index": 367,
        "Title": "ProxyQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models.",
        "Abstract": "Large Language Models (LLMs) have shown significant success in understanding and generating long-form text. While LLMs have demonstrated proficiency in various natural language processing tasks, including text completion and dialogue generation, there remains a need for a comprehensive evaluation framework that can assess the quality and accuracy of their outputs. In this paper, we introduce ProxyQA, an alternative framework for evaluating long-form text generation with LLMs. ProxyQA leverages a combination of human evaluation and automated metrics to assess the fluency, coherence, and relevance of the generated text. By focusing on multiple aspects of text generation, ProxyQA provides a more holistic and nuanced evaluation of LLMs' performance. Through extensive experiments and case studies, we demonstrate the effectiveness of ProxyQA in evaluating and improving the quality of text generated by LLMs. This framework offers a valuable tool for researchers and developers seeking to optimize the performance of LLMs in long-form text generation tasks.",
        "Source": "GPT"
    },
    {
        "Index": 368,
        "Title": "A Glitch in the Matrix? Locating and Detecting Language Model Grounding with Fakepedia.",
        "Abstract": "Large language models (LLMs) have an impressive ability to draw on novel information supplied in text, but there is a growing concern about their ability to understand and ground the information they generate. In this study, we explore the phenomenon of a potential \"glitch in the matrix\" of language models by proposing a method to locate and detect language model grounding using a dataset called Fakepedia. Fakepedia consists of articles generated by a state-of-the-art LLM that intentionally includes incorrect or misleading information. By analyzing the generated text and comparing it to human-written content, we are able to identify instances where the language model fails to effectively ground its output in reality. This research sheds light on the limitations of current language models in comprehending and producing accurate information, and highlights the need for improved grounding mechanisms in natural language processing systems. By identifying and addressing these glitches, we can work towards creating more reliable and trustworthy language models for various applications.",
        "Source": "GPT"
    },
    {
        "Index": 369,
        "Title": "Muffin or Chihuahua? Challenging Multimodal Large Language Models with Multipanel VQA.",
        "Abstract": "Multipanel images are increasingly prevalent in our daily digital interactions, appearing in various forms such as web screenshots and posters. In this study, we present a novel approach to challenging multimodal large language models using multipanel images through a Multipanel Visual Question Answering (VQA) task. Specifically, we leverage the complexity and diversity of multipanel images to create a dataset that requires models to accurately parse and reason about the content across multiple panels.\n\nOur experimental results demonstrate the effectiveness of our approach in pushing the boundaries of current multimodal models, with specific focus on their abilities to understand context and context transitions within multipanel images. By introducing this new task, we aim to enhance the capabilities of large language models in handling complex visual scenarios, extending their applications to real-world tasks that require multi-panel comprehension. This research opens up new possibilities for the development of more sophisticated and versatile multimodal models in the future.",
        "Source": "GPT"
    },
    {
        "Index": 370,
        "Title": "WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models.",
        "Abstract": "The rapid advancement of large language models (LLMs) has led to a new era marked by the development of sophisticated web agents capable of processing and understanding vast amounts of multimodal data. In this paper, we present WebVoyager, an end-to-end web agent designed to utilize large multimodal models for enhanced performance in tasks such as web search, content recommendation, and user interaction. By leveraging cutting-edge LLMs, such as GPT-3, WebVoyager is able to comprehend and generate text, images, and videos, providing a seamless and intuitive browsing experience for users. We discuss the architecture of WebVoyager, including its integration of different modalities and its ability to adapt and learn from user interactions. Through a series of experiments, we demonstrate the efficacy of WebVoyager in handling complex web tasks and outperforming traditional search engines. Overall, our work showcases the potential of large multimodal models in revolutionizing the capabilities of web agents and shaping the future of web browsing.",
        "Source": "GPT"
    },
    {
        "Index": 371,
        "Title": "Translation-based Lexicalization Generation and Lexical Gap Detection: Application to Kinship Terms.",
        "Abstract": "Constructing lexicons with explicitly identified lexical gaps is a vital part of building multilingual lexical resources. In this study, we propose a novel approach for the generation of kinship terms in different languages using translation-based lexicalization and gap detection techniques. Our method leverages parallel text data to identify common patterns in kinship term mappings across languages, allowing for the automatic generation of missing terms. By utilizing the translations of existing kinship terms as a basis, our approach can accurately predict and generate equivalent terms in target languages where lexical gaps exist. We demonstrate the effectiveness of our method by evaluating the quality of generated terms against human-established gold standards. Our results show that our approach significantly reduces the number of missing kinship terms in multilingual lexicons, improving overall coverage and accuracy. This research contributes to the advancement of cross-lingual lexical resources and provides a practical solution for addressing lexical gaps in the domain of kinship terminology.",
        "Source": "GPT"
    },
    {
        "Index": 372,
        "Title": "Leveraging Machine-Generated Rationales to Facilitate Social Meaning Detection in Conversations.",
        "Abstract": "We present a generalizable classification approach that leverages Large Language Models (LLMs) to facilitate the detection of social meanings in conversations. Our method utilizes machine-generated rationales to enhance the understanding of complex social interactions and identify underlying intentions and emotions in dialogues. By incorporating LLMs, we can effectively analyze the context and nuances of language to classify social meanings with high accuracy.\n\nWe demonstrate the effectiveness of our approach through extensive evaluations on various conversational datasets, showcasing its ability to identify subtle social cues and accurately classify different types of social meanings. Our method significantly outperforms existing classification techniques by harnessing the power of LLMs and utilizing machine-generated rationales to interpret and detect social intentions in conversations. This approach can have wide-ranging applications in sentiment analysis, opinion mining, and social media monitoring, enabling more nuanced and insightful analyses of social interactions.",
        "Source": "GPT"
    },
    {
        "Index": 373,
        "Title": "Robust Frame-Semantic Models with Lexical Unit Trees and Negative Samples.",
        "Abstract": "We present novel advancements in frame-semantic parsing, specifically focusing on target identification and frame identification. Our proposed model integrates lexical unit trees and negative samples to enhance the robustness and efficiency of frame-semantic parsing. By incorporating lexical unit trees, we are able to capture the hierarchical structure of lexico-semantic information, aiding in target identification within a frame. Additionally, the introduction of negative samples allows our model to effectively distinguish between relevant and irrelevant information, improving frame identification accuracy. Through extensive experiments on benchmark datasets, we demonstrate the effectiveness of our approach in achieving state-of-the-art performance in frame-semantic parsing tasks. Our model not only outperforms existing methods in target identification and frame identification tasks but also showcases the potential of leveraging lexical unit trees and negative samples for enhancing the overall performance of frame-semantic models. Our work contributes to the advancement of frame-semantic parsing techniques and presents a promising direction for future research in this field.",
        "Source": "GPT"
    },
    {
        "Index": 374,
        "Title": "Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation.",
        "Abstract": "Advancements in logical reasoning have been greatly enhanced by the harnessing of Large Language Models (LLMs) for the translation of natural language into first-order logic. By utilizing the powerful capabilities of LLMs, researchers and practitioners are now able to efficiently convert complex natural language expressions into symbolic logical representations. This breakthrough in technology promises to revolutionize the field of logical reasoning by enabling more accurate and efficient translations of natural language text into formal logic.\n\nThis paper explores the current state-of-the-art techniques for utilizing LLMs for natural language to first-order logic translation. We discuss the challenges and opportunities inherent in this task, as well as the potential applications and implications for various fields, including artificial intelligence, natural language processing, and automated reasoning. Through a comprehensive review of existing literature and experimental results, we demonstrate the effectiveness and reliability of LLMs in facilitating the efficient conversion of natural language to logical symbolism, paving the way for enhanced logical reasoning capabilities.",
        "Source": "GPT"
    },
    {
        "Index": 375,
        "Title": "Lightweight reranking for language model generations.",
        "Abstract": "Large Language Models (LLMs) can exhibit considerable variation in the quality of their sampled outputs, leading to the generation of nonsensical or low-quality text. To address this issue, lightweight reranking techniques have been proposed to improve the overall coherence and fluency of LLM-generated text. These techniques aim to augment the re-ranking process with minimal additional complexity, making them computationally efficient and scalable for real-world applications. In this paper, we review and analyze existing lightweight reranking methods for LLM generations, focusing on their effectiveness in enhancing the quality of text outputs. We also discuss the trade-offs between the computational cost and the improvement in text quality achieved by these reranking techniques. Through our analysis, we aim to provide insights into the potential of lightweight reranking approaches to enhance the performance of LLMs in generating coherent and fluent text, paving the way for more efficient and effective natural language processing applications.",
        "Source": "GPT"
    },
    {
        "Index": 376,
        "Title": "ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews.",
        "Abstract": "We introduce the task of automatically revising scientific papers based on peer feedback and release ARIES, a Corpus of Scientific Paper Edits Made in Response to Peer Reviews. The corpus contains a diverse collection of edits made by authors in response to feedback from peer reviewers, providing valuable insights into the revision process in academic publishing. Our goal is to facilitate research in natural language processing and machine learning for automatic paper revision by providing a large, high-quality dataset for training and evaluation. ARIES includes a wide range of editing operations, such as adding new content, rephrasing sentences, correcting grammar and punctuation errors, and addressing reviewer comments. We believe that ARIES will serve as a valuable resource for developing automated tools that assist authors in improving the quality and clarity of their research papers.",
        "Source": "GPT"
    },
    {
        "Index": 377,
        "Title": "The Unreasonable Effectiveness of Easy Training Data for Hard Tasks.",
        "Abstract": " Training models on easy training data can surprisingly lead to good performance on hard test data. This phenomenon, known as the unreasonable effectiveness of easy training data for hard tasks, challenges the traditional assumption that models must be trained on difficult data in order to perform well on challenging tasks. This paper explores the reasons behind this counterintuitive observation and investigates how we can leverage easy training data to improve performance on hard tasks.\n\nWe propose a novel approach that combines easy and hard training data in a strategic manner to achieve superior performance on difficult test data. Our experiments demonstrate that by incorporating easy training data, models can learn generalizable patterns that are beneficial for tackling hard tasks. Additionally, we provide theoretical insights into why this approach is effective and discuss practical implications for training models on challenging tasks. Overall, our research highlights the potential of using easy training data to enhance the performance of models on hard tasks, presenting a promising avenue for future research in machine learning.",
        "Source": "GPT"
    },
    {
        "Index": 378,
        "Title": "PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning.",
        "Abstract": "Instruction tuning has remarkably advanced large language models (LLMs) in understanding and responding to diverse languages. However, the process of instruction tuning can be challenging when dealing with multiple languages due to variations in syntax, grammar, and semantics. In this paper, we propose PLUG, a novel approach that leverages Pivot Language to facilitate cross-lingual instruction tuning for LLMs. By utilizing a bridging language to transfer knowledge from one language to another, PLUG allows for more efficient and effective tuning across different languages. We demonstrate the effectiveness of PLUG through experiments on various language pairs, showing significant improvements in performance compared to traditional methods. Our approach not only enhances the capabilities of LLMs in understanding and generating text in multiple languages but also contributes to the overall advancement of cross-lingual natural language processing tasks.",
        "Source": "GPT"
    },
    {
        "Index": 379,
        "Title": "MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning.",
        "Abstract": "We study the task of conducting structured reasoning as generating a reasoning graph from natural language input. Our approach, MIDGARD (Minimum Description Length for Structured Commonsense Reasoning), focuses on achieving self-consistency in the generated reasoning graph by minimizing the description length of the graph. This involves identifying and resolving inconsistencies or contradictions within the graph to ensure logical coherence in the reasoning process. By incorporating principles of minimum description length and commonsense reasoning, MIDGARD aims to enhance the quality and reliability of structured reasoning systems, particularly in the realm of natural language understanding and inference. Experimental results demonstrate the effectiveness of our approach in improving self-consistency and coherence in reasoning graphs generated from complex natural language inputs. MIDGARD represents a significant advancement in the field of structured commonsense reasoning, offering a novel framework for conducting logical and coherent reasoning in natural language contexts.",
        "Source": "GPT"
    },
    {
        "Index": 380,
        "Title": "ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs.",
        "Abstract": "Large Language Models (LLMs) still struggle with natural language reasoning tasks, hindering their ability to achieve higher levels of performance in various language processing applications. In response to this challenge, this study introduces a novel approach called ReConcile, which employs a round-table conference methodology to facilitate consensus-building among diverse LLMs. By encouraging LLMs to engage in collaborative reasoning and knowledge synthesis, ReConcile aims to enhance their ability to understand and answer complex natural language questions more effectively. Through the integration of multiple perspectives and diverse strategies, ReConcile creates a synergistic environment that promotes reasoning abilities and improves overall performance. Experimental results demonstrate that the ReConcile approach significantly boosts the reasoning capabilities of LLMs, leading to more accurate and nuanced responses to natural language queries. This innovative methodology showcases the potential for consensus-driven techniques to enhance the reasoning capabilities of LLMs and advance the field of natural language processing.",
        "Source": "GPT"
    },
    {
        "Index": 381,
        "Title": "Mirror: Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning.",
        "Abstract": "While Large language models (LLMs) have the capability to iteratively reflect on their own outputs, there is a need for a more structured and efficient self-reflection method to enhance knowledge-rich reasoning. In this paper, we introduce a novel approach called Mirror, which enables multiple perspectives for self-reflection in LLMs. Mirror combines the strengths of diverse reasoning and knowledge sources, allowing LLMs to incorporate varied viewpoints and enhance their understanding of complex concepts. By incorporating multiple perspectives, Mirror facilitates a more comprehensive and nuanced analysis of the model's outputs, improving the quality of reasoning and decision-making. We demonstrate the effectiveness of Mirror through experimental evaluations on a range of tasks, showcasing its ability to enhance knowledge-rich reasoning in LLMs. Our results indicate that Mirror outperforms existing self-reflection methods in terms of accuracy, robustness, and efficiency. Overall, Mirror provides a valuable framework for enhancing the capabilities of LLMs in knowledge-rich reasoning tasks.",
        "Source": "GPT"
    },
    {
        "Index": 382,
        "Title": "Where Do People Tell Stories Online? Story Detection Across Online Communities.",
        "Abstract": "Story detection in online communities is a challenging task as stories are scattered across various platforms and communities. This paper explores the detection of stories in online communities and investigates where people typically share stories online. By analyzing a large dataset of online posts from different communities, we identify common patterns and trends in storytelling behavior. Our findings reveal that stories are prevalent in a wide range of online platforms, including social media sites, forums, and blogging platforms. Furthermore, we discover that the types of stories shared vary across different communities, with some platforms being more conducive to personal narratives while others are better suited for fictional storytelling. Understanding where people tell stories online can help researchers and practitioners better detect and analyze stories in online communities, leading to advancements in natural language processing, social network analysis, and storytelling research.",
        "Source": "GPT"
    },
    {
        "Index": 383,
        "Title": "Large Language Models Are No Longer Shallow Parsers.",
        "Abstract": "The development of large language models (LLMs) brings significant changes to the field of natural language processing. Traditionally, shallow parsers were commonly used in NLP tasks to identify basic syntactic elements in a sentence. However, with the rise of LLMs such as GPT-3 and BERT, these models have demonstrated the capability to perform more complex language understanding tasks. LLMs are able to capture deeper semantic meaning in text, allowing for more nuanced analyses and improved performance on a wide range of NLP applications.\n\nAs a result, LLMs have shown great promise in various industries such as healthcare, finance, and customer service, where accurately understanding human language is crucial. The enhanced ability of LLMs to comprehend context, detect sentiment, and generate human-like responses has revolutionized the way we interact with machines and process vast amounts of text data. Moving forward, the incorporation of LLMs into NLP pipelines will continue to drive advancements in the field, paving the way for more sophisticated language understanding technologies.",
        "Source": "GPT"
    },
    {
        "Index": 384,
        "Title": "Dialogue Summarization with Mixture of Experts based on Large Language Models.",
        "Abstract": "Dialogue summarization is an important task that requires generating highlights for a conversation. This paper presents a novel approach, leveraging Large Language Models (LLMs) and a Mixture of Experts (MoE) framework for dialogue summarization. The proposed method combines the generalization capabilities of LLMs with the specialization of expert models to improve the summarization performance. By utilizing multiple experts with diverse expertise, our model can capture different aspects of the dialogue and generate more informative summaries. Experimental results show that our approach outperforms existing methods, achieving state-of-the-art results on benchmark datasets. Additionally, we demonstrate the effectiveness of incorporating both LLMs and expert models in dialogue summarization tasks. Our research contributes to the advancement of dialogue summarization techniques and establishes a strong foundation for future work in this area.",
        "Source": "GPT"
    },
    {
        "Index": 385,
        "Title": "ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences.",
        "Abstract": "Recently, the increasing demand for superior medical services has highlighted the discrepancies in the medical field, specifically in the context of Chinese medicine. In response to this need, we introduce ChiMed-GPT, a Chinese Medical Large Language Model equipped with a comprehensive training regime to better align with human preferences. Our model is trained on a large dataset of Chinese medical texts and incorporates the latest advancements in natural language processing to enhance its understanding of medical concepts and terminology. By focusing on the unique characteristics of Chinese medicine, ChiMed-GPT aims to bridge the gap between traditional Chinese medicine and modern healthcare practices.\n\nThrough extensive training, ChiMed-GPT has demonstrated improved performance in generating accurate and relevant medical information, making it a valuable tool for medical professionals and researchers in the field. With its enhanced capabilities and alignment with human preferences, ChiMed-GPT has the potential to revolutionize the way Chinese medicine is practiced and studied in the future.",
        "Source": "GPT"
    },
    {
        "Index": 386,
        "Title": "An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs.",
        "Abstract": "Large language models (LLMs) have demonstrated impressive arithmetic reasoning capabilities when presented with Chain-of-Thought (CoT) prompts. However, the underlying mechanisms driving this phenomenon have remained largely unexplored. In this study, we propose a novel approach by investigating the activation patterns of neurons within LLMs as a unified lens to explain the intricate process of CoT eliciting arithmetic reasoning.\n\nThrough a series of experiments and analyses, we aim to discern how the neural networks of LLMs are activated in response to CoT prompts, and how this activation correlates with successful arithmetic reasoning outputs. By mapping out the neural pathways involved in this cognitive process, we strive to uncover the cognitive mechanisms that enable LLMs to perform complex arithmetic reasoning tasks.\n\nUltimately, our findings have the potential to shed light on the inner workings of LLMs when engaged in arithmetic reasoning via CoT prompts, providing valuable insights for advancing the capabilities of LLMs in mathematical reasoning tasks.",
        "Source": "GPT"
    },
    {
        "Index": 387,
        "Title": "Leveraging Large Language Models for Learning Complex Legal Concepts through Storytelling.",
        "Abstract": "Making legal knowledge accessible to non-experts is crucial for enhancing general legal literacy and encouraging informed decision-making. Leveraging large language models, such as GPT-3, for learning complex legal concepts through storytelling presents a promising approach to bridge the gap between legal experts and lay persons. By transforming complex legal principles into engaging and digestible narratives, these models have the potential to make legal education more engaging, accessible, and effective for a wider audience. Through storytelling, individuals can grasp intricate legal concepts in a more relatable and memorable way, ultimately leading to a deeper understanding of the law and its implications. This innovative use of large language models has the power to democratize legal education, empower individuals to navigate legal issues with confidence, and enhance their overall legal literacy. Ultimately, by making legal knowledge more approachable and understandable, we can create a more informed and empowered society.",
        "Source": "GPT"
    },
    {
        "Index": 388,
        "Title": "Intrinsic Task-based Evaluation for Referring Expression Generation.",
        "Abstract": "Recently, a human evaluation study of Referring Expression Generation (REG) models had an unexpected conclusion: current state-of-the-art models performing well on standard metrics like BLEU scores and METEOR were not necessarily generating the most linguistically natural expressions as judged by human evaluators. This discrepancy highlights the need for intrinsic task-based evaluation methods to better assess the quality of REG models. In this paper, we propose an intrinsic task-based evaluation approach that focuses on the linguistic properties of generated referring expressions, such as coherence, specificity, and naturalness. By conducting controlled experiments with human annotators, we show that our proposed evaluation method provides a more accurate and meaningful assessment of REG model performance compared to traditional metrics. Our results suggest that incorporating intrinsic task-based evaluation into the development and assessment of REG models can help bridge the gap between automatic metrics and human judgment, ultimately improving the overall quality of referring expression generation systems.",
        "Source": "GPT"
    },
    {
        "Index": 389,
        "Title": "From Moments to Milestones: Incremental Timeline Summarization Leveraging Large Language Models.",
        "Abstract": "Timeline summarization (TLS) is essential for distilling coherent narratives from a vast collection of texts. In this paper, we introduce a novel approach for TLS, leveraging the power of large language models. Our model, called Incremental Timeline Summarization (ITS), takes advantage of fine-tuned language models to extract meaningful moments and milestones from a given text corpus. By incrementally updating the summary as new information is added, ITS is able to generate comprehensive and coherent summaries that capture the essence of the timeline. We evaluate our approach on various datasets and demonstrate its efficacy in producing concise and informative summaries. Our experiments show that ITS outperforms existing methods in terms of summarization quality and coherence. By leveraging the capabilities of large language models, ITS represents a significant advancement in TLS, offering a more efficient and effective way of summarizing timelines.",
        "Source": "GPT"
    },
    {
        "Index": 390,
        "Title": "End-to-end Learning of Logical Rules for Enhancing Document-level Relation Extraction.",
        "Abstract": "Document-level relation extraction (DocRE) is a task that involves extracting relationships between entities mentioned in a given document. Traditionally, this task has been challenging due to the need for integrating information from various parts of the document to understand the context and infer relationships accurately. In this study, we propose an end-to-end learning approach for enhancing DocRE by learning logical rules that capture complex patterns and dependencies in the text. Our method leverages a neural network model that combines both the ability to capture semantic information and the flexibility to learn and generalize logical rules from the training data. We evaluate our approach on benchmark datasets and demonstrate its effectiveness in improving relation extraction performance compared to existing methods. Overall, our results suggest that incorporating logical rules into the learning process can significantly enhance the performance of document-level relation extraction systems.",
        "Source": "GPT"
    },
    {
        "Index": 391,
        "Title": "Can We Achieve High-quality Direct Speech-to-Speech Translation without Parallel Speech Data?",
        "Abstract": "Recent advancements in direct speech-to-speech translation (S2ST) models have shown promising results by utilizing a two-pass approach, which breaks down the task into speech-to-text translation (S2TT) and text-to-speech synthesis. This novel approach has streamlined the translation process and improved the overall quality of the translation output. However, one of the major challenges faced by S2ST models is the scarcity of parallel speech data, which significantly hinders their performance. In this study, we explore the feasibility of achieving high-quality direct speech-to-speech translation without relying on parallel speech data. By leveraging the latest advancements in machine learning and natural language processing, we propose innovative techniques to enhance the performance of S2ST models in the absence of abundant parallel data. Our experimental results demonstrate the potential for achieving robust and accurate speech-to-speech translation without the need for parallel speech data, thus paving the way for more accessible and efficient translation solutions in the future.",
        "Source": "GPT"
    },
    {
        "Index": 392,
        "Title": "Enhancing EEG-to-Text Decoding through Transferable Representations from Pre-trained Contrastive EEG-Text Masked Autoencoder.",
        "Abstract": "EEG-based language decoding has gained significant attention in the field of brain-computer interface (BCI) technology as a potential avenue for facilitating communication for individuals with severe motor impairments. In this study, we propose a novel approach for enhancing EEG-to-text decoding through transferable representations derived from a pre-trained contrastive EEG-Text Masked Autoencoder. This approach leverages the rich information present in both EEG signals and text data to improve the accuracy and efficiency of converting EEG signals into natural language text. By pre-training the contrastive autoencoder on both EEG and text data, we are able to learn latent representations that capture the inherent relationships between the two modalities, leading to more effective decoding performance. Our experimental results demonstrate the efficacy of our proposed approach, showcasing improved text reconstruction accuracy compared to traditional methods. This enhancement in EEG-to-text decoding has the potential to greatly benefit individuals who rely on BCI technology for communication and information retrieval.",
        "Source": "GPT"
    },
    {
        "Index": 393,
        "Title": "CQIL: Inference Latency Optimization with Concurrent Computation of Quasi-Independent Layers.",
        "Abstract": "The fast-growing large scale language models are revolutionizing the field of natural language processing by achieving unprecedented performance in various tasks such as text generation, translation, and question answering. However, one common limitation of these models is the significant inference latency, which hinders their practical deployment in real-time applications. In this paper, we propose a novel approach called Concurrent Computation of Quasi-Independent Layers (CQIL) to optimize inference latency in large scale language models. By identifying and isolating quasi-independent layers within the model architecture, we enable concurrent computation of these layers, thereby reducing the overall inference time without compromising the model's performance. Our experimental results demonstrate that CQIL effectively minimizes inference latency while maintaining high accuracy across a range of natural language tasks. Overall, our work presents a promising solution to enhance the efficiency of large scale language models and facilitate their widespread application in real-world scenarios.",
        "Source": "GPT"
    },
    {
        "Index": 394,
        "Title": "Prompt Optimization via Adversarial In-Context Learning.",
        "Abstract": "In this study, we introduce a novel approach, Adversarial In-Context Learning (adv-ICL), aimed at enhancing the optimization of prompts for in-context learning. Traditional prompt optimization methods often struggle to generate effective prompts that capture the relevant information in the context, leading to suboptimal performance in various natural language processing tasks. Our proposed adv-ICL method leverages adversarial training to encourage prompts to better align with the context, thus improving the model's ability to understand and generate relevant responses.\n\nBy incorporating an adversarial component into the prompt optimization process, our approach not only aids in better capturing contextual information but also helps mitigate issues such as prompt degeneration and language model biases. Through extensive experimentation on multiple benchmark datasets, we demonstrate that adv-ICL consistently outperforms existing prompt optimization techniques in various in-context learning tasks. Overall, our study showcases the effectiveness of adv-ICL in enhancing prompt optimization for improved performance in natural language processing applications.",
        "Source": "GPT"
    },
    {
        "Index": 395,
        "Title": "StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion.",
        "Abstract": "Recent language model (LM) advancements have demonstrated significant advancements in zero-shot voice conversion (VC) performance. StreamVoice is a novel approach to real-time zero-shot voice conversion that leverages streamable context-aware language modeling techniques to achieve state-of-the-art results. By incorporating contextual information during the conversion process, StreamVoice is able to accurately capture and reproduce the nuances of different voices in real-time.\n\nUnlike existing methods, StreamVoice does not require pre-training on a specific voice dataset, making it more versatile and adaptable to a wider range of use cases. This not only simplifies the implementation process but also enhances the overall flexibility and effectiveness of the system. Additionally, StreamVoice ensures a high level of fidelity and naturalness in the converted voice, resulting in a more immersive and engaging user experience.\n\nOverall, StreamVoice represents a significant advancement in real-time zero-shot voice conversion technology, offering a powerful and efficient solution for a variety of applications in speech synthesis and voice transformation.",
        "Source": "GPT"
    },
    {
        "Index": 396,
        "Title": "Generate-then-Ground in Retrieval-Augmented Generation for Multi-hop Question Answering.",
        "Abstract": "This paper introduces a novel approach, called Generate-then-Ground in Retrieval-Augmented Generation, for addressing the challenges presented by the Multi-Hop Question Answering (MHQA) task for large language models (LLMs). The MHQA task requires the model to correctly answer questions that involve multiple pieces of information from different parts of the text. However, existing methods struggle to effectively integrate information from multiple sources and generate accurate answers. \n\nOur proposed approach first generates a candidate answer based on the context and then grounds it by retrieving relevant information from the text. By combining generation and retrieval techniques, our model improves answer accuracy and significantly outperforms existing methods on MHQA tasks. Experimental results on benchmark datasets demonstrate the effectiveness of our approach in handling multi-hop reasoning tasks. Overall, our Generate-then-Ground approach represents a promising direction for improving the performance of LLMs on complex question-answering tasks.",
        "Source": "GPT"
    },
    {
        "Index": 397,
        "Title": "Multimodal Contextualized Semantic Parsing from Speech.",
        "Abstract": "We introduce Semantic Parsing in Contextual Environments (SPICE), a task designed to enhance artificial agents' ability to parse and understand natural language in various contextual settings, particularly in multimodal environments where information is presented through both speech and other modalities. In this paper, we propose a new framework for multimodal contextualized semantic parsing from speech, which incorporates relevant contextual cues to improve the accuracy and robustness of semantic parsing models. We demonstrate the effectiveness of our approach through extensive experiments on a diverse range of datasets, showing significant improvements in parsing accuracy and contextual understanding compared to traditional semantic parsing methods. Our results suggest that incorporating contextual information into semantic parsing models from speech can greatly enhance the capabilities of artificial agents in understanding and responding to natural language queries in real-world scenarios. This work lays the foundation for future research in multimodal semantic parsing and paves the way for more sophisticated and context-aware artificial intelligence systems.",
        "Source": "GPT"
    },
    {
        "Index": 398,
        "Title": "LaMP: When Large Language Models Meet Personalization.",
        "Abstract": "This paper highlights the importance of personalization in large language models and introduces the LaMP framework, which blends the power of artificial intelligence with personalized user experiences. Large language models have revolutionized natural language processing tasks by generating human-like text based on vast amounts of data. However, these models often lack personalization, leading to generic responses that may not fully address individual user needs.\n\nLaMP addresses this issue by customizing language models to individual preferences, habits, and demographics. By leveraging user-specific data and feedback, LaMP tailors responses to provide more relevant and engaging interactions. This approach not only enhances the user experience but also improves the overall performance and efficiency of language models.\n\nThrough a series of experiments and case studies, we demonstrate the effectiveness of personalized language models in various applications, such as chatbots, search engines, and content recommendation systems. By integrating personalization into large language models, LaMP showcases the vast potential of AI technology to create more personalized and impactful user experiences.",
        "Source": "GPT"
    },
    {
        "Index": 399,
        "Title": "AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters.",
        "Abstract": "Large language models' (LLMs) abilities are drawn from their pretraining data, and model development begins by fine-tuning these pretrained models on specific tasks. However, the quality of the pretraining data plays a crucial role in determining the performance of the LLMs. In this study, we focus on examining the effects of English pretraining data filters on LLMs' ability to accurately self-describe in webpages. We collected data from various websites where individuals describe themselves, and then evaluated the performance of LLMs trained with different pretraining data filters on this task. Our findings indicate that the choice of pretraining data filters significantly impacts the LLMs' proficiency in accurately describing themselves in webpages. Understanding the effects of pretraining data filters on self-descriptions can provide insights into the importance of high-quality pretraining data for maximizing the performance of LLMs in various natural language processing tasks. This research contributes to the ongoing efforts to improve the efficiency and effectiveness of LLMs in web content analysis and knowledge extraction.",
        "Source": "GPT"
    },
    {
        "Index": 400,
        "Title": "MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues.",
        "Abstract": "The advent of Large Language Models (LLMs) has drastically enhanced dialogue systems, enabling more natural and engaging interactions with users. However, comprehensively evaluating the performance of these models in multi-turn dialogues presents a significant challenge. In this paper, we introduce MT-Bench-101, a fine-grained benchmark specifically designed for evaluating LLMs in multi-turn dialogues. MT-Bench-101 consists of a diverse set of conversations covering various topics and scenarios, with annotated references for evaluating response relevance, coherence, and engagement. By providing a standardized and comprehensive evaluation framework, MT-Bench-101 allows for a more in-depth analysis of LLM performance in dialogues, enabling researchers and developers to identify strengths and weaknesses in model capabilities. We demonstrate the effectiveness of MT-Bench-101 through a series of experiments with state-of-the-art LLMs, showcasing its utility in assessing and comparing the performance of different models in multi-turn dialogue settings.",
        "Source": "GPT"
    },
    {
        "Index": 401,
        "Title": "EFSA: Towards Event-Level Financial Sentiment Analysis.",
        "Abstract": "In this paper, we extend financial sentiment analysis (FSA) to event-level since events usually serve as key drivers of market movements. We propose a novel approach called Event-Level Financial Sentiment Analysis (EFSA) that leverages natural language processing techniques to extract sentiment from news articles, social media, and other sources at the individual event level. By analyzing sentiments associated with specific events, EFSA aims to provide more granular and timely insights into market sentiment compared to traditional FSA approaches that focus on overall sentiment trends. We showcase the effectiveness of EFSA through a case study on a sample of news articles related to a major financial event, demonstrating the ability of our approach to capture nuanced sentiment shifts at the event level. Our results suggest that EFSA has the potential to enhance understanding of market dynamics, improve risk management strategies, and inform investment decisions by providing a more detailed and nuanced perspective on financial sentiment.",
        "Source": "GPT"
    },
    {
        "Index": 402,
        "Title": "What Evidence Do Language Models Find Convincing?",
        "Abstract": "Retrieval-augmented language models are an emerging technology that is being utilized to tackle complex and debated queries. These models are designed to consider subjective, contentious, and conflicting information in order to provide more nuanced and comprehensive responses. However, a critical question arises - what evidence do these language models find convincing? This abstract explores the factors that influence the decision-making process of retrieval-augmented language models when confronted with ambiguous or disputed data. By examining the cognitive processes involved in weighing different types of evidence and evaluating sources, this research sheds light on the inner workings of these advanced AI systems. Understanding the criteria that language models use to determine the credibility and validity of information is crucial for improving their performance and ensuring the accuracy of their responses in a variety of contexts.",
        "Source": "GPT"
    },
    {
        "Index": 403,
        "Title": "Advancement in Graph Understanding: A Multimodal Benchmark and Fine-Tuning of Vision-Language Models.",
        "Abstract": "Graph data organizes complex relationships and interactions between objects, facilitating advanced analysis and decision-making across various domains. In this paper, we present a multimodal benchmark for advancing graph understanding by incorporating vision-language models. By fine-tuning pre-trained models on graph data, we demonstrate significant improvements in tasks such as node classification, link prediction, and graph generation. Our approach leverages the power of combining visual and textual information to enhance the representation and interpretation of graph structures. Through extensive experiments on benchmark datasets, we show the effectiveness of our methodology in capturing intricate relationships within graphs and accurately predicting various graph-related tasks. Additionally, we provide insights into the interpretability and generalization capabilities of vision-language models in the context of graph analysis. Our work contributes to the advancement of graph understanding by exploiting the complementary nature of visual and textual modalities, paving the way for more robust and accurate graph analytics systems.",
        "Source": "GPT"
    },
    {
        "Index": 404,
        "Title": "LangBridge: Multilingual Reasoning Without Multilingual Supervision.",
        "Abstract": "We introduce LangBridge, a novel zero-shot approach for adapting language models to multilingual reasoning tasks without requiring multilingual supervision. Our proposed method leverages the intrinsic linguistic similarities across different languages to enable language models to perform well on tasks in languages for which they were not explicitly trained. By using a cross-lingual knowledge distillation process, LangBridge is able to transfer knowledge from a source language to a target language without the need for bilingual aligned data or parallel corpora. Experimental results demonstrate the effectiveness of LangBridge on various multilingual reasoning benchmarks, outperforming baselines and achieving competitive performance with models that have been explicitly trained on multiple languages. Our findings suggest that LangBridge has the potential to significantly reduce the resource-intensive process of training multilingual models, making it a promising approach for advancing multilingual natural language understanding tasks.",
        "Source": "GPT"
    },
    {
        "Index": 405,
        "Title": "Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs.",
        "Abstract": "Large language models (LLMs) have achieved impressive human-like performance across various reasoning tasks. However, their ability to reason with rules is still an area of concern. In this study, we propose a logic scaffolding approach to stress-test and improve LLMs' rule-based reasoning capabilities. By providing explicit logical rules as input, we aim to evaluate the LLMs' understanding and application of these rules in decision-making processes. Through a series of experiments and evaluations, we demonstrate the effectiveness of our logic scaffolding approach in enhancing the rule-based reasoning abilities of LLMs. Our findings suggest that LLMs can be trained to reason with rules by incorporating structured logic into their learning frameworks. This research contributes to the ongoing efforts in advancing the interpretability and reliability of LLMs in reasoning tasks where explicit rule adherence is crucial.",
        "Source": "GPT"
    },
    {
        "Index": 406,
        "Title": "SEGO: Sequential Subgoal Optimization for Mathematical Problem-Solving.",
        "Abstract": "Large Language Models (LLMs) have driven substantial progress in artificial intelligence in recent years, exhibiting remarkable capabilities in a wide range of tasks. However, their performance in mathematical problem-solving tasks still lags behind human capabilities due to the lack of explicit reasoning and planning mechanisms. In this paper, we present SEGO (Sequential Subgoal Optimization), a novel approach that leverages the strengths of LLMs while incorporating explicit subgoal reasoning and planning to improve mathematical problem-solving. SEGO decomposes complex mathematical problems into smaller, more manageable subgoals and sequentially optimizes the model's decision-making process to achieve the overall solution. Our experimental results demonstrate that SEGO significantly outperforms baseline LLM approaches on a variety of mathematical problem-solving tasks, showcasing the potential of integrating subgoal optimization techniques with large language models. SEGO represents a promising step towards enhancing the problem-solving capabilities of LLMs and advancing the state-of-the-art in mathematical reasoning and planning.",
        "Source": "GPT"
    },
    {
        "Index": 407,
        "Title": "Unlocking the Power of Large Language Models for Entity Alignment.",
        "Abstract": "Entity Alignment (EA) is vital for integrating diverse knowledge graph (KG) data, playing a crucial role in various applications such as information retrieval, recommendation systems, and question answering. However, accurately aligning entities across different KGs remains challenging due to the vast amount of data and the inherent noise present in the KGs. Large Language Models (LLMs) have recently shown promising results in various natural language processing tasks, prompting researchers to explore their potential in EA. In this paper, we investigate the use of LLMs for entity alignment, proposing a novel approach that leverages the power of these models to improve the accuracy and efficiency of entity alignment processes. We demonstrate the effectiveness of our approach through extensive experiments on benchmark datasets, showing significant improvements in alignment quality compared to existing methods. Our findings highlight the untapped potential of LLMs in facilitating the integration of diverse KG data and pave the way for future research in this area. Unlocking the power of LLMs for entity alignment holds great promise for advancing knowledge integration and enhancing the performance of various AI applications.",
        "Source": "GPT"
    },
    {
        "Index": 408,
        "Title": "Trial and Error: Exploration-Based Trajectory Optimization of LLM Agents.",
        "Abstract": "Large Language Models (LLMs) have become integral components in various autonomous agent systems. In this study, we propose a trial and error approach for trajectory optimization of LLM agents in exploration-based tasks. Traditional trajectory optimization methods often struggle with the complexity and high-dimensional nature of LLMs, leading to suboptimal solutions. Our approach leverages the inherent ability of LLMs to learn from trial and error, allowing the agent to explore different trajectories and learn from its mistakes. Through a series of experiments, we demonstrate the effectiveness of our method in improving exploration and optimizing trajectories for LLM agents in various environments. By combining the power of LLMs with trial and error learning, we show that our approach can achieve significant performance improvements compared to traditional optimization techniques. Our findings highlight the potential of exploration-based trajectory optimization for enhancing the capabilities of LLM agents in autonomous systems.",
        "Source": "GPT"
    },
    {
        "Index": 409,
        "Title": "ReFT: Reasoning with Reinforced Fine-Tuning.",
        "Abstract": "One way to enhance the reasoning capability of Large Language Models (LLMs) is to conduct fine-tuning with reinforcement learning techniques. This new approach, known as ReFT (Reasoning with Reinforced Fine-Tuning), focuses on improving the ability of LLMs to reason and make logical inferences. By combining traditional fine-tuning methods with reinforcement learning algorithms, ReFT leverages feedback loops to strengthen the model's understanding of complex relationships and improve its reasoning skills. Through this iterative process, the LLM receives rewards for accurately interpreting and solving reasoning tasks, encouraging it to learn and adjust its parameters accordingly. The result is a more robust and effective reasoning system that can solve a wider range of tasks with higher accuracy and efficiency. ReFT offers a promising avenue for advancing the capabilities of LLMs and unlocking their full potential in various applications requiring sophisticated reasoning abilities.",
        "Source": "GPT"
    },
    {
        "Index": 410,
        "Title": "Cognitive Visual-Language Mapper: Advancing Multimodal Comprehension with Enhanced Visual Knowledge Alignment.",
        "Abstract": "As we evaluate and rethink the current landscape of Large Multimodal Models (LMMs), we find that widely-used approaches may lack the ability to effectively align visual and linguistic features in a coherent manner. In response to this limitation, we propose the Cognitive Visual-Language Mapper, a novel framework designed to advance multimodal comprehension by enhancing visual knowledge alignment. By addressing the shortcomings of existing LMMs, our model offers a more comprehensive and intuitive mapping of visual and linguistic information, ultimately improving the accuracy and efficiency of multimodal tasks such as image captioning, visual question answering, and visual grounding. Through a series of experiments and evaluations, we demonstrate that the Cognitive Visual-Language Mapper significantly outperforms traditional LMMs in terms of semantic alignment and overall performance. Our findings highlight the importance of aligning visual and linguistic knowledge in multimodal comprehension tasks and pave the way for further advancements in the field of artificial intelligence and computer vision.",
        "Source": "GPT"
    },
    {
        "Index": 411,
        "Title": "FreeCtrl: Constructing Control Centers with Feedforward Layers for Learning-Free Controllable Text Generation.",
        "Abstract": "Controllable text generation (CTG) is a powerful technique for crafting text that adheres to specific attributes, such as style or sentiment. Traditionally, CTG models rely on learning-based approaches, which require extensive training data and can be computationally intensive. In this paper, we propose FreeCtrl, a novel framework for constructing control centers with feedforward layers to enable learning-free controllable text generation. By leveraging feedforward layers instead of traditional learning-based methods, FreeCtrl allows for more efficient and flexible text generation. Through a series of experiments, we demonstrate that FreeCtrl outperforms existing learning-based CTG models in terms of both performance and efficiency. Additionally, we show that FreeCtrl can easily adapt to different attributes, making it a versatile tool for controllable text generation. Overall, our work contributes to the advancement of controllable text generation by providing a more efficient and effective approach that does not rely on extensive training data.",
        "Source": "GPT"
    },
    {
        "Index": 412,
        "Title": "HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical Criteria Decomposition.",
        "Abstract": "Large language models (LLMs) have emerged as a promising alternative to expensive human evaluations. However, evaluating the performance of these models still poses a challenge due to the lack of standardized evaluation criteria. In this paper, we present HD-Eval, a novel framework for aligning large language model evaluators through hierarchical criteria decomposition. HD-Eval breaks down the evaluation process into multiple levels of criteria, from high-level abstract concepts to low-level specific metrics, providing a structured and comprehensive way to assess LLM performance.\n\nThrough HD-Eval, we aim to address the issue of inconsistency and subjectivity in evaluating large language models by providing a systematic approach that allows evaluators to compare and contrast model performance based on a common set of criteria. This framework enables researchers to gain a deeper understanding of the strengths and weaknesses of different LLMs and facilitates more robust and reliable evaluations in the field of natural language processing and artificial intelligence.",
        "Source": "GPT"
    },
    {
        "Index": 413,
        "Title": "Conundrums in Cross-Prompt Automated Essay Scoring: Making Sense of the State of the Art.",
        "Abstract": "Cross-prompt automated essay scoring (AES) is an under-investigated yet challenging task that has recently gained momentum in the field of natural language processing. In this task, automated systems are required to evaluate and score essays on various prompts, which adds another layer of complexity compared to traditional single-prompt AES. This paper provides an in-depth analysis of the current state of the art in cross-prompt AES and highlights the major conundrums that researchers face in this evolving area of study. We discuss the key challenges, such as prompt variability, domain adaptability, and scoring consistency, and propose potential solutions to address these issues. By exploring these conundrums and offering insights into the advancements in cross-prompt AES, this paper aims to shed light on the complexities of automated essay scoring across multiple prompts and pave the way for future research in this burgeoning field.",
        "Source": "GPT"
    },
    {
        "Index": 414,
        "Title": "Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution.",
        "Abstract": "Large language models (LLMs) reflect societal norms and biases, especially about gender. While societal biases and stereotypes are prevalent in many aspects of language processing, our study focuses on how LLMs attribute emotions differently to men and women. We found that LLMs tend to associate anger more strongly with men and sadness more strongly with women, perpetuating gendered stereotypes in emotion attribution.\n\nBy analyzing the outputs of various LLMs, we observed a consistent pattern of gendered emotion attribution, regardless of the specific tasks or prompts given to the models. These findings raise concerns about the potential reinforcement of harmful gender stereotypes in natural language processing technologies. As LLMs continue to be widely used in various applications, it is crucial to address and mitigate the biases present in these models to ensure fair and accurate representation of diverse groups in automated language processing. This study highlights the importance of critically assessing the societal impacts of LLMs and advocating for more inclusive and equitable approaches to language modeling.",
        "Source": "GPT"
    },
    {
        "Index": 415,
        "Title": "Label Augmentation for Zero-Shot Hierarchical Text Classification.",
        "Abstract": "Hierarchical Text Classification poses the difficult challenge of classifying documents into multiple labels organized in a hierarchical structure. In this study, we propose a Label Augmentation approach for Zero-Shot Hierarchical Text Classification. The main idea behind our approach is to leverage a small set of labeled data to learn new labels that can be used for classifying unseen documents. Through a combination of label embedding techniques and hierarchical label relationships, we are able to generalize the classifier to predict labels that were not present in the training data. Our experimental results on a real-world dataset demonstrate the effectiveness of our Label Augmentation approach, achieving competitive performance compared to existing methods. By enabling zero-shot classification for hierarchical text data, our approach provides a flexible and scalable solution for handling large and complex document categorization tasks. Overall, our study contributes to advancing the state-of-the-art in hierarchical text classification and opens up new possibilities for applying machine learning techniques to real-world text data.",
        "Source": "GPT"
    },
    {
        "Index": 416,
        "Title": "STICKERCONV: Generating Multimodal Empathetic Responses from Scratch.",
        "Abstract": "Stickers have gained widespread recognition for their ability to enhance empathetic communication in online interactions. However, the full potential of stickers in generating multimodal empathetic responses from scratch remains underexplored in current research. In this study, we present an innovative approach called STICKERCONV that leverages stickers to create empathetic responses across multiple modalities. By analyzing the emotional content and contexts of conversations, STICKERCONV generates unique and personalized sticker-based responses that convey empathy and understanding to the recipient. Through a combination of machine learning algorithms and natural language processing techniques, our framework enables users to create empathetic responses that go beyond traditional text-based communication. By incorporating stickers into the conversational flow, STICKERCONV enhances the emotional expressiveness of online interactions and fosters a deeper sense of connection between individuals. Our findings highlight the potential of stickers as a powerful tool for promoting empathy and understanding in digital communication.",
        "Source": "GPT"
    },
    {
        "Index": 417,
        "Title": "EIT: Enhanced Interactive Transformer.",
        "Abstract": "In this paper, we propose a novel model called Enhanced Interactive Transformer (EIT), which integrates two key principles from the literature: the complementary principle and the consensus principle. The complementary principle suggests that combining different modalities or features can enhance the overall performance of a model, while the consensus principle emphasizes the importance of aggregating information from multiple sources to make more accurate predictions. \n\nOur EIT model builds upon the standard Transformer architecture by incorporating mechanisms to effectively leverage complementary information from various sources and reach a consensus through interactive learning. This allows the model to capture dependencies and relationships between different modalities, leading to improved performance on tasks that require holistic understanding of complex data. \n\nExperimental results demonstrate that our EIT model outperforms existing state-of-the-art models on various benchmarks, highlighting the effectiveness of integrating the complementary and consensus principles in enhancing interactive learning capabilities.",
        "Source": "GPT"
    },
    {
        "Index": 418,
        "Title": "MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs.",
        "Abstract": "Generative Large Language Models (LLMs) are widely utilized for their excellence in various tasks. However, one challenge they face is accurately estimating uncertainty in their responses. In this paper, we introduce MARS, a novel approach for Meaning-Aware Response Scoring in generative LLMs. MARS leverages semantic and syntactic information to better understand the context of the conversation and provide a more meaningful response. By considering the meaning of the response in addition to its fluency, MARS is able to accurately estimate uncertainty and increase the model's reliability. We demonstrate the effectiveness of MARS through experiments on a range of benchmark datasets, showing that it outperforms existing methods in uncertainty estimation. Our results show that incorporating meaning-aware scoring can improve the overall performance of generative LLMs by providing more reliable responses. MARS represents a significant step forward in enhancing the capabilities of LLMs for natural language understanding and generation tasks.",
        "Source": "GPT"
    },
    {
        "Index": 419,
        "Title": "EXAMS-V: A Multi-Discipline Multilingual Multimodal Exam Benchmark for Evaluating Vision Language Models.",
        "Abstract": "We introduce EXAMS-V, a new challenging multi-discipline multimodal multilingual exam benchmark for evaluating vision language models. This benchmark incorporates diverse disciplines such as biology, physics, history, and literature, along with multimodal inputs such as text, images, and audio in multiple languages. By combining these factors, EXAMS-V presents a comprehensive evaluation of the capabilities of vision language models in understanding and generating content across various subjects and modalities.\n\nThe diverse nature of EXAMS-V allows for a more comprehensive evaluation of the robustness and generalization capabilities of vision language models. By including a multilingual component, this benchmark also addresses the need for models to perform well across different languages, thereby promoting the development of more inclusive and globally-applicable vision language models.\n\nWe believe that EXAMS-V will serve as a valuable resource for researchers and practitioners in the field of vision language modeling, enabling them to assess and compare the performance of different models in a wide range of contexts.",
        "Source": "GPT"
    },
    {
        "Index": 420,
        "Title": "Order-Agnostic Data Augmentation for Few-Shot Named Entity Recognition.",
        "Abstract": "Data augmentation (DA) methods have been proven to be effective for pre-trained language models (PLMs) in improving performance on various natural language processing tasks. In this paper, we propose an order-agnostic data augmentation approach specifically tailored for few-shot named entity recognition (NER). Our method generates diverse and informative training samples by shuffling the input entities in a sentence, effectively simulating different orders of entity mentions. This order-agnostic data augmentation strategy helps the model learn to recognize entities regardless of their positions in a sentence, thereby enhancing its generalization capability. We conducted experiments on a benchmark dataset for few-shot NER and demonstrated that our proposed approach outperforms existing data augmentation techniques, achieving state-of-the-art results. Furthermore, we conducted ablation studies to analyze the impact of different augmentation strategies and observed that order-agnostic augmentation plays a crucial role in improving the performance of few-shot NER models. Our findings highlight the importance of designing task-specific data augmentation methods for enhancing the capabilities of PLMs in tackling challenging NER tasks with limited labeled data.",
        "Source": "GPT"
    },
    {
        "Index": 421,
        "Title": "Text Embedding Inversion Security for Multilingual Language Models.",
        "Abstract": "Textual data is often represented as real-numbered embeddings in NLP, particularly with the popularity of language models like BERT and GPT-3. However, recent research has identified potential security risks in these embeddings, particularly in the context of text embedding inversion attacks. In this study, we focus on the security of multilingual language models, analyzing the vulnerability of their embeddings to inversion attacks across multiple languages. We propose novel techniques to enhance the security and robustness of text embeddings in multilingual models, aiming to mitigate the risk of unauthorized access to sensitive information. Our experimental results demonstrate the effectiveness of our proposed methods in resisting text embedding inversion attacks, highlighting the importance of incorporating security measures into the design of multilingual language models. By addressing these security concerns, we aim to promote the safe and secure use of text embeddings in multilingual NLP applications, ensuring the privacy and confidentiality of users' data in a global linguistic context.",
        "Source": "GPT"
    },
    {
        "Index": 422,
        "Title": "Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment.",
        "Abstract": "Recent advancements in large language models have sparked considerable efforts to improve their role-playing capabilities. In this study, we propose a novel approach to enhancing the role-play abilities of open-source language models by exploring the concept of self-alignment. We demonstrate that large language models can be viewed as superpositions of all characters, enabling them to attain arbitrary role-play tasks through self-alignment. By leveraging this unique characteristic of language models, we are able to significantly improve their role-playing proficiency in various scenarios.\n\nOur experiments show that incorporating self-alignment into language models not only enhances their performance in conventional role-play tasks but also enables them to adapt to new and challenging role-play scenarios. This approach provides a promising direction for future research on enhancing the capabilities of large language models, opening up new possibilities for their application in human-computer interaction, storytelling, and other creative domains. Overall, our findings highlight the potential of self-alignment as a key mechanism for advancing the role-playing proficiency of open-source large language models.",
        "Source": "GPT"
    },
    {
        "Index": 423,
        "Title": "PlatoLM: Teaching LLMs in Multi-Round Dialogue via a User Simulator.",
        "Abstract": "The unparalleled performance of closed-sourced ChatGPT has sparked efforts towards its democratization, with notable strides in the development of PlatoLM. PlatoLM is a novel approach to teaching Language Learning Models (LLMs) through multi-round dialogue utilizing a User Simulator. This innovative method allows for more interactive and engaging learning experiences, enhancing the effectiveness of LLM training. By simulating user responses and feedback, PlatoLM provides LLMs with a diverse range of linguistic inputs and challenges, resulting in improved language understanding and generation capabilities. Furthermore, the use of multi-round dialogue helps to facilitate a more dynamic and realistic learning environment for LLMs, better preparing them for real-world applications. The potential impact of PlatoLM extends to various fields, including natural language processing, virtual assistants, and language translation services. Overall, the development of PlatoLM represents a significant advancement in the democratization of language learning models, presenting exciting opportunities for the future of AI-driven communication technologies.",
        "Source": "GPT"
    },
    {
        "Index": 424,
        "Title": "Synthesizing Text-to-SQL Data from Weak and Strong LLMs.",
        "Abstract": "The capability gap between open-source and closed-source large language models (LLMs) remains a challenge in natural language processing (NLP) tasks, particularly in the context of generating SQL queries from text. In this paper, we propose a novel approach to leveraging both weak and strong LLMs to synthesize text-to-SQL data in a more robust and accurate manner. By combining the strengths of both types of models, we are able to improve the overall performance and efficiency of the data synthesis process. Our experimental results demonstrate the effectiveness of our approach, yielding significantly higher accuracy rates compared to using either weak or strong LLMs individually. Additionally, we provide insights into the potential applications of our methodology in various NLP tasks, showcasing the versatility and adaptability of our synthesized text-to-SQL data.Overall, our work addresses the existing capability gap between open-source and closed-source LLMs, offering a promising solution for enhancing the performance of text-to-SQL data synthesis.",
        "Source": "GPT"
    },
    {
        "Index": 425,
        "Title": "STRUCTSUM Generation for Faster Text Comprehension.",
        "Abstract": "In this paper, we address the challenge of generating structured summaries of text content using large language models (LLMs). Specifically, we propose a method for Structured Summary (STRUCTSUM) generation, which aims to facilitate faster and more efficient comprehension of textual information. Our approach leverages the powerful capabilities of LLMs to not only summarize the content but also organize it in a structured format that enhances readability and comprehension. By structuring the generated summaries, we enable users to quickly grasp key information and relationships within the text, reducing the cognitive load typically associated with reading and understanding lengthy documents. Our experimental results demonstrate the effectiveness of our proposed STRUCTSUM generation method in producing concise and informative summaries that facilitate faster text comprehension. Overall, our work contributes to the advancement of text summarization techniques that leverage LLMs to improve the efficiency and effectiveness of information processing in various applications.",
        "Source": "GPT"
    },
    {
        "Index": 426,
        "Title": "Analysing The Impact of Sequence Composition on Language Model Pre-Training.",
        "Abstract": "Most language model pre-training frameworks concatenate multiple documents into fixed-length sequences and use causal masking to predict the next word in a sequence. This study analyzes the impact of sequence composition on the effectiveness of language model pre-training. By varying the lengths of the concatenated sequences and exploring different strategies for organizing the document inputs, we investigate how these factors influence the performance of the pre-trained models. Our findings suggest that the composition of sequences can significantly affect the model's ability to capture long-range dependencies and contextual information. Moreover, we show that carefully organizing document inputs can improve the overall performance of language model pre-training. These results have important implications for developers and researchers working on building and improving language models for a variety of natural language processing tasks. Ultimately, understanding the impact of sequence composition can lead to more efficient and effective pre-training strategies for language models.",
        "Source": "GPT"
    },
    {
        "Index": 427,
        "Title": "NACL: A General and Effective KV Cache Eviction Framework for LLM at Inference Time.",
        "Abstract": "Recently, Large Language Models (LLMs) have emerged as powerful tools in artificial intelligence, revolutionizing various applications such as natural language processing and machine translation. However, efficient memory management is crucial for the optimal performance of LLMs, especially during inference time where memory constraints can pose challenges. In this paper, we introduce NACL, a novel KV cache eviction framework designed to address these challenges by effectively managing the memory cache of LLMs. NACL offers a general and efficient solution for cache eviction by dynamically prioritizing and removing key-value pairs based on their relevance and access patterns. By integrating NACL into the memory management system of LLMs, we demonstrate significant improvements in performance and resource utilization during inference time. Our experimental results show that NACL effectively reduces memory footprint and latency, making it a valuable tool for enhancing the efficiency of LLMs in real-world applications. Overall, NACL provides a versatile and effective solution for optimizing memory usage in LLMs, thus facilitating their widespread deployment in AI applications.",
        "Source": "GPT"
    },
    {
        "Index": 428,
        "Title": "SpikeVoice: High-Quality Text-to-Speech Via Efficient Spiking Neural Network.",
        "Abstract": "Brain-inspired Spiking Neural Network (SNN) has demonstrated its effectiveness and efficiency in vision, natural language processing, and other cognitive tasks. In this paper, we propose SpikeVoice, a high-quality text-to-speech system that leverages the power of SNNs for efficient speech synthesis. SpikeVoice utilizes a novel architecture that combines traditional neural networks with spiking neurons to achieve superior performance in generating human-like speech. By capturing the temporal dynamics of speech signals, SpikeVoice is able to produce more natural and expressive audio output compared to existing text-to-speech systems.\n\nWe demonstrate the effectiveness of SpikeVoice through extensive experiments on various speech datasets, showing that our approach outperforms state-of-the-art models in both quality and efficiency. Additionally, SpikeVoice is able to generate speech in real-time, making it suitable for applications such as conversational agents, virtual assistants, and audiobook production. Overall, SpikeVoice represents a significant advancement in text-to-speech technology, showcasing the potential of spiking neural networks in creating high-quality synthetic speech.",
        "Source": "GPT"
    },
    {
        "Index": 429,
        "Title": "Context-aware Difference Distilling for Multi-change Captioning.",
        "Abstract": "Multi-change captioning aims to describe complex and coupled changes within an image pair in natural language, providing a detailed and informative description of the differences between the two images. However, accurately capturing the intricate relationships between multiple changes remains a challenging task, as existing methods often struggle to produce coherent and relevant captions. In this paper, we propose a novel approach called Context-aware Difference Distilling (CADD) for multi-change captioning, which leverages the context information surrounding each change to improve the quality and relevance of the generated captions. By incorporating contextual cues into the captioning process, CADD is able to effectively capture the interdependencies between different changes in the image pair, resulting in more informative and accurate descriptions. Experimental results on benchmark datasets demonstrate that our approach outperforms state-of-the-art methods in terms of caption quality and relevance, highlighting the effectiveness of context-aware difference distilling for multi-change captioning tasks.",
        "Source": "GPT"
    },
    {
        "Index": 430,
        "Title": "Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion.",
        "Abstract": "In recent years, code language models (LMs) have been increasingly utilized in code intelligence applications. These LMs have demonstrated significant capabilities in assisting developers with tasks such as code completion. However, current LM-based code completion systems primarily focus on local context within a single code file, limiting their effectiveness in suggesting relevant code snippets from a repository-level perspective. To address this limitation, we propose a Dataflow-Guided Retrieval Augmentation (DGRA) approach for enhancing repository-level code completion. By leveraging the dataflow information between different code entities within a codebase, our approach aims to provide more accurate and contextually relevant code suggestions to developers. Through experimental evaluations on a set of real-world code repositories, we demonstrate that our DGRA approach outperforms existing LM-based code completion systems in terms of retrieval accuracy and recommendation relevance. Our findings suggest that incorporating dataflow-guided retrieval mechanisms can significantly enhance the quality of code completion suggestions at the repository level.",
        "Source": "GPT"
    },
    {
        "Index": 431,
        "Title": "Chain-of-Exemplar: Enhancing Distractor Generation for Multimodal Educational Question Generation.",
        "Abstract": "Multiple-choice questions (MCQs) are important in enhancing concept learning and student engagement for educational purposes. However, the effectiveness of MCQs relies heavily on the quality of the distractors provided. Distractors are the incorrect answer choices included in MCQs that aim to challenge students' understanding of the subject matter. In this study, we propose a novel approach termed Chain-of-Exemplar to enhance distractor generation for multimodal educational question generation. \n\nChain-of-Exemplar leverages a chain of exemplar images to guide the generation of distractors that are not only plausible but also informative and relevant to the correct answer choice. By incorporating multimodal elements such as images along with text, our approach aims to provide a more immersive and engaging learning experience for students. \n\nThrough experimental evaluations, we demonstrate that Chain-of-Exemplar significantly improves the quality of distractors generated for MCQs, leading to better educational outcomes in terms of concept learning and student engagement.",
        "Source": "GPT"
    },
    {
        "Index": 432,
        "Title": "LLMEmbed: Rethinking Lightweight LLM's Genuine Function in Text Classification.",
        "Abstract": "With the booming of Large Language Models (LLMs), prompt-learning has become a promising method mainly due to its ability to tailor the LLMs to specific tasks. However, the genuine function of Lightweight LLMs (LLMEmbed) in text classification has not been fully explored. This paper rethinks the role of Lightweight LLMs in text classification tasks, highlighting their potential to improve efficiency and effectiveness in classification tasks while maintaining a lower computational cost compared to traditional LLMs. Through a series of experiments, we demonstrate that LLMEmbed can achieve comparable or even superior performance in text classification tasks when compared to larger LLMs. Additionally, we explore how the use of Lightweight LLMs can enhance interpretability and domain-specific fine-tuning in text classification tasks. Overall, this paper sheds light on the overlooked potential of Lightweight LLMs in text classification and emphasizes the importance of considering their genuine function in future research and applications.",
        "Source": "GPT"
    },
    {
        "Index": 433,
        "Title": "LEMON: Reviving Stronger and Smaller LMs from Larger LMs with Linear Parameter Fusion.",
        "Abstract": "In the new era of language models, small models with billions of parameters are gaining attention for their potential to offer efficient and scalable solutions. However, these smaller models often struggle to match the performance of larger language models due to limitations in their capacity and expressiveness. In this study, we propose a novel approach called LEMON (Linear Parameter Fusion) to revive stronger and smaller language models by leveraging the strengths of larger models through linear parameter fusion. By combining the knowledge and parameters of larger language models with the smaller models, LEMON aims to enhance the efficiency and effectiveness of small models without sacrificing their compact size. Our experiments demonstrate that LEMON significantly improves the performance of smaller language models on various natural language processing tasks, showcasing its potential to bridge the gap between small and large models in the field of language understanding and generation.",
        "Source": "GPT"
    },
    {
        "Index": 434,
        "Title": "Speech Sense Disambiguation: Tackling Homophone Ambiguity in End-to-End Speech Translation.",
        "Abstract": "End-to-end speech translation (ST) presents notable disambiguation challenges as it necessitates simultaneous cross-modal and cross-lingual understanding. One particularly challenging aspect is homophone ambiguity, where words with different meanings but the same pronunciation can lead to errors in translation. In this paper, we propose a novel approach called Speech Sense Disambiguation (SSD) to address this issue in end-to-end ST systems. \n\nOur method leverages both acoustic and linguistic cues to disambiguate homophones in the speech signal, allowing for more accurate translations. By incorporating context information and semantic embeddings, our model is able to correctly identify the intended meaning of homophones based on the surrounding words and the overall semantic context. \n\nThrough extensive experimentation, we demonstrate that our SSD approach significantly improves translation accuracy, especially in cases of homophone ambiguity. Our results show that by tackling this challenging aspect of speech translation, we can enhance the overall performance and usability of end-to-end ST systems.",
        "Source": "GPT"
    },
    {
        "Index": 435,
        "Title": "To be Continuous, or to be Discrete, Those are Bits of Questions.",
        "Abstract": "Abstract:\n\nRecently, binary representation has emerged as a novel approach that sits between the realms of continuous and discrete representations. This abstract explores the concept of binary representation and the implications it has for various fields, including computer science, mathematics, and information theory. By utilizing binary digits, or bits, to represent data, binary representation allows for more efficient storage and processing of information. Additionally, it enables the seamless transition between continuous and discrete data types, leading to more flexible and versatile data manipulation techniques. This abstract discusses the benefits and drawbacks of using binary representation in various applications, as well as the challenges that arise when implementing this approach. Overall, binary representation offers a unique perspective on data representation that bridges the gap between continuous and discrete domains, opening up new possibilities for data analysis and interpretation.",
        "Source": "GPT"
    },
    {
        "Index": 436,
        "Title": "Moûsai: Efficient Text-to-Music Diffusion Models.",
        "Abstract": "Recent years have seen exponential growth in the development of large generative models for text, transforming the capabilities of natural language processing. However, the translation of text into music has not received comparable attention. In response, the Moûsai project introduces efficient text-to-music diffusion models to bridge this gap in the field of generative models. By leveraging the latest advancements in machine learning and music composition techniques, Moûsai aims to enable the seamless conversion of textual information into musical compositions. The key innovation in Moûsai lies in its ability to capture the nuanced relationship between text and music, allowing for the creation of harmonious and expressive pieces. Through extensive experimentation and evaluation, Moûsai demonstrates promising results in generating diverse and high-quality musical outputs from textual inputs. Ultimately, this research opens up new avenues for creative expression and exploration at the intersection of language and music.",
        "Source": "GPT"
    },
    {
        "Index": 437,
        "Title": "PokeMQA: Programmable knowledge editing for Multi-hop Question Answering.",
        "Abstract": "Multi-hop question answering (MQA) is one of the most challenging tasks in natural language processing, as it requires machines to not only understand individual facts but also to connect multiple pieces of information to generate a cohesive answer. Current MQA systems often struggle with efficiently processing and synthesizing knowledge from various sources to provide accurate responses.\n\nIn this paper, we introduce PokeMQA, a programmable knowledge editing framework designed to improve the performance of multi-hop question answering systems. By allowing users to manually edit and organize knowledge graphs, PokeMQA enables humans to provide valuable input in guiding machine comprehension. This knowledge editing process helps to bridge the gap between individual pieces of information and assists machines in making logical connections to arrive at the correct answer.\n\nWe demonstrate the effectiveness of PokeMQA through a series of experiments on standard MQA datasets, showcasing its ability to significantly enhance the performance of existing multi-hop question answering models. Our framework introduces a novel approach to improving machine comprehension through human-guided knowledge editing, paving the way for more accurate and reliable multi-hop question answering systems.",
        "Source": "GPT"
    },
    {
        "Index": 438,
        "Title": "MemeGuard: An LLM and VLM-based Framework for Advancing Content Moderation via Meme Intervention.",
        "Abstract": "In the digital world, memes present a unique challenge for content moderation due to their fast dissemination and potential for spreading harmful or misleading information. Traditional moderation approaches often struggle to keep up with the constantly evolving nature of memes. To address this challenge, we propose MemeGuard, an innovative framework that leverages machine learning models, specifically Latent Dirichlet Allocation (LLM) and Visual Latent Mapping (VLM), for effective content moderation through meme intervention. By analyzing the text and visual components of memes, MemeGuard can identify and categorize problematic content, enabling timely intervention to prevent its further spread. Our framework offers a proactive and adaptive solution to the complex problem of meme moderation, helping platforms maintain a safer and more trustworthy online environment. Through advanced techniques such as sentiment analysis and keyword detection, MemeGuard enhances the efficiency and accuracy of content moderation, ultimately fostering a more positive digital experience for users.",
        "Source": "GPT"
    },
    {
        "Index": 439,
        "Title": "Efficient OCR for Building a Diverse Digital History.",
        "Abstract": "Many users consult digital archives daily, but the information they can access is unrepresentative of the diverse history and perspectives of our society. Traditional Optical Character Recognition (OCR) tools often struggle to accurately transcribe documents that include diverse languages, scripts, and formats. This limitation hinders the ability to build a comprehensive and inclusive digital history.\n\nIn response to this challenge, our research focuses on developing an efficient OCR system that can accurately process a wide range of text inputs, including different languages, historical scripts, and formats. By improving OCR technology, we aim to enhance access to diverse historical materials and support the creation of a more inclusive digital archive.\n\nOur approach involves incorporating machine learning algorithms and adaptive techniques to train the OCR system to recognize and transcribe diverse text inputs more effectively. Through this research, we strive to advance the field of digital archiving and ensure that diverse voices and perspectives are represented in our shared digital history.",
        "Source": "GPT"
    },
    {
        "Index": 440,
        "Title": "Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space.",
        "Abstract": "Despite the notable success of language models (LMs) in various natural language processing (NLP) tasks, these models are often vulnerable to backdoor attacks when trained on datasets containing poisoned samples. In this paper, we propose a novel approach for acquiring clean language models by downscaling the frequency space of the poisoned datasets. By reducing the impact of the poisoned samples in the training data, we aim to mitigate the risk of backdoor attacks and enhance the robustness of the language models. Our experimental results demonstrate that our proposed method effectively reduces the presence of backdoor triggers in the trained models, while maintaining high performance on standard NLP benchmarks. Additionally, we show that downscaling frequency space can help identify and filter out poisoned samples, leading to cleaner and more reliable language models. Overall, our approach provides a promising solution for improving the security and trustworthiness of language models in the face of potential backdoor attacks.",
        "Source": "GPT"
    },
    {
        "Index": 441,
        "Title": "ANAH: Analytical Annotation of Hallucinations in Large Language Models.",
        "Abstract": "Reducing the 'hallucination' problem of Large Language Models (LLMs) is crucial for their wide applications. In this paper, we present ANAH, an analytical annotation framework designed to address and mitigate the issue of hallucinations in LLMs. By systematically analyzing the generated text outputs of LLMs, ANAH utilizes a set of predefined criteria to identify and annotate instances of hallucination. These annotations provide valuable insights into the underlying mechanisms causing hallucinations in LLMs, helping researchers better understand and mitigate this phenomenon. Furthermore, ANAH offers a systematic and structured approach to evaluating and improving the performance of LLMs in various applications, such as natural language understanding and generation tasks. Through a series of experiments and case studies, we demonstrate the effectiveness of ANAH in detecting and reducing hallucinations in LLMs, highlighting its potential to enhance the reliability and accuracy of these powerful language models. Ultimately, our framework aims to contribute to the ongoing efforts in developing more robust and trustworthy LLMs for real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 442,
        "Title": "Aligning Large Language Models for Controllable Recommendations.",
        "Abstract": "Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their potential in generating controllable recommendations. In this study, we propose a novel approach for aligning LLMs to enhance their capability in providing personalized and context-aware recommendations. By fine-tuning the models on large-scale recommendation datasets and incorporating control knobs, we aim to improve the interpretability and user satisfaction of the generated recommendations.\n\nThrough experimental evaluations on various recommendation tasks, we demonstrate the effectiveness of our proposed method in achieving controllability without compromising the diversity and relevance of recommendations. Our findings highlight the importance of aligning LLMs for controllable recommendations and suggest potential applications in diverse domains such as e-commerce, entertainment, and content discovery. Overall, our research contributes to advancing the field of recommendation systems by harnessing the power of LLMs for more intuitive and tailored recommendation experiences.",
        "Source": "GPT"
    },
    {
        "Index": 443,
        "Title": "Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods.",
        "Abstract": "Language Models (LMs) acquire parametric knowledge from their training process, embedding it within their weights. This knowledge is crucial for their ability to generate coherent and contextually relevant text. However, understanding how LMs utilize this parametric knowledge has been a challenging task. In this paper, we present a unified framework for attribution methods that aims to reveal the inner workings of LMs by deciphering the importance of different parameters in the model. By analyzing the attributions of specific parameters to the model's predictions, our framework sheds light on how LMs leverage their parametric knowledge to generate text. We demonstrate the effectiveness of our approach on various LM architectures and datasets, showcasing how different attribution methods can provide insights into the functioning of LMs. Overall, our framework offers a comprehensive and intuitive way to interpret the behavior of LMs and highlights the importance of parametric knowledge in their language generation capabilities.",
        "Source": "GPT"
    },
    {
        "Index": 444,
        "Title": "Full Parameter Fine-tuning for Large Language Models with Limited Resources.",
        "Abstract": "Large Language Models (LLMs) have drastically improved the performance of Natural Language Processing (NLP) tasks, including machine translation, text generation, and sentiment analysis. However, the training of such models requires enormous amounts of GPU resources, making it inaccessible to many researchers and organizations with limited computational capabilities. In this study, we propose a full parameter fine-tuning approach to optimize LLMs with limited resources, allowing for efficient model tuning and improved performance without the need for extensive GPU resources.\n\nOur method leverages techniques such as transfer learning, knowledge distillation, and gradient accumulation to maximize the effectiveness of fine-tuning while minimizing the computational requirements. Through experimental validation on various NLP tasks, we demonstrate that our approach achieves comparable performance to traditional fine-tuning methods while significantly reducing the GPU resources needed. This work aims to democratize the use of LLMs in NLP research and applications, enabling a wider range of researchers to leverage the power of large language models for their tasks.",
        "Source": "GPT"
    },
    {
        "Index": 445,
        "Title": "M³CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought.",
        "Abstract": "Multi-modal Chain-of-Thought (MCoT) requires models to leverage knowledge from both textual and visual modalities for the completion of complex reasoning tasks. In this paper, we introduce M³CoT, a novel benchmark that extends the traditional MCoT framework by incorporating multiple domains and multi-step reasoning processes. Our proposed benchmark challenges models to navigate through different domains, such as science, history, and literature, while performing multi-step reasoning tasks that require integrating information from both textual and visual inputs.\n\nWe provide a detailed description of the M³CoT benchmark, including the dataset creation process, task formulation, evaluation metrics, and baseline models. Additionally, we present experimental results demonstrating the effectiveness of our benchmark in evaluating the performance of multi-modal reasoning models. Our results show that modeling multi-domain, multi-step, multi-modal chain-of-thought reasoning is a challenging yet crucial task for advancing the capabilities of AI systems. We believe that the M³CoT benchmark will serve as a valuable resource for assessing the robustness and generalization ability of existing models and inspiring the development of more sophisticated multi-modal reasoning architectures.",
        "Source": "GPT"
    },
    {
        "Index": 446,
        "Title": "Long Context is Not Long at All: A Prospector of Long-Dependency Data for Large Language Models.",
        "Abstract": "Long-context modeling is crucial for the optimal performance of large language models (LLMs) in tasks such as natural language understanding, translation, and generation. This study explores the significance of long-context dependency data for enhancing LLMs' ability to capture complex linguistic patterns and relationships within text. We propose a novel approach for incorporating long-context information into LLMs, which enables more accurate predictions and better context understanding. Our experimental results demonstrate the effectiveness of our proposed method in improving the performance of LLMs across a range of language tasks. By leveraging long-context dependencies, LLMs can achieve higher levels of fluency, coherence, and semantic understanding in their generated output. Overall, our findings underscore the importance of considering long-context modeling capabilities in the design and development of advanced language models for various real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 447,
        "Title": "Label-Synchronous Neural Transducer for E2E Simultaneous Speech Translation.",
        "Abstract": "While the neural transducer is popular for online speech recognition, simultaneous speech translation (SST) requires a label-synchronous neural transducer to accurately translate speech on-the-fly. In this paper, we propose a novel Label-Synchronous Neural Transducer for E2E SST that performs speech recognition and translation simultaneously, without the need for intermediate text representation. Our model utilizes a transformer architecture with multi-head self-attention mechanisms to maintain alignment between the input speech stream and the output translation. By incorporating label-synchronous training techniques, we enhance the model's ability to generate translations in real-time while maintaining the correct linguistic structure. Experimental results on benchmark SST datasets demonstrate the superior performance of our proposed model compared to traditional approaches. Our label-synchronous neural transducer achieves state-of-the-art results in terms of translation accuracy and speed, making it a promising solution for real-time speech translation applications.",
        "Source": "GPT"
    },
    {
        "Index": 448,
        "Title": "Hard Prompts Made Interpretable: Sparse Entropy Regularization for Prompt Tuning with RL.",
        "Abstract": "With the advent of foundation models, prompt tuning has positioned itself as an important technique in natural language processing (NLP) tasks. In this study, we propose a novel approach called Sparse Entropy Regularization for Prompt Tuning with Reinforcement Learning (RL) to address the challenge of understanding and effectively utilizing hard prompts. Our method aims to make hard prompts more interpretable by encouraging sparsity in the prompt tokens through entropy regularization. By applying RL techniques, we are able to dynamically adjust the prompt tokens during the fine-tuning process, leading to improved performance on a variety of NLP tasks.\n\nThrough extensive experimentation, we demonstrate the effectiveness of our proposed approach on a range of benchmark datasets. Our method outperforms existing hard prompt tuning techniques, achieving superior results in terms of accuracy and efficiency. Additionally, we analyze the impact of prompt sparsity on model interpretability and showcase the potential of sparse entropy regularization in enhancing the robustness and generalization capabilities of foundation models.",
        "Source": "GPT"
    },
    {
        "Index": 449,
        "Title": "A Modular Approach for Multimodal Summarization of TV Shows.",
        "Abstract": "In this paper, we propose a modular approach for multimodal summarization of television shows, leveraging both audio and visual information to provide a comprehensive summary. Our approach aims to capture key aspects of television shows by combining transcripts, audio features, and visual cues to generate a concise and coherent summary. We first extract textual information from transcripts to capture dialogue and plot points, while also incorporating audio features such as speaker diarization and emotion recognition to add context to the summary. Additionally, we utilize visual information such as scene segmentation and keyframe extraction to enhance the summarization process. By integrating multiple modalities, our approach enables a more holistic understanding of television shows, capturing both verbal and non-verbal elements that contribute to the overall viewing experience. Experimental results demonstrate the effectiveness of our approach in generating informative and coherent summaries across a variety of television genres.",
        "Source": "GPT"
    },
    {
        "Index": 450,
        "Title": "Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities.",
        "Abstract": "Human interactions are deeply rooted in the interplay of thoughts, beliefs, and desires, making theory-of-mind (ToM) capabilities crucial for effective communication and understanding. Recent advancements in large language models (LLMs) have shown promise in natural language processing tasks, but their ToM abilities are still limited. This study investigates the impact of perspective-taking on improving LLMs' ToM capabilities. Through the incorporation of perspective-taking techniques, LLMs demonstrated a significant enhancement in their ability to infer and accurately predict mental states of others. By encouraging LLMs to simulate and understand different viewpoints and emotions, they were able to develop a more sophisticated understanding of human cognition and behavior. This research highlights the importance of incorporating perspective-taking strategies in LLMs to enhance their ToM capabilities and ultimately improve their performance in real-world applications that require a deeper understanding of human interactions. In conclusion, integrating perspective-taking into LLMs can lead to more accurate and empathetic AI systems that can better navigate complex social interactions.",
        "Source": "GPT"
    },
    {
        "Index": 451,
        "Title": "BizBench: A Quantitative Reasoning Benchmark for Business and Finance.",
        "Abstract": "Answering questions within business and finance requires reasoning, precision, and a wide breadth of technical knowledge. To facilitate the evaluation and comparison of quantitative reasoning skills in these fields, we introduce BizBench, a benchmark specifically designed for assessing proficiency in business and finance-related quantitative reasoning. \n\nBizBench is a comprehensive tool that covers a wide range of topics, including financial analysis, investment decision-making, and economic forecasting. The benchmark includes a series of challenging questions that test the ability to interpret data, perform calculations, and draw valid conclusions based on quantitative information. \n\nBy utilizing BizBench, individuals and organizations can gauge their quantitative reasoning abilities in the context of business and finance, identify areas for improvement, and track progress over time. This benchmark serves as a valuable resource for students, professionals, and researchers looking to enhance their quantitative reasoning skills in the realm of business and finance.",
        "Source": "GPT"
    },
    {
        "Index": 452,
        "Title": "Direct Metric Optimization for Image Captioning through Reward-Weighted Augmented Data Utilization.",
        "Abstract": "While image captioning is an essential field of vision language models (VLM), a lack of high-quality training data and the challenges of directly optimizing metrics have hindered progress in this area. In this study, we propose a novel approach to tackle these issues through Direct Metric Optimization for Image Captioning (DMOIC) using Reward-Weighted Augmented Data Utilization (RWADU). By leveraging a reward-weighted strategy, we augment the training data to improve model performance and optimize directly for captioning metrics such as BLEU and CIDEr. Our experimental results demonstrate that DMOIC with RWADU significantly outperforms existing methods in terms of caption quality and metric scores. Furthermore, we show that our approach is robust to variations in datasets and achieves state-of-the-art results on benchmark datasets such as COCO and Flickr30k. Overall, our work highlights the importance of directly optimizing metrics in image captioning tasks and provides a promising solution to address the challenges associated with training data availability and metric optimization.",
        "Source": "GPT"
    },
    {
        "Index": 453,
        "Title": "Deciphering Hate: Identifying Hateful Memes and Their Targets.",
        "Abstract": "Internet memes have become a powerful means for individuals to express emotions, thoughts, and perspectives. However, with the rise of online hate speech, it is crucial to understand how memes can be used as a tool to spread hateful messages. This study aims to explore the phenomenon of hateful memes and their targets, focusing on the deciphering of their underlying messages. By analyzing various memes circulating on social media platforms, we identify common features and patterns that contribute to the dissemination of hate speech. Through this analysis, we aim to shed light on the ways in which hateful memes can perpetuate stereotypes, stigmatize marginalized groups, and incite violence. By understanding the mechanisms behind these memes, we can better equip individuals and platforms to recognize and counteract hate speech online. This research contributes to the growing body of literature on online hate speech and highlights the importance of addressing this issue in order to create a more inclusive and respectful online environment.",
        "Source": "GPT"
    },
    {
        "Index": 454,
        "Title": "Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings.",
        "Abstract": "Transformers have shown remarkable success in natural language processing tasks by learning representations that capture hierarchical and compositional structures. However, their ability to generalize to novel compositions of structures and entities after training on complex data remains limited. In this paper, we propose a method for inducing systematicity in Transformers by attending to structurally quantized embeddings. By quantizing the embeddings of tokens based on their structural roles within the input sequence, our approach guides the model to capture compositional relationships between elements more effectively. We demonstrate the effectiveness of our method on a range of tasks requiring systematic generalization, including arithmetic reasoning and syntactic parsing. Our experiments show that our approach significantly improves the model's performance on tasks involving novel compositions of structures, outperforming previous methods that rely solely on the model's ability to generalize. Overall, our proposed method offers a principled way to enhance systematicity in Transformers and improve their ability to generalize to diverse and complex input structures.",
        "Source": "GPT"
    },
    {
        "Index": 455,
        "Title": "Label-Efficient Model Selection for Text Generation.",
        "Abstract": "Model selection for a given target task can be costly, as it may entail extensive training and evaluation of multiple models. In the context of text generation, this process becomes even more challenging due to the large number of potential models available. In this study, we propose a label-efficient method for selecting the most suitable model for text generation tasks. Our approach leverages pre-trained language models and uses a limited amount of labeled data to evaluate different models and identify the best one for a specific task. By doing so, we significantly reduce the computational and annotation costs associated with model selection, making it more accessible for researchers and practitioners. Through extensive experiments on multiple text generation tasks, we demonstrate the effectiveness of our method in achieving competitive performance with state-of-the-art models while requiring significantly fewer labeled examples. Our approach can have a wide range of applications in various fields such as natural language processing, machine translation, and dialogue systems.",
        "Source": "GPT"
    },
    {
        "Index": 456,
        "Title": "Machine Unlearning of Pre-trained Large Language Models.",
        "Abstract": "This study investigates the concept of the 'right to be forgotten' within the context of machine unlearning of pre-trained large language models. Large language models have shown remarkable capabilities in natural language processing tasks, but there are growing concerns about their potential to perpetuate biases, misinformation, and privacy violations. The 'right to be forgotten' is a key component of data protection regulations that allows individuals to request the deletion of their personal information from online platforms. In the context of language models, this concept raises questions about the feasibility and implications of removing specific data points from pre-trained models to address privacy concerns and prevent the propagation of harmful information. This study explores the technical challenges and ethical considerations associated with implementing the 'right to be forgotten' in large language models, highlighting the need for transparent policies and mechanisms to support responsible data management practices in AI systems.",
        "Source": "GPT"
    },
    {
        "Index": 457,
        "Title": "Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals.",
        "Abstract": "Interpretability research aims to bridge the gap between the empirical success and our scientific understanding by delving into how language models handle facts and counterfactuals. In this study, we investigate the competition of mechanisms employed by language models when processing these two types of information. Through a series of experiments and analysis, we trace the decision-making processes and reasoning behind the handling of facts and counterfactuals in language models. Our findings reveal the underlying mechanisms at play and shed light on the differences in how language models interpret and process factual information compared to counterfactual information. By understanding these mechanisms, we can gain deeper insights into the inner workings of language models and potentially improve their performance and reliability in various applications. This research contributes to the broader goal of enhancing the interpretability and explainability of language models, ultimately advancing our understanding of artificial intelligence and its impact on society.",
        "Source": "GPT"
    },
    {
        "Index": 458,
        "Title": "FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence.",
        "Abstract": "Plain language summarization with Large Language Models (LLMs) can be a valuable tool for improving the accessibility of technical medical content. In this study, we present FactPICO, a novel framework for evaluating the factuality of plain language summaries generated by LLMs in the context of medical evidence. FactPICO is designed to assess the accuracy and credibility of information presented in these summaries, ensuring that they provide reliable and trustworthy information to readers. By leveraging the power of LLMs, we aim to bridge the gap between complex medical literature and lay audiences, making it easier for non-experts to understand and benefit from the latest medical research. Through rigorous evaluation and validation, we demonstrate the effectiveness of FactPICO in enhancing the quality and reliability of plain language summaries, ultimately contributing to the democratization of medical knowledge and empowering individuals to make informed health decisions.",
        "Source": "GPT"
    },
    {
        "Index": 459,
        "Title": "BvSP: Broad-view Soft Prompting for Few-Shot Aspect Sentiment Quad Prediction.",
        "Abstract": "Aspect sentiment quad prediction (ASQP) aims to predict four aspect-based elements: aspect term, opinion term, sentiment polarity, and opinion target. This task plays a crucial role in sentiment analysis and opinion mining, as it helps to understand the overall sentiment towards specific aspects within a given text. However, ASQP is challenging, especially in few-shot learning scenarios where limited training data is available for each aspect.\n\nIn this paper, we propose a novel approach called Broad-view Soft Prompting for Few-Shot Aspect Sentiment Quad Prediction (BvSP). BvSP leverages a broad-view perspective to capture diverse aspects and sentiments, while also using soft prompting mechanisms to guide the model in generating accurate predictions even with limited training data. Our experimental results on benchmark datasets demonstrate that BvSP outperforms existing methods in few-shot ASQP tasks, achieving significant improvements in aspect term extraction, opinion term identification, sentiment polarity classification, and opinion target identification.\n\nOverall, our work highlights the importance of incorporating broad-view perspectives and soft prompting mechanisms for effective few-shot ASQP, advancing the field of sentiment analysis and opinion mining.",
        "Source": "GPT"
    },
    {
        "Index": 460,
        "Title": "Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an In-Context Attack.",
        "Abstract": "Recent developments in balancing the usefulness and safety of Large Language Models (LLMs) have raised the need for ensuring safety alignment in Natural Language Processing (NLP) tasks. One area of concern is weakly aligned summarization, where the generated summaries may deviate from the original input text, leading to potential misinformation or erroneous information propagation. In this paper, we propose a novel framework for addressing weak alignment in summarization tasks by treating it as an in-context attack. By incorporating safety alignment measures into the training process of LLMs, we aim to improve the reliability and trustworthiness of generated summaries. Our experimental results demonstrate the effectiveness of our approach in mitigating weak alignment issues and improving the overall quality of generated summaries. This work contributes to the growing body of research on safety alignment in NLP tasks, highlighting the importance of considering safety alongside utility in the development of LLMs for real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 461,
        "Title": "Speech language models lack important brain-relevant semantics.",
        "Abstract": "Despite known differences between reading and listening in the brain, recent work has shown that speech and language models lack important brain-relevant semantics. While these models have demonstrated impressive capabilities in various natural language processing tasks, they still struggle to incorporate the nuanced semantic aspects that are crucial for understanding language in a way that mirrors human cognition.\n\nCurrent speech language models rely heavily on statistical patterns and large-scale training data, but they often fail to capture the deeper, more intricate meanings that are processed in the human brain during language comprehension. This limitation stems from a lack of understanding and representation of the underlying semantic structures that govern how language is processed in the brain.\n\nTo address this issue, future research efforts should focus on integrating neurocognitive insights into the development of speech language models. By incorporating brain-relevant semantics into these models, we can improve their ability to understand and generate language in a more human-like manner.",
        "Source": "GPT"
    },
    {
        "Index": 462,
        "Title": "DocLLM: A Layout-Aware Generative Language Model for Multimodal Document Understanding.",
        "Abstract": "Enterprise documents such as forms, receipts, reports, and other records often contain valuable and complex information. In order to extract meaningful insights from these documents, a high level of understanding is required. In this paper, we propose DocLLM, a Layout-Aware Generative Language Model for Multimodal Document Understanding. DocLLM is designed to analyze and comprehend the structured and unstructured data present in diverse enterprise documents. By incorporating layout information, the model is able to better capture the relationships between different elements within the document, leading to more accurate and efficient understanding. We demonstrate the effectiveness of DocLLM on a variety of document types, including financial statements, legal contracts, and medical records. Our experiments show that DocLLM outperforms existing models in terms of document classification, information extraction, and data retrieval tasks. Overall, DocLLM showcases the potential of layout-aware generative language models in enhancing multimodal document understanding in enterprise applications.",
        "Source": "GPT"
    },
    {
        "Index": 463,
        "Title": "Bypassing LLM Watermarks with Color-Aware Substitutions.",
        "Abstract": "Watermarking approaches are often utilized to distinguish between human-generated text and text generated by language models such as GPT-3. In this study, we propose a novel technique for bypassing LLM watermarks by utilizing color-aware substitutions. By manipulating the colors of specific characters or words in the text, we are able to deceive watermarking algorithms that rely solely on the presence of certain words or patterns. This method allows for the generation of text that appears human-generated while still being produced by a language model.\n\nWe demonstrate the effectiveness of our approach through experiments on various watermarking algorithms, showing that our color-aware substitutions successfully fool the systems into misclassifying the text. Additionally, we analyze the limitations and potential vulnerabilities of current watermarking techniques and discuss the implications of our findings for the field of text analysis and identification. Overall, our study highlights the importance of continuously evolving and adapting watermarking approaches to effectively distinguish between human and language model-generated text.",
        "Source": "GPT"
    },
    {
        "Index": 464,
        "Title": "Parallel Structures in Pre-training Data Yield In-Context Learning.",
        "Abstract": "Pre-trained language models (LMs) are capable of in-context learning (ICL): they can adapt to a wide range of tasks by fine-tuning on specific data sets. One key factor in the effectiveness of pre-training data is the presence of parallel structures, which provide multiple examples of similar linguistic patterns. In this study, we explore the impact of parallel structures in pre-training data on the ability of LMs to perform in-context learning tasks. We find that LMs trained on data with parallel structures show improved performance on ICL tasks compared to those trained on data without such structures. This suggests that exposing LMs to diverse examples of similar linguistic patterns during pre-training can enhance their ability to generalize to new tasks and contexts. Our findings highlight the importance of designing pre-training data with parallel structures to optimize the learning capabilities of LMs for in-context learning tasks.",
        "Source": "GPT"
    },
    {
        "Index": 465,
        "Title": "OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models.",
        "Abstract": "Neural Theory-of-Mind (N-ToM) refers to a machine's ability to understand and keep track of the mental states of agents in a given scenario. In recent years, large language models have shown impressive capabilities in natural language understanding and generation tasks. However, their performance in theory-of-mind reasoning tasks remains relatively unexplored. To facilitate the evaluation of these capabilities, we introduce OpenToM, a comprehensive benchmark for assessing theory-of-mind reasoning abilities of large language models.\n\nOpenToM consists of a diverse set of tasks that require reasoning about different aspects of mental states, including beliefs, desires, intentions, and emotions. We propose evaluating language models on OpenToM to provide a standardized and comprehensive assessment of their theory-of-mind reasoning capabilities. By leveraging OpenToM, researchers and developers can gain insights into the strengths and limitations of current language models in understanding and reasoning about mental states. This benchmark will contribute to advancing research in neural theory-of-mind and fostering the development of more sophisticated language models with enhanced theory-of-mind reasoning abilities.",
        "Source": "GPT"
    },
    {
        "Index": 466,
        "Title": "Towards Privacy-Aware Sign Language Translation at Scale.",
        "Abstract": "A major impediment to the advancement of sign language translation (SLT) is data scarcity. Much work has been done in recent years to develop SLT systems that can accurately translate between sign language and spoken or written language. However, the lack of large-scale, diverse data sets hinders the ability to train these systems effectively. In this paper, we propose a framework for privacy-aware sign language translation at scale, which aims to address the issues of data scarcity while also ensuring the privacy of individuals who contribute to the system. Our framework leverages techniques such as differential privacy and federated learning to aggregate data from multiple sources without compromising the privacy of the individuals involved. By implementing this framework, we hope to pave the way for the development of more accurate and robust SLT systems that can be trained on larger, more diverse data sets.",
        "Source": "GPT"
    },
    {
        "Index": 467,
        "Title": "Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards.",
        "Abstract": "Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user preferences. In this paper, we propose a novel approach for arithmetic control of LLMs to align their outputs with directional preferences expressed by users. By incorporating multi-objective rewards, our method allows for the simultaneous optimization of multiple user-specified objectives, enabling the fine-tuning of LLMs to cater to a wide range of preferences. Additionally, we introduce a directional preference alignment mechanism that guides the generation of outputs towards specific desired directions, enhancing the interpretability and usability of LLMs for various applications. Experimental results demonstrate the effectiveness of our approach in achieving precise control over LLMs while maintaining high performance on diverse tasks. Our method paves the way for more customizable and user-centric interactions with LLMs, ultimately improving their utility in real-world scenarios.",
        "Source": "GPT"
    },
    {
        "Index": 468,
        "Title": "Towards Real-World Writing Assistance: A Chinese Character Checking Benchmark with Faked and Misspelled Characters.",
        "Abstract": "Writing assistance aims to improve the correctness and quality of input texts, with character checking playing a crucial role in ensuring accuracy, especially in languages with complex writing systems like Chinese. In this study, we propose a Chinese character checking benchmark that focuses on faked and misspelled characters, which are common errors made by non-native speakers and can significantly impact the readability and comprehension of written texts. By systematically evaluating the performance of different character checking tools on a diverse set of faked and misspelled characters, this benchmark aims to provide a comprehensive evaluation of their effectiveness in real-world scenarios. Our results highlight the importance of robust character checking algorithms that can accurately identify and correct both genuine mistakes and intentionally altered characters. The findings of this study can inform the development of more advanced and reliable writing assistance tools that cater to the specific needs of Chinese language learners and users.",
        "Source": "GPT"
    },
    {
        "Index": 469,
        "Title": "RAVEL: Evaluating Interpretability Methods on Disentangling Language Model Representations.",
        "Abstract": "Individual neurons participate in the representation of multiple high-level concepts. To what extent can different interpretability methods disentangle these complex language model representations? This study evaluates various interpretability methods on disentangling language model representations using RAVEL, a framework specifically designed for evaluating interpretability methods on neural network representations. We explore the ability of prominent interpretability methods such as attention visualization, feature visualization, and attribution methods to disentangle and interpret the complex representations learned by language models. Our results showcase the strengths and limitations of each method in disentangling different high-level concepts within the language model. By comparing the performance of these methods on disentangling representations of concepts such as sentiment, topic, and syntax, we provide insights into which methods are most effective for revealing the internal workings of language models. Ultimately, this work contributes to the ongoing effort of understanding and interpreting the representations learned by neural language models.",
        "Source": "GPT"
    },
    {
        "Index": 470,
        "Title": "Large Language Models as Zero-shot Dialogue State Tracker through Function Calling.",
        "Abstract": "Large Language Models (LLMs) have become a key component in conversational systems, owing to their ability to comprehend and generate human-like text. In this study, we propose utilizing LLMs as zero-shot dialogue state trackers through function calling. By leveraging the advanced understanding capabilities of LLMs, we aim to improve the accuracy and efficiency of dialogue state tracking in conversational systems.\n\nTraditionally, dialogue state tracking involves predicting the current state of a conversation based on the dialogue history. However, this approach may be limited by the complexity and variability of natural language conversations. By utilizing LLMs for zero-shot dialogue state tracking, we can leverage their pre-trained knowledge to dynamically call functions that update the dialogue state based on the incoming text.\n\nOur experimental results demonstrate the effectiveness of using LLMs for zero-shot dialogue state tracking, showing improvements in accuracy and efficiency compared to traditional methods. Overall, this study highlights the potential of large language models in enhancing dialogue state tracking in conversational systems.",
        "Source": "GPT"
    },
    {
        "Index": 471,
        "Title": "Faithful Chart Summarization with ChaTS-Pi.",
        "Abstract": "Chart-to-summary generation is a crucial task for exploring and communicating insights from data. It plays a vital role in enabling visually impaired individuals to access and comprehend visual information effectively. In this paper, we present a novel framework called ChaTS-Pi, which focuses on faithful chart summarization. Our proposed method leverages multi-modal information, including textual and visual cues, to generate detailed and accurate summaries from various types of charts. By incorporating both textual and visual features, ChaTS-Pi is able to capture the important details of the chart while also providing a concise and informative summary. We demonstrate the effectiveness of our approach through extensive experiments on a diverse range of chart datasets. Our results show that ChaTS-Pi outperforms existing methods in terms of summarization quality and fidelity to the original chart. Overall, our framework provides a valuable tool for generating faithful chart summaries that can benefit a wide range of users, including those with visual impairments.",
        "Source": "GPT"
    },
    {
        "Index": 472,
        "Title": "Enhancing Dialogue State Tracking Models through LLM-backed User-Agents Simulation.",
        "Abstract": "Dialogue State Tracking (DST) is designed to monitor the evolving dialogue state in conversations, enabling intelligent systems to effectively manage and respond to user inputs. However, existing DST models often struggle to accurately capture the nuances and dynamics of natural language conversations, leading to suboptimal performance in task-oriented dialogue systems. In this paper, we propose a novel approach to enhance DST models by leveraging Large Language Models (LLMs) to simulate user-agents in dialogues. By integrating LLM-backed user-agents into the training process, our model learns to better understand user intents, context, and preferences, resulting in improved dialogue state tracking performance.\n\nThrough extensive experiments and evaluations on benchmark datasets, we demonstrate that our proposed approach significantly outperforms traditional DST models in terms of accuracy, robustness, and flexibility. Ultimately, our method shows promise in advancing the capabilities of task-oriented dialogue systems and enhancing user experiences in various applications, from customer service chatbots to virtual assistants.",
        "Source": "GPT"
    },
    {
        "Index": 473,
        "Title": "MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking.",
        "Abstract": "Fact-checking real-world claims often requires reviewing multiple multimodal documents in order to assess the claim's veracity. However, manually analyzing and synthesizing information from various sources can be time-consuming and prone to errors. In this paper, we propose MetaSumPerceiver, a novel approach for multimodal multi-document evidence summarization for fact-checking. MetaSumPerceiver leverages both textual and visual information from diverse sources to generate concise and informative summaries of relevant evidence. Our approach incorporates state-of-the-art natural language processing and computer vision techniques to analyze and extract key information from a variety of documents, including articles, images, and videos. Through extensive experiments on real-world datasets, we demonstrate that MetaSumPerceiver outperforms existing methods in terms of accuracy and efficiency. By automating the process of evidence summarization, MetaSumPerceiver can significantly improve the fact-checking process by providing reliable and comprehensive summaries of evidence for verifying real-world claims.",
        "Source": "GPT"
    },
    {
        "Index": 474,
        "Title": "Systematic Task Exploration with LLMs: A Study in Citation Text Generation.",
        "Abstract": "Large language models (LLMs) bring unprecedented flexibility in defining and executing complex, creative natural language tasks. In this study, we focus on systematic task exploration with LLMs, specifically in the context of citation text generation. By leveraging the capabilities of LLMs, we aim to develop a deeper understanding of how these models can be used to generate accurate and contextually relevant citations. Through a series of experiments and analyses, we investigate the impact of various parameters and strategies on the quality of citation text created by LLMs. Our findings reveal insights into the strengths and limitations of LLMs in this particular task, shedding light on potential improvements and best practices for citation text generation. Overall, our study contributes to the growing body of research on utilizing LLMs for specific natural language tasks, showcasing their versatility and potential for advancing text generation capabilities in scholarly communication.",
        "Source": "GPT"
    },
    {
        "Index": 475,
        "Title": "ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis.",
        "Abstract": "Large language models (LLMs) have achieved commendable accomplishments in various natural language processing tasks. However, these models often struggle with maintaining coherent and logical chain of thoughts in their generated text. In this paper, we propose ERA-CoT, a novel approach to improve the chain-of-thought in LLMs through entity relationship analysis. By leveraging entity relationships extracted from the text, ERA-CoT enhances the coherence and logical flow of generated text by guiding the model to maintain consistency in the entities and their relationships throughout the text. Our experimental results demonstrate that ERA-CoT significantly outperforms baseline models in maintaining the chain-of-thought and coherence in generated text across multiple language tasks. Additionally, we analyze the impact of entity relationship analysis on various metrics such as fluency, coherence, and entity accuracy to provide insights into the effectiveness of our proposed approach. Overall, ERA-CoT presents a promising step towards enhancing the coherence and logical flow of generated text by incorporating entity relationship analysis in large language models.",
        "Source": "GPT"
    },
    {
        "Index": 476,
        "Title": "On the Multi-turn Instruction Following for Conversational Web Agents.",
        "Abstract": "Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and generating natural language responses in conversational settings. However, their performance in following multi-turn instructions has been relatively limited. In this paper, we propose a novel approach to enhance the instruction-following abilities of conversational web agents through the use of multi-turn instruction understanding techniques. We introduce a framework that combines contextual understanding, memory-based reasoning, and reinforcement learning to enable web agents to better comprehend and act upon complex, multi-step instructions given by users. Our experimental results show that our proposed approach significantly improves the performance of web agents in following multi-turn instructions, outperforming existing methods in various benchmark tasks. Overall, our work contributes to the advancement of conversational web agents by enhancing their capabilities in understanding and executing complex instructions, thereby improving the overall user experience and usability of intelligent conversational systems.",
        "Source": "GPT"
    },
    {
        "Index": 477,
        "Title": "Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents.",
        "Abstract": "With the remarkable advancements of large language models (LLMs), LLM-based agents have become a research focus in the field of mobile agents. In this paper, we introduce Mobile-Bench, an evaluation benchmark specifically designed for LLM-based mobile agents. Mobile-Bench includes a diverse set of tasks and scenarios to comprehensively evaluate the performance and capabilities of LLM-based agents on mobile devices. The benchmark covers tasks such as natural language understanding, dialog generation, and knowledge retrieval, among others. Mobile-Bench aims to provide a standardized evaluation framework for researchers and developers to compare and improve the efficiency, effectiveness, and resource utilization of LLM-based mobile agents. We believe that Mobile-Bench will facilitate the development of more advanced and optimized LLM-based mobile agents, ultimately leading to greater usability and performance in real-world applications.",
        "Source": "GPT"
    },
    {
        "Index": 478,
        "Title": "MC²: Towards Transparent and Culturally-Aware NLP for Minority Languages in China.",
        "Abstract": "Current large language models demonstrate deficiencies in understanding low-resource languages, particularly the minority languages in China. In this study, we propose MC², a novel approach that aims to improve the transparency and cultural awareness of natural language processing (NLP) models for minority languages in China. By incorporating cultural knowledge and linguistic nuances specific to these languages, MC² can provide more accurate and culturally sensitive results compared to existing models. Our methodology involves collecting a diverse range of linguistic data from minority language speakers, developing language-specific pre-processing techniques, and implementing culturally-aware training strategies. Through MC², we hope to bridge the gap between NLP technology and minority language speakers in China, enabling more inclusive and accurate language processing capabilities. This research contributes to the growing field of NLP for low-resource languages and highlights the importance of considering cultural differences in language processing models.",
        "Source": "GPT"
    },
    {
        "Index": 479,
        "Title": "Decoder-only Streaming Transformer for Simultaneous Translation.",
        "Abstract": "Simultaneous Machine Translation (SiMT) is a cutting-edge approach that allows translations to be generated in real-time as the source text is being read. This technique, also known as \"simultaneous decoding,\" enables the translation system to produce target language output incrementally, creating a target prefix that grows in parallel with the source input. In this study, we propose a Decoder-only Streaming Transformer for SiMT, a novel model that leverages the power of transformers for efficient and accurate simultaneous translation tasks. By focusing solely on the decoding process, our model eliminates the need for complex encoder-decoder architecture, leading to faster and more streamlined translation performance. Through extensive experimentation and evaluation, we demonstrate that our Decoder-only Streaming Transformer outperforms traditional SiMT models in terms of both translation quality and speed, making it a promising solution for real-time translation applications in various domains.",
        "Source": "GPT"
    },
    {
        "Index": 480,
        "Title": "Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization.",
        "Abstract": "While significant attention has been dedicated to exploiting weaknesses in Large Language Models (LLMs) through jailbreaking attacks, there is a lack of research focused on defending against such attacks. In this paper, we propose a novel approach to protect LLMs from jailbreaking attacks by prioritizing specific goals during the training process. By identifying and prioritizing key objectives such as model robustness and privacy preservation, we aim to enhance the security of LLMs against potential threats. We leverage advancements in reinforcement learning and differential privacy techniques to design a defense mechanism that can effectively mitigate jailbreaking attacks without sacrificing the performance of the model. Through extensive theoretical analysis and experimental evaluations, we demonstrate the effectiveness of our proposed approach in achieving robust defense against jailbreaking attacks on LLMs. Our findings provide valuable insights for enhancing the security of LLMs in real-world applications where data privacy and model integrity are critical concerns.",
        "Source": "GPT"
    },
    {
        "Index": 481,
        "Title": "I am a Strange Dataset: Metalinguistic Tests for Language Models.",
        "Abstract": "Metalinguistic self-referential statements, such as \"This paper discusses...\", are commonly used in various academic disciplines. In this paper, we explore the use of metalinguistic tests for language models, focusing on the evaluation of their ability to understand and generate self-referential statements. We present a series of experiments that demonstrate the effectiveness of these tests in assessing a language model's metalinguistic capabilities.\n\nOur findings highlight the importance of incorporating metalinguistic tasks into the evaluation of language models, as they provide valuable insights into the model's understanding of language beyond surface-level patterns. By analyzing the performance of language models on metalinguistic tests, we can gain a deeper understanding of their linguistic reasoning abilities and improve their overall language generation capabilities.\n\nOverall, this paper showcases the significance of metalinguistic self-reference in the evaluation of language models and provides a framework for incorporating these tests into future language model development and evaluation processes.",
        "Source": "GPT"
    },
    {
        "Index": 482,
        "Title": "TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space.",
        "Abstract": "Large Language Models (LLMs) sometimes suffer from producing hallucinations, where they generate untruthful responses that do not align with reality. These hallucinations pose a significant challenge in deploying LLMs in various applications, as the generated misinformation can have detrimental effects. To address this issue, we propose TruthX, a novel approach to alleviate hallucinations by editing LLMs in a truthful space. \n\nTruthX leverages a Truthfulness Classifier to identify hallucinations in the outputs generated by LLMs. Once identified, the hallucinated text is then transformed using a Truthful Editor, which adjusts the content to ensure it aligns with factual information. By operating in a truthful space, TruthX aims to enhance the reliability and accuracy of LLMs, ultimately improving the quality of generated responses.\n\nOur experimental results demonstrate the effectiveness of TruthX in reducing hallucinations and generating more factually accurate outputs. By incorporating TruthX into LLMs, we can mitigate the risks associated with misinformation and enhance the trustworthiness of these powerful models.",
        "Source": "GPT"
    },
    {
        "Index": 483,
        "Title": "ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training.",
        "Abstract": "We propose ProtLLM, a novel cross-modal large language model (LLM) designed for dual functionality in the protein-centric and protein-language domains. Our model leverages protein sequences as input data, treating them as sequences of \"words\" within a protein \"language.\" ProtLLM is pre-trained on protein sequences using a protein-as-word encoding strategy, allowing it to learn rich representations of protein structures and functions. Additionally, our model is capable of processing natural language text related to proteins, enabling it to perform tasks such as protein sequence generation, function prediction, and text generation.\n\nProtLLM offers a versatile solution for a wide range of protein-centric and protein-language tasks, filling a critical gap in the field of computational biology and bioinformatics. By jointly modeling protein sequences and natural language text, ProtLLM has the potential to enhance our understanding of protein structure-function relationships and facilitate the discovery of new biological insights. Our experimental results demonstrate the effectiveness of ProtLLM in various protein-centric and protein-language tasks, showcasing its potential as a powerful tool for biologists, bioinformaticians, and computational biologists alike.",
        "Source": "GPT"
    },
    {
        "Index": 484,
        "Title": "StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task Learning.",
        "Abstract": "Simultaneous speech-to-speech translation (Simul-S2ST) is a cutting-edge technology that allows for the real-time translation of spoken language into target speech as the speaker continues to talk. This process, also known as streaming speech translation, has the potential to revolutionize communication by enabling seamless and immediate multilingual conversations. \n\nOur research focuses on developing StreamSpeech, a system that leverages multi-task learning to improve the accuracy and efficiency of Simul-S2ST. By simultaneously training our model on multiple related tasks, such as speech recognition and machine translation, we are able to enhance the overall performance of the translation process. \n\nThrough extensive experimentation, we demonstrate the effectiveness of StreamSpeech in achieving high-quality, real-time speech-to-speech translations. Our results show significant improvements in speed and accuracy, making Simul-S2ST more practical and reliable for a wide range of applications, from international conferences to personal interactions. StreamSpeech represents a significant advancement in the field of simultaneous speech translation and has the potential to greatly enhance cross-cultural communication.",
        "Source": "GPT"
    },
    {
        "Index": 485,
        "Title": "Investigating Multi-Hop Factual Shortcuts in Knowledge Editing of Large Language Models.",
        "Abstract": "Recent work has showcased the powerful capability of large language models (LLMs) in recalling knowledge through fine-tuning and prompt-based methods. However, there is a growing concern regarding the reliability and trustworthiness of the information generated by these models, particularly in the context of knowledge editing. This study investigates the use of multi-hop factual shortcuts in knowledge editing of large language models, with the aim of improving the accuracy and coherence of the generated knowledge. Through extensive experiments and analysis, we demonstrate that incorporating multi-hop factual shortcuts can enhance the performance of LLMs in generating factual information while maintaining semantic coherence. Additionally, our findings suggest that the use of multi-hop shortcuts can help mitigate the issue of factual errors and inconsistencies commonly observed in current LLM-generated content. Overall, our research sheds light on the potential of leveraging multi-hop factual shortcuts to enhance the reliability and trustworthiness of knowledge editing in large language models.",
        "Source": "GPT"
    },
    {
        "Index": 486,
        "Title": "Why Don't Prompt-Based Fairness Metrics Correlate?",
        "Abstract": "The widespread use of large language models has brought up essential questions about the potential biases and unfairness embedded in these models. Prompt-based fairness metrics have been proposed as a way to evaluate and mitigate these issues, aiming to ensure that language models generate fair and unbiased outputs. However, despite the increasing emphasis on fairness in natural language processing tasks, there is a lack of correlation between different prompt-based fairness metrics. This discrepancy raises concerns about the effectiveness and reliability of current fairness evaluation methods in language models. In this paper, we delve into the reasons behind the lack of correlation among prompt-based fairness metrics and propose potential strategies to improve the assessment of biases in large language models. By addressing these challenges, we aim to pave the way for more rigorous and effective fairness evaluation techniques in natural language processing research and applications.",
        "Source": "GPT"
    },
    {
        "Index": 487,
        "Title": "NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using Representative Data.",
        "Abstract": "To address the global issue of online hate, hate speech detection (HSD) systems are typically developed and evaluated using data from Western social media platforms. However, these systems may not be effective in detecting hate speech in non-Western contexts, such as Nigeria. In this study, we present NaijaHate, a dataset of Nigerian Twitter data annotated for hate speech, and evaluate the performance of existing HSD systems on this dataset. We find that these systems perform poorly on NaijaHate, highlighting the need for context-specific approaches to hate speech detection. Additionally, we analyze the linguistic characteristics of hate speech in Nigerian tweets and compare them to existing hate speech datasets. Our findings suggest that hate speech in Nigeria exhibits unique linguistic features that may challenge the performance of current HSD systems. This study underscores the importance of developing and evaluating hate speech detection tools on diverse and representative datasets to effectively combat online hate in global contexts.",
        "Source": "GPT"
    },
    {
        "Index": 488,
        "Title": "M³AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset.",
        "Abstract": "Publishing open-source academic video recordings is an emergent and prevalent approach to sharing knowledge online. In response to the increasing demand for high-quality academic resources, we present the M³AV dataset - a comprehensive collection of multimodal, multigenre, and multipurpose audio-visual academic lecture recordings. This dataset includes a diverse range of lectures from various academic disciplines, each accompanied by complementary materials such as slides, transcripts, and supplementary resources. By providing access to these resources in an open-source format, researchers, educators, and students can benefit from a rich and varied learning experience.\n\nThe M³AV dataset is designed to facilitate research and development in the areas of multimedia processing, educational technology, and digital learning environments. With its emphasis on diversity and accessibility, this dataset aims to support a wide range of applications, including content analysis, automatic transcription, and personalized learning experiences. We believe that the M³AV dataset will serve as a valuable resource for advancing research in the field of academic video recordings and promoting knowledge dissemination in the digital age.",
        "Source": "GPT"
    },
    {
        "Index": 489,
        "Title": "Mitigating Biases for Instruction-following Language Models via Bias Neurons Elimination.",
        "Abstract": "Instruction-following language models often show undesirable biases that can impact the quality and fairness of their outputs. These biases may be exacerbated in the training process, leading to the production of biased and potentially harmful language model outputs. In this study, we propose a method to mitigate biases in instruction-following language models by eliminating bias neurons during the training phase. By identifying and removing neurons that contribute to biased behavior, we aim to improve the overall performance and fairness of these models. Our approach involves analyzing the activation patterns of neurons in the language model and selectively disabling those that are responsible for generating biased outputs. Experimental results show that our method effectively reduces biases in instruction-following language models, leading to more accurate and unbiased responses to instructions. By eliminating bias neurons, we can enhance the reliability and trustworthiness of instruction-following language models in various applications, such as natural language processing and human-computer interaction.",
        "Source": "GPT"
    },
    {
        "Index": 490,
        "Title": "Domain Adaptation for Subjective Induction Questions Answering on Products by Adversarial Disentangled Learning.",
        "Abstract": "This paper presents a novel approach for answering subjective questions about products through domain adaptation using adversarial disentangled learning. Subjective induction questions require understanding context, emotions, opinions, and personal preferences, which cannot be answered with simple facts. Our proposed method leverages adversarial disentangled learning to separate domain-specific information from general knowledge, allowing our model to adapt to different product domains and improve performance on subjective question answering tasks. By disentangling the latent representations, our model can learn domain-invariant features that facilitate knowledge transfer across different product categories. Experimental results demonstrate that our approach outperforms standard methods on a dataset of subjective induction questions about various products. This work contributes to the advancement of natural language processing and addresses the challenges in understanding and answering subjective questions in the context of product reviews and recommendations.",
        "Source": "GPT"
    },
    {
        "Index": 491,
        "Title": "Revisiting Demonstration Selection Strategies in In-Context Learning.",
        "Abstract": "Large language models (LLMs) have shown an impressive ability to perform a wide range of natural language processing tasks, including question answering and text generation. In the field of in-context learning, where models are trained to generate responses in an ongoing conversation, the selection of demonstration examples plays a crucial role in shaping the model's behavior. In this paper, we revisit and explore various demonstration selection strategies in the context of in-context learning. We examine the effectiveness of different approaches, such as random selection, diversity sampling, and active learning, in improving the performance and efficiency of LLMs in generating contextually relevant responses. Our experimental results demonstrate the importance of carefully selecting demonstration examples to optimize model performance in in-context learning settings. We also provide insights into the potential impact of different selection strategies on model generalization and adaptation to new dialogue contexts. Overall, our study highlights the significance of revisiting and refining demonstration selection strategies to enhance the capabilities of LLMs in in-context learning tasks.",
        "Source": "GPT"
    },
    {
        "Index": 492,
        "Title": "Multimodal Table Understanding.",
        "Abstract": "Although great progress has been made by previous table understanding methods including recent approaches based on neural networks, there still remains a significant gap in achieving multimodal table understanding. In this paper, we propose a novel technique that combines text, image, and structural information to improve the comprehension and interpretation of tables. By incorporating multiple modalities, our approach aims to enhance the accuracy and robustness of table understanding, particularly in complex and diverse datasets. Our method leverages the strengths of each modality to capture various aspects of tables, such as content, layout, and context, thereby enabling a more comprehensive analysis. Experimental results demonstrate the effectiveness of our multimodal approach compared to existing methods, showcasing improvements in tasks such as table recognition, entity extraction, and relationship extraction. Overall, our work contributes to advancing the field of table understanding by addressing the challenges associated with multimodal data integration and interpretation.",
        "Source": "GPT"
    },
    {
        "Index": 493,
        "Title": "Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding.",
        "Abstract": "Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding. \n\nGenerating long-term texts such as novels using artificial intelligence has always been a challenge. The Ex3 system proposes a novel approach to overcome this challenge by combining the processes of extracting key information, excelling in language generation, and expanding on existing text. \n\nIn the extraction phase, the system identifies relevant themes, characters, settings, and plot points from a given dataset or input. It then excels in language generation by utilizing advanced natural language processing techniques to craft coherent and engaging sentences. Finally, the system expands on the extracted information by weaving in additional details, descriptions, and dialogue to create a comprehensive narrative.\n\nThrough a combination of machine learning algorithms, deep neural networks, and automated text generation models, Ex3 has shown promising results in producing novel-length texts that are both compelling and immersive. This innovative approach opens up new possibilities for automating the creation of long-form literary works and pushing the boundaries of artificial intelligence in the realm of creative writing.",
        "Source": "GPT"
    },
    {
        "Index": 494,
        "Title": "Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning.",
        "Abstract": "Existing Knowledge Base Question Answering (KBQA) architectures are hungry for annotated data, which makes training them a challenging task. In this paper, we propose a novel approach to address this issue by introducing Few-shot Transfer Learning for KBQA. Our method involves fusing supervised models with in-context learning, enabling the KBQA system to leverage pre-trained knowledge while requiring only a small amount of annotated data for fine-tuning. By doing so, we can significantly reduce the need for large datasets, making the training process more efficient and cost-effective. Our experimental results demonstrate that our approach outperforms traditional KBQA architectures on various datasets, achieving state-of-the-art results with minimal annotated data. This suggests that Few-shot Transfer Learning has the potential to revolutionize the field of KBQA by enabling more effective and scalable systems.",
        "Source": "GPT"
    },
    {
        "Index": 495,
        "Title": "WatME: Towards Lossless Watermarking Through Lexical Redundancy.",
        "Abstract": "Text watermarking has emerged as a pivotal technique for identifying machine-generated text. However, existing methods often suffer from lossy compression, leading to degradation of the original content. In this paper, we propose a novel watermarking technique, WatME, which aims to achieve lossless watermarking through utilizing lexical redundancy in the text. By identifying and leveraging redundant information present in the text, WatME is able to embed watermark without altering the original content, thus ensuring high fidelity in the watermarked text. Experimental results demonstrate the effectiveness of WatME in maintaining the integrity of the original text while successfully embedding and extracting watermarks with minimal distortion. Additionally, WatME offers robustness against common attacks such as noise addition and text reordering, further highlighting its potential for practical applications in text authentication and copyright protection. Overall, WatME represents a promising advancement towards lossless text watermarking, addressing the limitations of existing methods and opening up new possibilities for secure and reliable text watermarking in diverse real-world scenarios.",
        "Source": "GPT"
    },
    {
        "Index": 496,
        "Title": "Text-like Encoding of Collaborative Information in Large Language Models for Recommendation.",
        "Abstract": "When adapting Large Language Models for Recommendation (LLMRec), it is crucial to integrate collaborative information. In this study, we propose a novel text-like encoding method to incorporate collaborative filtering signals into pre-trained language models for recommendation tasks. By encoding user-item interactions as text sequences, we are able to leverage the rich contextual information captured by language models to make more personalized and accurate recommendations. Our approach takes into account user interactions with items, as well as social connections and other collaborative signals, to enhance the recommendation performance of LLMRec. Experimental results on real-world datasets demonstrate that our text-like encoding method significantly improves recommendation accuracy compared to traditional approaches that do not consider collaborative information. Overall, our study highlights the importance of integrating collaborative information in large language models for recommendation systems, and provides a practical and effective method to do so.",
        "Source": "GPT"
    },
    {
        "Index": 497,
        "Title": "MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception.",
        "Abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated exceptional capabilities in visual perception. However, it is crucial to evaluate their self-awareness in perceiving the world around them. In this study, we introduce MM-SAP, a comprehensive benchmark designed to assess the self-awareness of MLLMs in perception tasks. The benchmark consists of a diverse set of challenges that test the model's ability to accurately interpret and understand multimodal inputs.\n\nMM-SAP encompasses tasks ranging from identifying objects in images to generating descriptive captions for complex scenes. By evaluating MLLMs on this benchmark, we can gain insights into their level of self-awareness and their capacity to understand the context and nuances of multimodal inputs. The results from this benchmark will inform the development of more robust and self-aware MLLMs, ultimately enhancing their performance in various applications such as image recognition, video understanding, and natural language processing.",
        "Source": "GPT"
    },
    {
        "Index": 498,
        "Title": "Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems in Commonsense Reasoning.",
        "Abstract": "Large language models, such as GPT-3, have demonstrated impressive commonsense reasoning capabilities, particularly when enhanced with techniques like Chain-of-Thought (CoT). However, as these models become increasingly sophisticated, there is growing concern about the potential for toxic behaviors and biases to manifest in their reasoning processes. This paper focuses on addressing and mitigating these issues, emphasizing the importance of carefully monitoring and interpreting the outputs of large language models when applying CoT techniques. By focusing on the user's input question and maintaining a clear objective during the reasoning process, we can better understand the model's decision-making and identify potential instances of toxicity. Through a combination of human oversight and automated monitoring tools, we can work to minimize the impact of toxic CoT problems in commonsense reasoning, ensuring that these advanced language models remain valuable tools for a wide range of applications.",
        "Source": "GPT"
    },
    {
        "Index": 499,
        "Title": "Multi-Aspect Controllable Text Generation with Disentangled Counterfactual Augmentation.",
        "Abstract": "Multi-aspect controllable text generation aims to control the generated texts in attributes from multiple aspects, such as style, sentiment, and content. Existing methods often struggle to generate text with desired attributes due to the complex interactions between different aspects. In this paper, we propose a novel approach called Disentangled Counterfactual Augmentation (DCA) to enhance multi-aspect controllable text generation. DCA leverages counterfactual data augmentation to disentangle the aspects of the text generation process, enabling more precise control over each attribute. By conditioning the generation process on disentangled latent variables, DCA can generate text with specific attributes while maintaining overall coherence and fluency. We conduct experiments on multiple benchmark datasets to demonstrate the effectiveness of our approach in controlling various aspects of text generation. The results show that our method outperforms existing techniques in terms of attribute control and text quality. Overall, our work contributes to advancing the field of multi-aspect controllable text generation and opens up new possibilities for generating high-quality text with desired attributes.",
        "Source": "GPT"
    }
]